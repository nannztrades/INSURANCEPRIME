################################################################################
# Combined Python Scripts
# Created: 2026-01-16T23:59:34
# Source base: D:\PROJECT\INSURANCELOCAL\src
# Files included: 51
################################################################################

################################################################################
# ===== FILE: __init__.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\__init__.py
# SIZE: 0 bytes
# ENCODING: utf-8
# ===== START =====

# ===== END FILE: __init__.py =====

################################################################################
# ===== FILE: api\__init__.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\__init__.py
# SIZE: 0 bytes
# ENCODING: utf-8
# ===== START =====

# ===== END FILE: api\__init__.py =====

################################################################################
# ===== FILE: api\admin_agents.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\admin_agents.py
# SIZE: 5,214 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from typing import Any, Dict, List, Optional

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel

from src.ingestion.db import get_conn
from src.services.roles import require_role
from src.services.security import require_csrf


router = APIRouter(
    prefix="/api/admin/agents",
    tags=["Admin Agents"],
    dependencies=[Depends(require_role("admin", "superuser"))],
)


class AgentCreate(BaseModel):
    agent_code: str
    agent_name: Optional[str] = None
    license_number: Optional[str] = None
    agent_provided_earliest_date: Optional[str] = None
    is_active: int = 1


class AgentUpdate(BaseModel):
    agent_name: Optional[str] = None
    license_number: Optional[str] = None
    agent_provided_earliest_date: Optional[str] = None
    is_active: Optional[int] = None


@router.get("")
def list_agents(limit: int = 200, offset: int = 0) -> Dict[str, Any]:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT `agent_code`,`agent_name`,`license_number`,
                       `agent_provided_earliest_date`,`is_active`,
                       `created_at`,`updated_at`
                FROM `agents`
                ORDER BY `agent_code` ASC
                LIMIT %s OFFSET %s
                """,
                (limit, offset),
            )
            items = list(cur.fetchall() or [])
        return {"count": len(items), "items": items}
    finally:
        conn.close()


@router.post("", dependencies=[Depends(require_csrf)])
def create_agent(payload: AgentCreate) -> Dict[str, Any]:
    if not payload.agent_code or not str(payload.agent_code).strip():
        raise HTTPException(status_code=400, detail="agent_code is required")

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT 1 FROM `agents` WHERE `agent_code`=%s",
                (payload.agent_code,),
            )
            if cur.fetchone():
                cur.execute(
                    """
                    UPDATE `agents`
                    SET `agent_name`=%s,
                        `license_number`=%s,
                        `agent_provided_earliest_date`=%s,
                        `is_active`=%s,
                        `updated_at`=NOW()
                    WHERE `agent_code`=%s
                    """,
                    (
                        payload.agent_name,
                        payload.license_number,
                        payload.agent_provided_earliest_date,
                        int(bool(payload.is_active)),
                        payload.agent_code,
                    ),
                )
            else:
                cur.execute(
                    """
                    INSERT INTO `agents`
                        (`agent_code`,`agent_name`,`license_number`,
                         `agent_provided_earliest_date`,`is_active`,`created_at`,`updated_at`)
                    VALUES (%s,%s,%s,%s,%s,NOW(),NOW())
                    """,
                    (
                        payload.agent_code,
                        payload.agent_name,
                        payload.license_number,
                        payload.agent_provided_earliest_date,
                        int(bool(payload.is_active)),
                    ),
                )
        conn.commit()
        return {"status": "SUCCESS", "agent_code": payload.agent_code}
    finally:
        conn.close()


@router.put(
    "/{agent_code}",
    dependencies=[Depends(require_csrf)],
)
def update_agent(agent_code: str, payload: AgentUpdate) -> Dict[str, Any]:
    sets: List[str] = []
    vals: List[Any] = []

    if payload.agent_name is not None:
        sets.append("`agent_name`=%s")
        vals.append(payload.agent_name)
    if payload.license_number is not None:
        sets.append("`license_number`=%s")
        vals.append(payload.license_number)
    if payload.agent_provided_earliest_date is not None:
        sets.append("`agent_provided_earliest_date`=%s")
        vals.append(payload.agent_provided_earliest_date)
    if payload.is_active is not None:
        sets.append("`is_active`=%s")
        vals.append(int(bool(payload.is_active)))

    if not sets:
        return {"status": "NOOP", "agent_code": agent_code}

    sql = f"UPDATE `agents` SET {', '.join(sets)}, `updated_at`=NOW() WHERE `agent_code`=%s"
    vals.append(agent_code)

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(sql, tuple(vals))
        conn.commit()
        return {"status": "SUCCESS", "agent_code": agent_code}
    finally:
        conn.close()


@router.delete(
    "/{agent_code}",
    dependencies=[Depends(require_csrf)],
)
def deactivate_agent(agent_code: str) -> Dict[str, Any]:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "UPDATE `agents` SET `is_active`=0, `updated_at`=NOW() WHERE `agent_code`=%s",
                (agent_code,),
            )
        conn.commit()
        return {"status": "SUCCESS", "agent_code": agent_code}
    finally:
        conn.close()
# ===== END FILE: api\admin_agents.py =====

################################################################################
# ===== FILE: api\admin_reports.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\admin_reports.py
# SIZE: 25,174 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/admin_reports.py

from __future__ import annotations
from typing import Any, Dict, Iterable, List, Optional, Tuple
from fastapi import APIRouter, Depends, Form, HTTPException
from fastapi.responses import StreamingResponse
import csv
import io
from src.ingestion.db import get_conn
from src.services.roles import require_role
from src.services.security import require_csrf

router = APIRouter(
    prefix="/api/admin",
    tags=["Admin Reports"],
    dependencies=[Depends(require_role("admin", "superuser"))],
)

def _dicts_to_csv_stream(
    rows: Iterable[Dict[str, Any]],
    field_order: Optional[List[str]] = None,
    filename: Optional[str] = None,
) -> StreamingResponse:
    buf = io.StringIO()
    rows_list = list(rows)
    if rows_list:
        if field_order is None:
            field_order = list(rows_list[0].keys())
        writer = csv.DictWriter(buf, fieldnames=field_order, extrasaction="ignore")
        writer.writeheader()
        for r in rows_list:
            writer.writerow(r)
    buf.seek(0)
    headers = {"Content-Type": "text/csv; charset=utf-8"}
    if filename:
        headers["Content-Disposition"] = f'attachment; filename="{filename}"'
    return StreamingResponse(buf, headers=headers)

def _split_holder(holder: Optional[str]) -> Tuple[str, str]:
    s = str(holder or "").strip()
    if not s:
        return "", ""
    parts = s.split()
    surname = parts[0]
    other = " ".join(parts[1:]) if len(parts) > 1 else ""
    return surname, other

def _mr():
    import importlib
    return importlib.import_module("src.reports.monthly_reports")

@router.get("/uploads")
def list_uploads(
    doc_type: Optional[str] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    conn = get_conn()
    try:
        sql = """
        SELECT `UploadID`,`agent_code`,`AgentName`,`doc_type`,`FileName`,`UploadTimestamp`,
               `month_year`,`is_active`
        FROM `uploads` WHERE 1=1
        """
        params: List[Any] = []
        if doc_type:
            sql += " AND `doc_type`=%s"
            params.append(doc_type)
        if agent_code:
            sql += " AND `agent_code`=%s"
            params.append(agent_code)
        if month_year:
            sql += " AND `month_year`=%s"
            params.append(month_year)
        sql += " ORDER BY `UploadID` DESC LIMIT %s OFFSET %s"
        params += [limit, offset]
        with conn.cursor() as cur:
            cur.execute(sql, tuple(params))
            items = list(cur.fetchall() or [])
        return {"count": len(items), "items": items}
    finally:
        conn.close()

@router.get("/uploads.csv")
def list_uploads_csv(
    doc_type: Optional[str] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    data = list_uploads(
        doc_type=doc_type,
        agent_code=agent_code,
        month_year=month_year,
        limit=limit,
        offset=offset,
    )
    return _dicts_to_csv_stream(data.get("items", []), filename="uploads.csv")

@router.get("/uploads/tracker")
def uploads_tracker(agent_code: str, months_back: int = 36) -> Dict[str, Any]:
    conn = get_conn()
    items: List[Dict[str, Any]] = []
    try:
        with conn.cursor() as cur:
            sql = """
            SELECT m.`month_year`,
                   GREATEST(
                     IFNULL((SELECT MAX(CASE WHEN u.`doc_type`='STATEMENT' AND u.`is_active`=1 THEN 1 ELSE 0 END)
                             FROM `uploads` u
                             WHERE u.`agent_code`=%s AND u.`month_year`=m.`month_year`), 0),
                     IFNULL((SELECT MAX(1) FROM `statement` s
                             WHERE s.`agent_code`=%s AND s.`MONTH_YEAR`=m.`month_year`), 0)
                   ) AS `statement_present`,
                   GREATEST(
                     IFNULL((SELECT MAX(CASE WHEN u.`doc_type`='SCHEDULE' AND u.`is_active`=1 THEN 1 ELSE 0 END)
                             FROM `uploads` u
                             WHERE u.`agent_code`=%s AND u.`month_year`=m.`month_year`), 0),
                     IFNULL((SELECT MAX(1) FROM `schedule` sc
                             WHERE sc.`agent_code`=%s AND sc.`month_year`=m.`month_year`), 0)
                   ) AS `schedule_present`,
                   GREATEST(
                     IFNULL((SELECT MAX(CASE WHEN u.`doc_type`='TERMINATED' AND u.`is_active`=1 THEN 1 ELSE 0 END)
                             FROM `uploads` u
                             WHERE u.`agent_code`=%s AND u.`month_year`=m.`month_year`), 0),
                     IFNULL((SELECT MAX(1) FROM `terminated` t
                             WHERE t.`agent_code`=%s AND t.`month_year`=m.`month_year`), 0)
                   ) AS `terminated_present`,
                   (SELECT MAX(u.`UploadID`) FROM `uploads` u
                    WHERE u.`agent_code`=%s AND u.`month_year`=m.`month_year` AND u.`doc_type`='STATEMENT') AS `statement_upload_id`,
                   (SELECT MAX(u.`UploadID`) FROM `uploads` u
                    WHERE u.`agent_code`=%s AND u.`month_year`=m.`month_year` AND u.`doc_type`='SCHEDULE') AS `schedule_upload_id`,
                   (SELECT MAX(u.`UploadID`) FROM `uploads` u
                    WHERE u.`agent_code`=%s AND u.`month_year`=m.`month_year` AND u.`doc_type`='TERMINATED') AS `terminated_upload_id`
            FROM (
              SELECT DISTINCT u.`month_year`
              FROM `uploads` u
              WHERE u.`agent_code`=%s AND u.`month_year` IS NOT NULL
              UNION
              SELECT DISTINCT s.`MONTH_YEAR` AS `month_year`
              FROM `statement` s
              WHERE s.`agent_code`=%s AND s.`MONTH_YEAR` IS NOT NULL
              UNION
              SELECT DISTINCT sc.`month_year`
              FROM `schedule` sc
              WHERE sc.`agent_code`=%s AND sc.`month_year` IS NOT NULL
              UNION
              SELECT DISTINCT t.`month_year`
              FROM `terminated` t
              WHERE t.`agent_code`=%s AND t.`month_year` IS NOT NULL
            ) AS m
            ORDER BY STR_TO_DATE(CONCAT('01 ', m.`month_year`), '%%d %%b %%Y') DESC
            LIMIT %s
            """
            params = [
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                agent_code,
                months_back,
            ]
            cur.execute(sql, tuple(params))
            items = list(cur.fetchall() or [])
        return {"count": len(items), "items": items}
    finally:
        conn.close()

@router.get("/uploads/tracker.csv")
def uploads_tracker_csv(agent_code: str, months_back: int = 36) -> StreamingResponse:
    data = uploads_tracker(agent_code=agent_code, months_back=months_back)
    return _dicts_to_csv_stream(data.get("items", []), filename="uploads_tracker.csv")

@router.get("/statements")
def list_statements(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    conn = get_conn()
    items: List[Dict[str, Any]] = []
    try:
        base = """
        SELECT `statement_id`,`upload_id`,`agent_code`,`policy_no`,`holder`,
               `policy_type`,`pay_date`,`receipt_no`,`premium`,`com_rate`,
               `com_amt`,`inception`,`MONTH_YEAR` AS `month_year`,`AGENT_LICENSE_NUMBER`
        FROM `statement` WHERE 1=1
        """
        params: List[Any] = []
        if upload_id is not None:
            base += " AND `upload_id`=%s"
            params.append(upload_id)
        if agent_code:
            base += " AND `agent_code`=%s"
            params.append(agent_code)
        if month_year:
            base += " AND `MONTH_YEAR`=%s"
            params.append(month_year)
        if policy_no:
            base += " AND `policy_no`=%s"
            params.append(policy_no)
        base += " ORDER BY `statement_id` DESC LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        with conn.cursor() as cur:
            cur.execute(base, tuple(params))
            items = list(cur.fetchall() or [])
        for it in items:
            sur, other = _split_holder(it.get("holder"))
            it["holder_surname"] = sur
            it["other_name"] = other
        return {"count": len(items), "items": items}
    finally:
        conn.close()

@router.get("/statements.csv")
def list_statements_csv(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    data = list_statements(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )
    return _dicts_to_csv_stream(data.get("items", []), filename="statements.csv")

def _select_schedule_latest(conn, agent_code: str, limit: int, offset: int) -> List[Dict[str, Any]]:
    with conn.cursor() as cur:
        try:
            cur.execute(
                """
                SELECT sc.`month_year`, sc.`schedule_id`, sc.`upload_id`, sc.`agent_code`, sc.`agent_name`,
                       sc.`commission_batch_code`, sc.`total_premiums`, sc.`income`,
                       sc.`total_deductions`, sc.`net_commission`,
                       sc.`siclase`, sc.`premium_deduction`, sc.`pensions`, sc.`welfareko`
                FROM `schedule` sc
                JOIN (
                  SELECT `month_year`, MAX(`upload_id`) AS max_upload
                  FROM `schedule` WHERE `agent_code`=%s
                  GROUP BY `month_year`
                ) t ON sc.`month_year`=t.`month_year` AND sc.`upload_id`=t.`max_upload`
                ORDER BY STR_TO_DATE(CONCAT('01 ', sc.`month_year`), '%%d %%b %%Y') DESC
                LIMIT %s OFFSET %s
                """,
                (agent_code, limit, offset),
            )
            rows = list(cur.fetchall() or [])
        except Exception:
            cur.execute(
                """
                SELECT sc.`month_year`, sc.`schedule_id`, sc.`upload_id`, sc.`agent_code`, sc.`agent_name`,
                       sc.`commission_batch_code`, sc.`total_premiums`, sc.`income`,
                       sc.`total_deductions`, sc.`net_commission`
                FROM `schedule` sc
                JOIN (
                  SELECT `month_year`, MAX(`upload_id`) AS max_upload
                  FROM `schedule` WHERE `agent_code`=%s
                  GROUP BY `month_year`
                ) t ON sc.`month_year`=t.`month_year` AND sc.`upload_id`=t.`max_upload`
                ORDER BY STR_TO_DATE(CONCAT('01 ', sc.`month_year`), '%%d %%b %%Y') DESC
                LIMIT %s OFFSET %s
                """,
                (agent_code, limit, offset),
            )
            rows = list(cur.fetchall() or [])
            for r in rows:
                r["siclase"] = 0.0
                r["premium_deduction"] = 0.0
                r["pensions"] = 0.0
                r["welfareko"] = 0.0
        return rows

@router.get("/schedule")
def list_schedule(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    latest_only: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    eff_latest_int = 0
    if latest_only is None and agent_code:
        eff_latest_int = 1
    elif latest_only is not None:
        val = str(latest_only).strip()
        eff_latest_int = 0 if val == "" else int(bool(int(val)))
    conn = get_conn()
    items: List[Dict[str, Any]] = []
    try:
        with conn.cursor() as cur:
            if eff_latest_int and agent_code:
                items = _select_schedule_latest(conn, agent_code, limit, offset)
                return {"count": len(items), "items": items}
            try:
                base = """
                SELECT `month_year`,`schedule_id`,`upload_id`,`agent_code`,`agent_name`,
                       `commission_batch_code`,`total_premiums`,`income`,
                       `total_deductions`,`net_commission`,
                       `siclase`,`premium_deduction`,`pensions`,`welfareko`
                FROM `schedule` WHERE 1=1
                """
                params: List[Any] = []
                if upload_id is not None:
                    base += " AND `upload_id`=%s"
                    params.append(upload_id)
                if agent_code:
                    base += " AND `agent_code`=%s"
                    params.append(agent_code)
                if month_year:
                    base += " AND `month_year`=%s"
                    params.append(month_year)
                base += " ORDER BY `schedule_id` DESC LIMIT %s OFFSET %s"
                params.extend([limit, offset])
                cur.execute(base, tuple(params))
                items = list(cur.fetchall() or [])
            except Exception:
                base = """
                SELECT `month_year`,`schedule_id`,`upload_id`,`agent_code`,`agent_name`,
                       `commission_batch_code`,`total_premiums`,`income`,
                       `total_deductions`,`net_commission`
                FROM `schedule` WHERE 1=1
                """
                params = []
                if upload_id is not None:
                    base += " AND `upload_id`=%s"
                    params.append(upload_id)
                if agent_code:
                    base += " AND `agent_code`=%s"
                    params.append(agent_code)
                if month_year:
                    base += " AND `month_year`=%s"
                    params.append(month_year)
                base += " ORDER BY `schedule_id` DESC LIMIT %s OFFSET %s"
                params.extend([limit, offset])
                cur.execute(base, tuple(params))
                items = list(cur.fetchall() or [])
                for r in items:
                    r["siclase"] = 0.0
                    r["premium_deduction"] = 0.0
                    r["pensions"] = 0.0
                    r["welfareko"] = 0.0
        return {"count": len(items), "items": items}
    finally:
        conn.close()

@router.get("/schedule.csv")
def list_schedule_csv(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    latest_only: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    data = list_schedule(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        latest_only=latest_only,
        limit=limit,
        offset=offset,
    )
    return _dicts_to_csv_stream(data.get("items", []), filename="schedule.csv")

@router.get("/terminated")
def list_terminated(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    conn = get_conn()
    items: List[Dict[str, Any]] = []
    try:
        base = """
        SELECT `terminated_id`,`upload_id`,`agent_code`,`policy_no`,`holder`,
               `policy_type`,`premium`,`status`,`reason`,`month_year`,`termination_date`
        FROM `terminated` WHERE 1=1
        """
        params: List[Any] = []
        if upload_id is not None:
            base += " AND `upload_id`=%s"
            params.append(upload_id)
        if agent_code:
            base += " AND `agent_code`=%s"
            params.append(agent_code)
        if month_year:
            base += " AND `month_year`=%s"
            params.append(month_year)
        if policy_no:
            base += " AND `policy_no`=%s"
            params.append(policy_no)
        base += " ORDER BY `terminated_id` DESC LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        with conn.cursor() as cur:
            cur.execute(base, tuple(params))
            items = list(cur.fetchall() or [])
        for it in items:
            sur, other = _split_holder(it.get("holder"))
            it["holder_surname"] = sur
            it["other_name"] = other
        return {"count": len(items), "items": items}
    finally:
        conn.close()

@router.get("/terminated.csv")
def list_terminated_csv(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    data = list_terminated(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )
    return _dicts_to_csv_stream(data.get("items", []), filename="terminated.csv")

@router.get("/active-policies")
def list_active_policies(
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    conn = get_conn()
    items: List[Dict[str, Any]] = []
    try:
        base = """
        SELECT `id`,`agent_code`,`policy_no`,`policy_type`,`holder_name`,
               `inception_date`,`first_seen_date`,`last_seen_date`,`last_seen_month_year`,
               `last_premium`,`last_com_rate`,`status`,`consecutive_missing_months`
        FROM `active_policies` WHERE 1=1
        """
        params: List[Any] = []
        if agent_code:
            base += " AND `agent_code`=%s"
            params.append(agent_code)
        if month_year:
            base += " AND `last_seen_month_year`=%s"
            params.append(month_year)
        if status:
            base += " AND `status`=%s"
            params.append(status)
        base += " ORDER BY `id` DESC LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        with conn.cursor() as cur:
            cur.execute(base, tuple(params))
            items = list(cur.fetchall() or [])
        return {"count": len(items), "items": items}
    finally:
        conn.close()

@router.get("/active-policies.csv")
def list_active_policies_csv(
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    data = list_active_policies(
        agent_code=agent_code,
        month_year=month_year,
        status=status,
        limit=limit,
        offset=offset,
    )
    return _dicts_to_csv_stream(data.get("items", []), filename="active_policies.csv")

@router.post("/reports/generate-agent-month", dependencies=[Depends(require_csrf)])
def generate_agent_month(
    agent_code: str = Form(...),
    month_year: str = Form(...),
    upload_id: Optional[int] = Form(None),
) -> Dict[str, Any]:
    try:
        _ = _mr().compute_month_summary(agent_code, month_year)
        return {
            "status": "SUCCESS",
            "message": f"Monthly report successfully generated for {month_year}",
            "agent_code": agent_code,
            "month_year": month_year,
            "upload_id": upload_id,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/reports/commission-comparison")
def commission_comparison_admin(
    agent_code: str,
    month_year: str,
    upload_id: Optional[int] = None,
    include_raw: int = 0,
) -> Dict[str, Any]:
    try:
        mr = _mr()
        summary = mr.compute_month_summary(agent_code, month_year)
        comp = summary.get("commission_comparison", {}) or {}
        inputs = comp.get("inputs", {}) or {}
        tax_percent = inputs.get("tax_percent", 10.0)
        welfareko = inputs.get("welfareko", 0.0)
        siclase = inputs.get("siclase", 0.0)
        out: Dict[str, Any] = {
            "status": "OK",
            "inputs": {
                "agent_code": agent_code,
                "month_year": month_year,
                "upload_id": upload_id,
                "tax_percent": tax_percent,
                "welfareko": welfareko,
                "siclase": siclase,
            },
            "net": {
                "expected": comp.get("expected_net", 0.0),
                "statement": comp.get("statement_net", 0.0),
                "schedule": comp.get("schedule_net", 0.0),
            },
            "diffs_vs_expected": {
                "statement": (comp.get("diffs_vs_expected", {}) or {}).get(
                    "statement", {"amount": 0.0, "percent": 0.0}
                ),
                "schedule": (comp.get("diffs_vs_expected", {}) or {}).get(
                    "schedule", {"amount": 0.0, "percent": 0.0}
                ),
            },
        }
        if include_raw:
            try:
                comps_sched = mr._fetch_schedule_components(agent_code, month_year)  # noqa: SLF001
            except Exception:
                comps_sched = {}
            out["raw"] = {
                "totals": {
                    "total_expected": summary.get(
                        "total_commission_expected", 0.0
                    ),
                    "total_reported": summary.get(
                        "total_commission_reported", 0.0
                    ),
                    "variance_amount": summary.get("variance_amount", 0.0),
                    "variance_percentage": summary.get(
                        "variance_percentage", 0.0
                    ),
                },
                "schedule_components": {
                    "gov_tax": comps_sched.get("gov_tax", 0.0),
                    "siclase": comps_sched.get("siclase", 0.0),
                    "welfareko": comps_sched.get("welfareko", 0.0),
                    "premium_deductions": comps_sched.get(
                        "premium_deduction", 0.0
                    ),
                    "pensions": comps_sched.get("pensions", 0.0),
                    "total_deductions": comps_sched.get(
                        "total_deductions", 0.0
                    ),
                    "net_commission": comps_sched.get(
                        "net_commission", 0.0
                    ),
                },
                "notes": "Derived from compute_month_summary() + schedule components when available.",
            }
        return out
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/reports/commission-comparison.csv")
def commission_comparison_admin_csv(
    agent_code: str,
    month_year: str,
    upload_id: Optional[int] = None,
) -> StreamingResponse:
    mr = _mr()
    summary = mr.compute_month_summary(agent_code, month_year)
    comp = summary.get("commission_comparison", {}) or {}
    inputs = comp.get("inputs", {}) or {}
    row = {
        "agent_code": agent_code,
        "month_year": month_year,
        "upload_id": upload_id,
        "expected_net": comp.get("expected_net", 0.0),
        "statement_net": comp.get("statement_net", 0.0),
        "schedule_net": comp.get("schedule_net", 0.0),
        "statement_diff_amt": (comp.get("diffs_vs_expected", {}) or {})
        .get("statement", {})
        .get("amount", 0.0),
        "statement_diff_pct": (comp.get("diffs_vs_expected", {}) or {})
        .get("statement", {})
        .get("percent", 0.0),
        "schedule_diff_amt": (comp.get("diffs_vs_expected", {}) or {})
        .get("schedule", {})
        .get("amount", 0.0),
        "schedule_diff_pct": (comp.get("diffs_vs_expected", {}) or {})
        .get("schedule", {})
        .get("percent", 0.0),
        "tax_percent": inputs.get("tax_percent", 10.0),
        "welfareko": inputs.get("welfareko", 0.0),
        "siclase": inputs.get("siclase", 0.0),
        "total_expected": summary.get("total_commission_expected", 0.0),
        "total_reported": summary.get("total_commission_reported", 0.0),
        "variance_amount": summary.get("variance_amount", 0.0),
        "variance_percentage": summary.get("variance_percentage", 0.0),
    }
    headers = list(row.keys())
    return _dicts_to_csv_stream(
        [row],
        field_order=headers,
        filename="commission_comparison.csv",
    )
# ===== END FILE: api\admin_reports.py =====

################################################################################
# ===== FILE: api\admin_users.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\admin_users.py
# SIZE: 6,062 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from typing import Any, Dict, List, Optional

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel

from src.ingestion.db import get_conn
from src.services.auth_service import hash_password
from src.services.roles import require_role
from src.services.security import require_csrf


router = APIRouter(
    prefix="/api/admin/users",
    tags=["Admin Users"],
    dependencies=[Depends(require_role("admin"))],
)


class UserCreate(BaseModel):
    email: str
    role: str  # 'admin' | 'superuser' | 'agent'
    agent_code: Optional[str] = None
    is_active: int = 1
    password: str


class UserUpdate(BaseModel):
    email: Optional[str] = None
    role: Optional[str] = None
    agent_code: Optional[str] = None
    is_active: Optional[int] = None
    password: Optional[str] = None


@router.get("", summary="List users")
def list_users(limit: int = 200, offset: int = 0) -> Dict[str, Any]:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT `id`,`email`,`role`,`agent_code`,`is_active`,`last_login`
                FROM `users`
                ORDER BY `id` DESC
                LIMIT %s OFFSET %s
                """,
                (limit, offset),
            )
            items = list(cur.fetchall() or [])
        return {"count": len(items), "items": items}
    finally:
        conn.close()


@router.post("", summary="Create user", dependencies=[Depends(require_csrf)])
def create_user(payload: UserCreate) -> Dict[str, Any]:
    if not payload.password or not str(payload.password).strip():
        raise HTTPException(
            status_code=400,
            detail="Password is required when creating a user",
        )

    ac_norm: Optional[str] = None
    if payload.agent_code and str(payload.agent_code).strip():
        ac_norm = str(payload.agent_code).strip()

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            if str(payload.role).lower() == "agent":
                if not ac_norm:
                    raise HTTPException(
                        status_code=400,
                        detail="agent_code is required when role is 'agent'",
                    )
                cur.execute(
                    "SELECT 1 FROM `agents` WHERE `agent_code`=%s",
                    (ac_norm,),
                )
                exists = cur.fetchone()
                if not exists:
                    cur.execute(
                        """
                        INSERT INTO `agents`
                            (`agent_code`,`agent_name`,`is_active`,`created_at`,`updated_at`)
                        VALUES (%s,%s,%s,NOW(),NOW())
                        """,
                        (ac_norm, None, 1),
                    )

            pwd_hash = hash_password(payload.password)
            cur.execute(
                """
                INSERT INTO `users`
                    (`email`,`role`,`agent_code`,`is_active`,`password_hash`)
                VALUES (%s,%s,%s,%s,%s)
                """,
                (
                    str(payload.email),
                    payload.role,
                    ac_norm,
                    int(bool(payload.is_active)),
                    pwd_hash,
                ),
            )
            new_id = cur.lastrowid
        conn.commit()
        return {"status": "SUCCESS", "id": new_id}
    finally:
        conn.close()


@router.put(
    "/{user_id}",
    summary="Update user",
    dependencies=[Depends(require_csrf)],
)
def update_user(user_id: int, payload: UserUpdate) -> Dict[str, Any]:
    conn = get_conn()
    try:
        sets: List[str] = []
        vals: List[Any] = []

        if payload.email is not None:
            sets.append("`email`=%s")
            vals.append(str(payload.email))
        if payload.role is not None:
            sets.append("`role`=%s")
            vals.append(payload.role)
        if payload.agent_code is not None:
            ac_norm: Optional[str] = None
            if str(payload.agent_code).strip():
                ac_norm = str(payload.agent_code).strip()
            sets.append("`agent_code`=%s")
            vals.append(ac_norm)
        if payload.is_active is not None:
            sets.append("`is_active`=%s")
            vals.append(int(bool(payload.is_active)))
        if payload.password is not None:
            sets.append("`password_hash`=%s")
            vals.append(hash_password(payload.password))

        if not sets:
            return {"status": "NOOP", "id": user_id}

        sql = f"UPDATE `users` SET {', '.join(sets)} WHERE `id`=%s"
        vals.append(user_id)

        with conn.cursor() as cur:
            cur.execute(sql, tuple(vals))
        conn.commit()
        return {"status": "SUCCESS", "id": user_id}
    finally:
        conn.close()


@router.delete(
    "/{user_id}",
    summary="Deactivate user",
    dependencies=[Depends(require_csrf)],
)
def deactivate_user(user_id: int) -> Dict[str, Any]:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "UPDATE `users` SET `is_active`=0 WHERE `id`=%s",
                (user_id,),
            )
        conn.commit()
        return {"status": "SUCCESS", "id": user_id}
    finally:
        conn.close()


@router.post(
    "/{user_id}/password",
    summary="Set password",
    dependencies=[Depends(require_csrf)],
)
def set_password(user_id: int, payload: UserUpdate) -> Dict[str, Any]:
    if not payload.password:
        raise HTTPException(
            status_code=400,
            detail="Password is required",
        )

    conn = get_conn()
    try:
        hashed = hash_password(payload.password)
        with conn.cursor() as cur:
            cur.execute(
                "UPDATE `users` SET `password_hash`=%s WHERE `id`=%s",
                (hashed, user_id),
            )
        conn.commit()
        return {"status": "SUCCESS", "id": user_id}
    finally:
        conn.close()
# ===== END FILE: api\admin_users.py =====

################################################################################
# ===== FILE: api\agent_api.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\agent_api.py
# SIZE: 6,876 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from typing import Any, Dict, Optional

from fastapi import APIRouter, Depends, Request, HTTPException
from fastapi.responses import StreamingResponse

from src.api import admin_reports as admin
from src.services.roles import require_agent_user


router = APIRouter(
    prefix="/api/agent",
    tags=["Agent API"],
    dependencies=[Depends(require_agent_user)],
)


def _agent_code_from_user(user: Dict[str, Any]) -> str:
    ac = user.get("agent_code")
    if not isinstance(ac, str) or not ac.strip():
        raise HTTPException(
            status_code=400,
            detail="agent_code must be a non-empty string",
        )
    return ac.strip()


@router.get("/me")
def agent_me(current_user: Dict[str, Any] = Depends(require_agent_user)) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return {
        "status": "OK",
        "role": current_user.get("role"),
        "agent_code": agent_code,
    }


@router.get("/statements")
def statements_for_agent(
    request: Request,
    upload_id: Optional[int] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_statements(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )


@router.get("/statements.csv")
def statements_csv_for_agent(
    request: Request,
    upload_id: Optional[int] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> StreamingResponse:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_statements_csv(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )


@router.get("/uploads")
def uploads_for_agent(
    request: Request,
    doc_type: Optional[str] = None,
    month_year: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_uploads(
        doc_type=doc_type,
        agent_code=agent_code,
        month_year=month_year,
        limit=limit,
        offset=offset,
    )


@router.get("/schedule")
def schedule_for_agent(
    request: Request,
    upload_id: Optional[int] = None,
    month_year: Optional[str] = None,
    latest_only: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_schedule(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        latest_only=latest_only,
        limit=limit,
        offset=offset,
    )


@router.get("/schedule.csv")
def schedule_csv_for_agent(
    request: Request,
    upload_id: Optional[int] = None,
    month_year: Optional[str] = None,
    latest_only: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> StreamingResponse:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_schedule_csv(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        latest_only=latest_only,
        limit=limit,
        offset=offset,
    )


@router.get("/terminated")
def terminated_for_agent(
    request: Request,
    upload_id: Optional[int] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_terminated(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )


@router.get("/terminated.csv")
def terminated_csv_for_agent(
    request: Request,
    upload_id: Optional[int] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> StreamingResponse:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_terminated_csv(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )


@router.get("/active-policies")
def active_policies_for_agent(
    request: Request,
    month_year: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return admin.list_active_policies(
        agent_code=agent_code,
        month_year=month_year,
        status=status,
        limit=limit,
        offset=offset,
    )


@router.get("/missing")
def missing_for_agent(
    request: Request,
    month_year: str,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    from src.reports.monthly_reports import _fetch_missing_policies

    agent_code = _agent_code_from_user(current_user)
    try:
        raw = _fetch_missing_policies(agent_code, month_year)
        items: List[Dict[str, Any]] = []
        for r in raw:
            items.append(
                {
                    "policy_no": r.get("policy_no"),
                    "last_seen_month": r.get("last_seen_month"),
                    "last_premium": r.get("last_premium"),
                }
            )
        return {"count": len(items), "items": items}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/uploads/tracker")
def uploads_tracker_for_agent(
    request: Request,
    months_back: int = 36,
    current_user: Dict[str, Any] = Depends(require_agent_user),
) -> Dict[str, Any]:
    agent_code = _agent_code_from_user(current_user)
    return admin.uploads_tracker(agent_code=agent_code, months_back=months_back)
# ===== END FILE: api\agent_api.py =====

################################################################################
# ===== FILE: api\agent_missing.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\agent_missing.py
# SIZE: 4,252 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/agent_missing.py
from __future__ import annotations
from fastapi import APIRouter, HTTPException, Request, Depends
from fastapi.responses import StreamingResponse
from typing import Dict, Any, List, Optional, Tuple
import csv, io
from src.reports.monthly_reports import _fetch_missing_policies
from src.services.auth_service import decode_token, TOKEN_COOKIE_NAME
from src.ingestion.db import get_conn

router = APIRouter(prefix="/api/agent", tags=["Agent Missing (admin/superuser)"])

def _require_access(request: Request, agent_code: str):
    """
    Gate access:
    - agents: only their own agent_code
    - admin/superuser: any agent_code
    """
    tok = request.cookies.get(TOKEN_COOKIE_NAME)
    u = decode_token(tok) if tok else None
    if not u:
        raise HTTPException(status_code=403, detail="Authentication required")
    role = str((u.get("role") or "")).lower()
    if role == "agent":
        if str(u.get("agent_code") or "") != str(agent_code):
            raise HTTPException(status_code=403, detail="Agents may only access their own data")
        return u
    if role in ("admin", "superuser"):
        return u
    raise HTTPException(status_code=403, detail="Role not permitted")

def _split_holder(holder: Optional[str]) -> Tuple[str, str]:
    s = str(holder or "").strip()
    if not s:
        return "", ""
    parts = s.split()
    surname = parts[0]
    other = " ".join(parts[1:]) if len(parts) > 1 else ""
    return surname, other

def _fallback_active_row(policy_no: Optional[str]) -> Dict[str, Any]:
    """
    When _fetch_missing_policies doesn't provide holder/com_rate, try active_policies.
    """
    if not policy_no:
        return {}
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT `holder_name`,`last_com_rate` FROM `active_policies` WHERE `policy_no`=%s LIMIT 1",
                (policy_no,),
            )
            r = cur.fetchone() or {}
            return r
    finally:
        conn.close()

# NOTE: use a different path so we don't collide with /api/agent/missing
@router.get("/missing/by-agent")
def missing_by_agent(agent_code: str, month_year: str) -> Dict[str, Any]:
    try:
        raw = _fetch_missing_policies(agent_code, month_year)  # list of dicts
        items: List[Dict[str, Any]] = []
        for r in raw:
            policy_no = r.get("policy_no")
            holder_name = r.get("holder_name")
            last_com_rate = r.get("last_com_rate")
            if not (holder_name and last_com_rate is not None):
                fb = _fallback_active_row(policy_no)
                holder_name = holder_name or fb.get("holder_name")
                last_com_rate = last_com_rate if last_com_rate is not None else fb.get("last_com_rate")
            sur, other = _split_holder(holder_name)
            items.append(
                {
                    "policy_no": policy_no,
                    "holder_name": holder_name,
                    "holder_surname": sur,
                    "other_name": other,
                    "last_seen_month": r.get("last_seen_month"),
                    "last_premium": r.get("last_premium"),
                    "last_com_rate": last_com_rate,
                }
            )
        return {"count": len(items), "items": items}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/missing/by-agent.csv")
def missing_by_agent_csv(agent_code: str, month_year: str):
    try:
        res = missing_by_agent(agent_code=agent_code, month_year=month_year)
        rows: List[Dict[str, Any]] = res.get("items", []) if isinstance(res, dict) else []
        buf = io.StringIO()
        headers = ["policy_no","holder_name","holder_surname","other_name","last_seen_month","last_premium","last_com_rate"]
        writer = csv.DictWriter(buf, fieldnames=headers)
        writer.writeheader()
        for r in rows:
            writer.writerow(r)
        buf.seek(0)
        return StreamingResponse(buf, media_type="text/csv")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
# ===== END FILE: api\agent_missing.py =====

################################################################################
# ===== FILE: api\agent_reports.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\agent_reports.py
# SIZE: 13,453 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from decimal import Decimal
from mimetypes import guess_type
from pathlib import Path
from typing import Any, Dict, Optional, List

import csv
import io
import os
from fastapi import APIRouter, Form, HTTPException, Query
from fastapi.responses import FileResponse, StreamingResponse

from src.ingestion.commission import (
    compute_expected_for_upload_dynamic,
    insert_expected_rows,
)
from src.ingestion.db import get_conn
from src.reports.monthly_reports import (
    _period_key_from_month_year,
    build_csv_rows,
    compute_month_summary,
    local_and_gcs,
)

router = APIRouter(prefix="/api/agent", tags=["Agent Reports"])


def _active_upload_id(agent_code: str, month_year: str) -> Optional[int]:
    """
    Return the latest active STATEMENT upload_id for an agent+month_year, or None.
    This mirrors the logic used elsewhere for resolving the active statement upload.
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT `UploadID`
                FROM `uploads`
                WHERE `agent_code`=%s
                  AND `month_year`=%s
                  AND `doc_type`='STATEMENT'
                  AND `is_active`=1
                ORDER BY `UploadID` DESC
                LIMIT 1
                """,
                (agent_code, month_year),
            )
            r = cur.fetchone() or {}
            return r.get("UploadID")
    finally:
        conn.close()


def _insert_monthly_report_row(
    conn,
    agent_code: str,
    agent_name: str,
    report_period: str,
    upload_id: Optional[int],
    summary: dict,
    pdf_path: Optional[str],
) -> int:
    from datetime import datetime as _dt
    import os as _os

    # Totals derived from the commission grid (net reported vs expected)
    commission = summary.get("commission", {}) or {}
    reported = commission.get("reported", {}) or {}
    expected = commission.get("expected", {}) or {}

    total_reported = Decimal(str(reported.get("net", 0.0)))
    total_expected = Decimal(str(expected.get("net", 0.0)))
    variance_amount = total_reported - total_expected
    variance_percentage = Decimal("0.00")
    if total_expected != Decimal("0.00"):
        variance_percentage = (
            variance_amount / total_expected * Decimal("100")
        ).quantize(Decimal("0.01"))

    # Enriched counts from compute_month_summary
    audit_counts = summary.get("audit_counts", {}) or {}
    missing_policies_count = len(summary.get("missing_all", []) or [])
    commission_mismatches_count = int(audit_counts.get("commission_mismatches", 0) or 0)
    data_quality_issues_count = int(audit_counts.get("data_quality_issues", 0) or 0)
    terminated_policies_count = int(
        audit_counts.get("terminated_policies_in_month", 0) or 0
    )

    overall_status = "OK"
    if (
        missing_policies_count > 0
        or terminated_policies_count > 0
        or data_quality_issues_count > 0
    ):
        overall_status = "ATTENTION"

    now_dt = _dt.now().strftime("%Y-%m-%d %H:%M:%S")
    pdf_size = 0
    try:
        pdf_size = _os.path.getsize(pdf_path) if pdf_path else 0
    except Exception:
        pdf_size = 0

    sql = """
    INSERT INTO `monthly_reports`
    (`agent_code`,`agent_name`,`report_period`,`upload_id`,
     `policies_reported`,`total_premium`,`total_commission_reported`,
     `total_commission_expected`,`variance_amount`,`variance_percentage`,
     `missing_policies_count`,`commission_mismatches_count`,`data_quality_issues_count`,
     `terminated_policies_count`,`overall_status`,`report_html`,
     `report_pdf_path`,`report_pdf_s3_url`,`report_pdf_size_bytes`,
     `report_pdf_generated_at`,`generated_at`)
    VALUES
    (%s,%s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s)
    """
    with conn.cursor() as cur:
        cur.execute(
            sql,
            (
                agent_code,
                agent_name,
                report_period,
                upload_id,
                int(summary.get("policies_reported", 0)),
                float(summary.get("total_premium_reported", 0.0)),
                float(total_reported),
                float(total_expected),
                float(variance_amount),
                float(variance_percentage),
                missing_policies_count,
                commission_mismatches_count,
                data_quality_issues_count,
                terminated_policies_count,
                overall_status,
                None,  # report_html (unused)
                pdf_path or None,
                None,  # report_pdf_s3_url (unused)
                int(pdf_size),
                now_dt if pdf_path else None,
                now_dt,
            ),
        )
        conn.commit()
    return 1


@router.post("/reports/generate")
def generate_report(
    agent_code: str = Form(...),
    month_year: str = Form(...),
    upload_id: Optional[int] = Form(None),  # optional
    agent_name: Optional[str] = Form(None),
    out: Optional[str] = Form(None),
    user_id: Optional[int] = Form(None),
    skip_pdf: bool = Form(False),
    dry_run: bool = Form(False),
) -> Dict[str, Any]:
    """
    Agent-facing monthly report generation.

    Steps:
    - Resolve upload_id if missing (latest active STATEMENT upload for agent+month).
    - Compute expected commission rows for this upload (from dynamic rules).
    - Compute the month summary (commission grid + discrepancies).
    - Generate PDF (unless skip_pdf).
    - Insert a row into monthly_reports.
    - Emit discrepancies (best effort).
    """
    # Resolve upload_id (latest active statement upload for agent+month if not provided)
    resolved_upload_id = upload_id if upload_id is not None else _active_upload_id(
        agent_code, month_year
    )

    # Compute dynamic expected commissions for this upload (if present)
    rows = []
    inserted = 0
    if resolved_upload_id is not None:
        rows = compute_expected_for_upload_dynamic(resolved_upload_id)
        rows_agent = [r for r in rows if r.get("agent_code") == agent_code]
        if not dry_run:
            inserted = insert_expected_rows(rows_agent)

    # Compute the enriched summary
    summary = compute_month_summary(agent_code, month_year)

    # Output directory from env or form param
    reports_dir = Path(out or os.getenv("REPORTS_DIR", "reports"))
    pdf_meta: Optional[Dict[str, Any]] = None
    if not skip_pdf:
        try:
            pdf_meta = local_and_gcs(
                agent_code, agent_name or agent_code, month_year, reports_dir, user_id
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    # Insert monthly_reports row
    report_period = _period_key_from_month_year(month_year) or month_year.replace(
        "COM_", ""
    ).replace(" ", "-")
    conn = get_conn()
    try:
        _insert_monthly_report_row(
            conn,
            agent_code,
            agent_name or agent_code,
            report_period,
            resolved_upload_id,
            summary,
            (pdf_meta or {}).get("pdf_path") if pdf_meta else None,
        )
    finally:
        conn.close()

    # Best-effort discrepancies emission (non-fatal)
    try:
        from src.audit.discrepancies import emit_discrepancies_for_month

        emit_discrepancies_for_month(agent_code, month_year)
    except Exception:
        pass

    return {
        "status": "SUCCESS",
        "agent_code": agent_code,
        "agent_name": agent_name or agent_code,
        "month_year": month_year,
        "report_period": report_period,
        "upload_id_used": resolved_upload_id,
        "expected_rows_inserted": inserted,
        "pdf": pdf_meta or None,
        "summary": summary,
    }


@router.get("/reports")
def list_reports(agent_code: str, month_year: str) -> Dict[str, Any]:
    conn = get_conn()
    try:
        period = _period_key_from_month_year(month_year) or month_year.replace(
            "COM_", ""
        ).replace(" ", "-")
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT `report_id`,`report_period`,`upload_id`,
                       `report_pdf_path`,`report_pdf_size_bytes`,`generated_at`
                FROM `monthly_reports`
                WHERE `agent_code`=%s AND `report_period`=%s
                ORDER BY `report_id` DESC
                """,
                (agent_code, period),
            )
            rows = cur.fetchall() or []
        return {"count": len(rows), "items": rows}
    finally:
        conn.close()


@router.get("/reports/download/{report_id}")
def download_report(report_id: int) -> FileResponse:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT `report_pdf_path` FROM `monthly_reports` WHERE `report_id`=%s",
                (report_id,),
            )
            r = cur.fetchone() or {}
        pdf_path = r.get("report_pdf_path")
        if not pdf_path:
            raise HTTPException(status_code=404, detail="PDF path not found for report")
        p = Path(str(pdf_path))
        if not p.exists():
            raise HTTPException(status_code=404, detail="PDF file not found on disk")
        mt, _ = guess_type(p.name)  # should be application/pdf
        return FileResponse(
            path=str(p), media_type=mt or "application/octet-stream", filename=p.name
        )
    finally:
        conn.close()


@router.get("/reports/export-csv")
def export_report_csv(
    agent_code: str, month_year: str, agent_name: Optional[str] = None
) -> StreamingResponse:
    """
    Export the Monthly Report as CSV, aligned to the Book1.csv-style template.
    """
    try:
        rows = build_csv_rows(agent_code, agent_name or agent_code, month_year)
        buf = io.StringIO()
        writer = csv.writer(buf)
        for r in rows:
            writer.writerow(r)
        buf.seek(0)

        period = _period_key_from_month_year(month_year) or month_year.replace(
            "COM_", ""
        ).replace(" ", "-")
        filename = f"ICRS_{agent_code}_{period}.csv"

        headers = {
            "Content-Type": "text/csv; charset=utf-8",
            "Content-Disposition": f'attachment; filename="{filename}"',
        }
        return StreamingResponse(buf, headers=headers)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# 
# Simple Summary for Agent Dashboard: Active policies + policy type counts
# 


@router.get("/summary")
def agent_summary(
    agent_code: str = Query(..., description="Agent code"),
    month_year: Optional[str] = Query(
        None,
        description=(
            "Optional month label (e.g., 'Jun 2025'). When provided, counts are "
            "restricted to active_policies.last_seen_month_year = this value."
        ),
    ),
) -> Dict[str, Any]:
    """
    Simple summary for the agent dashboard.

    Returns JSON like:
    {
      "agent_code": "...",
      "month_year": "Jun 2025",
      "active_policies_total": 123,
      "policy_type_counts": {
        "EDUCATION": 23,
        "MOTOR": 7,
        "UNKNOWN": 3
      }
    }
    """
    conn = get_conn()
    try:
        params: List[Any] = [agent_code]
        where = "WHERE `agent_code`=%s AND `status`='ACTIVE'"

        if month_year:
            where += " AND `last_seen_month_year`=%s"
            params.append(month_year)

        sql_total = f"""
            SELECT COUNT(*) AS cnt
            FROM `active_policies`
            {where}
        """
        sql_by_type = f"""
            SELECT `policy_type`, COUNT(*) AS cnt
            FROM `active_policies`
            {where}
            GROUP BY `policy_type`
            ORDER BY `policy_type` ASC
        """

        with conn.cursor() as cur:
            cur.execute(sql_total, tuple(params))
            r_total = cur.fetchone() or {}
            total = int(r_total.get("cnt") or 0)

            cur.execute(sql_by_type, tuple(params))
            rows = list(cur.fetchall() or [])

        type_counts: Dict[str, int] = {}
        for r in rows:
            pt = (r.get("policy_type") or "").strip() or "UNKNOWN"
            type_counts[pt] = int(r.get("cnt") or 0)

        return {
            "agent_code": agent_code,
            "month_year": month_year,
            "active_policies_total": total,
            "policy_type_counts": type_counts,
        }
    finally:
        conn.close()
# ===== END FILE: api\agent_reports.py =====

################################################################################
# ===== FILE: api\auth_api copy.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\auth_api copy.py
# SIZE: 8,766 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/auth_api.py
from __future__ import annotations
from typing import Dict, Any, Literal, cast
from fastapi import APIRouter, HTTPException, Form, Request
from fastapi.responses import JSONResponse
from src.ingestion.db import get_conn
from src.services.auth_service import (
    create_token, decode_token, verify_password, TOKEN_COOKIE_NAME
)
import os

router = APIRouter(prefix="/api/auth", tags=["Auth"])

# Cookie defaults (configurable via env)
DEFAULT_AUTH_EXP_MINUTES: int = int(os.getenv("AUTH_EXP_MINUTES", "10080"))  # 7 days
AUTH_COOKIE_SECURE = bool(int(os.getenv("AUTH_COOKIE_SECURE", "0")))        # 0/1
AUTH_COOKIE_SAMESITE_ENV = os.getenv("AUTH_COOKIE_SAMESITE", "lax").lower() # lax|strict|none

def _normalize_samesite(val: str) -> Literal['lax', 'strict', 'none']:
    v = val.lower().strip()
    if v == 'strict':
        return cast(Literal['strict'], 'strict')
    if v == 'none':
        return cast(Literal['none'], 'none')
    return cast(Literal['lax'], 'lax')

def _set_cookie(resp: JSONResponse, token: str) -> None:
    resp.set_cookie(
        key=TOKEN_COOKIE_NAME,
        value=token,
        httponly=True,
        samesite=_normalize_samesite(AUTH_COOKIE_SAMESITE_ENV),
        secure=AUTH_COOKIE_SECURE,
        max_age=DEFAULT_AUTH_EXP_MINUTES * 60,
        path="/",
    )

# -----------------------------------------------------------------------------
# AGENT LOGIN  option A: Agent Code + Password
# -----------------------------------------------------------------------------
@router.post("/login/agent")
def login_agent_by_agent_code(
    agent_code: str = Form(...),
    password: str = Form(...),
) -> JSONResponse:
    """
    Agents login using AGENT CODE + PASSWORD.
    We locate the latest active user bound to that agent_code with role='agent'.
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT * FROM `users` WHERE `agent_code`=%s AND `role`='agent' ORDER BY `id` DESC LIMIT 1",
                (agent_code,)
            )
            u = cur.fetchone() or None
            if not u:
                raise HTTPException(status_code=404, detail="Agent user not found")
            if int(u.get("is_active") or 0) != 1:
                raise HTTPException(status_code=403, detail="User inactive")

            ph = u.get("password_hash") or ""
            if not verify_password(password, ph):
                raise HTTPException(status_code=401, detail="Invalid credentials")

            # Update last_login
            with conn.cursor() as cur2:
                cur2.execute("UPDATE `users` SET `last_login`=NOW() WHERE `id`=%s", (u["id"],))
                conn.commit()

            payload: Dict[str, Any] = {
                "role": "agent",
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            }
            token = create_token(payload, DEFAULT_AUTH_EXP_MINUTES)
            resp = JSONResponse({
                "status": "OK",
                "role": "agent",
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            })
            _set_cookie(resp, token)
            return resp
    finally:
        conn.close()

# -----------------------------------------------------------------------------
# AGENT LOGIN  option B: User ID + Password
# -----------------------------------------------------------------------------
@router.post("/login/agent-user")
def login_agent_by_user_id(
    user_id: int = Form(...),
    password: str = Form(...),
) -> JSONResponse:
    """
    Agents login using USER ID + PASSWORD (role must be 'agent').
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM `users` WHERE `id`=%s", (user_id,))
            u = cur.fetchone() or None
            if not u:
                raise HTTPException(status_code=404, detail="User not found")
            if int(u.get("is_active") or 0) != 1:
                raise HTTPException(status_code=403, detail="User inactive")

            role = str(u.get("role") or "").lower()
            if role != "agent":
                raise HTTPException(status_code=403, detail="Role not permitted (requires agent)")

            ph = u.get("password_hash") or ""
            if not verify_password(password, ph):
                raise HTTPException(status_code=401, detail="Invalid credentials")

            with conn.cursor() as cur2:
                cur2.execute("UPDATE `users` SET `last_login`=NOW() WHERE `id`=%s", (u["id"],))
                conn.commit()

            payload: Dict[str, Any] = {
                "role": "agent",
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            }
            token = create_token(payload, DEFAULT_AUTH_EXP_MINUTES)
            resp = JSONResponse({
                "status": "OK",
                "role": "agent",
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            })
            _set_cookie(resp, token)
            return resp
    finally:
        conn.close()

# -----------------------------------------------------------------------------
# ADMIN & SUPERUSER LOGIN  User ID + Password only
# -----------------------------------------------------------------------------
@router.post("/login/user")
def login_admin_or_superuser(
    user_id: int = Form(...),
    password: str = Form(...),
) -> JSONResponse:
    """
    Admin/Superuser login using USER ID + PASSWORD.
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM `users` WHERE `id`=%s", (user_id,))
            u = cur.fetchone() or None
            if not u:
                raise HTTPException(status_code=404, detail="User not found")
            if int(u.get("is_active") or 0) != 1:
                raise HTTPException(status_code=403, detail="User inactive")

            role = str(u.get("role") or "").lower()
            if role not in ("admin", "superuser"):
                raise HTTPException(status_code=403, detail="Role not permitted")

            ph = u.get("password_hash") or ""
            if not verify_password(password, ph):
                raise HTTPException(status_code=401, detail="Invalid credentials")

            with conn.cursor() as cur2:
                cur2.execute("UPDATE `users` SET `last_login`=NOW() WHERE `id`=%s", (u["id"],))
                conn.commit()

            payload: Dict[str, Any] = {
                "role": role,
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            }
            token = create_token(payload, DEFAULT_AUTH_EXP_MINUTES)
            resp = JSONResponse({
                "status": "OK",
                "role": role,
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            })
            _set_cookie(resp, token)
            return resp
    finally:
        conn.close()

# -----------------------------------------------------------------------------
# Logout & Identity
# -----------------------------------------------------------------------------
@router.post("/logout")
def logout_post() -> JSONResponse:
    resp = JSONResponse({"status": "OK", "message": "Logged out"})
    resp.delete_cookie(TOKEN_COOKIE_NAME, path="/")
    return resp

@router.get("/logout")
def logout_get() -> JSONResponse:
    resp = JSONResponse({"status": "OK", "message": "Logged out"})
    resp.delete_cookie(TOKEN_COOKIE_NAME, path="/")
    return resp

@router.get("/me")
def me(request: Request) -> Dict[str, Any]:
    token = request.cookies.get(TOKEN_COOKIE_NAME)
    if not token:
        return {"status": "ANON"}
    payload = decode_token(token)
    if not payload:
        return {"status": "INVALID"}
    return {"status": "OK", "identity": payload}
# ===== END FILE: api\auth_api copy.py =====

################################################################################
# ===== FILE: api\auth_api.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\auth_api.py
# SIZE: 10,503 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from typing import Dict, Any, Literal, cast

from fastapi import APIRouter, HTTPException, Form, Request, Depends
from fastapi.responses import JSONResponse, RedirectResponse
import os

from src.ingestion.db import get_conn
from src.services.auth_service import (
    create_token,
    decode_token,
    verify_and_upgrade_password,
    TOKEN_COOKIE_NAME,
)
from src.services.security import (
    check_login_rate_limit,
    register_login_failure,
    reset_login_attempts,
    issue_csrf_token,
    require_csrf,
)

router = APIRouter(prefix="/api/auth", tags=["Auth"])

# Cookie defaults (configurable via env)
DEFAULT_AUTH_EXP_MINUTES: int = int(os.getenv("AUTH_EXP_MINUTES", "10080"))  # 7 days
AUTH_COOKIE_SECURE = bool(int(os.getenv("AUTH_COOKIE_SECURE", "0")))  # 0/1
AUTH_COOKIE_SAMESITE_ENV = os.getenv("AUTH_COOKIE_SAMESITE", "lax").lower()  # lax|strict|none


def _normalize_samesite(val: str) -> Literal["lax", "strict", "none"]:
    v = val.lower().strip()
    if v == "strict":
        return cast(Literal["strict"], "strict")
    if v == "none":
        return cast(Literal["none"], "none")
    return cast(Literal["lax"], "lax")


def _set_cookie(resp: JSONResponse | RedirectResponse, token: str) -> None:
    resp.set_cookie(
        key=TOKEN_COOKIE_NAME,
        value=token,
        httponly=True,
        samesite=_normalize_samesite(AUTH_COOKIE_SAMESITE_ENV),
        secure=AUTH_COOKIE_SECURE,
        max_age=DEFAULT_AUTH_EXP_MINUTES * 60,
        path="/",
    )


# ---------- CSRF ----------


@router.get("/csrf")
def get_csrf() -> JSONResponse:
    token = issue_csrf_token()
    resp = JSONResponse({"status": "OK", "csrf_token": token})
    # not HttpOnly so JS can read and set X-CSRF-Token
    resp.set_cookie(
        "csrf_token",
        token,
        httponly=False,
        samesite=_normalize_samesite(AUTH_COOKIE_SAMESITE_ENV),
        secure=AUTH_COOKIE_SECURE,
        path="/",
    )
    return resp


# ---------- AGENT LOGIN  Agent Code + Password ----------


@router.post("/login/agent")
def login_agent_by_agent_code(
    request: Request,
    agent_code: str = Form(...),
    password: str = Form(...),
    _=Depends(require_csrf),
) -> JSONResponse:
    # Ensure test expectations: missing fields -> 422, not 403/429
    if not agent_code or not password:
        raise HTTPException(status_code=422, detail="agent_code and password are required")

    user_key = f"agent:{agent_code}"
    check_login_rate_limit(request, user_key)

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT * FROM `users` WHERE `agent_code`=%s AND `role`='agent' ORDER BY `id` DESC LIMIT 1",
                (agent_code,),
            )
            u = cur.fetchone() or None
        if not u:
            register_login_failure(user_key)
            raise HTTPException(status_code=404, detail="Agent user not found")
        if int(u.get("is_active") or 0) != 1:
            register_login_failure(user_key)
            raise HTTPException(status_code=403, detail="User inactive")

        ph: str = u.get("password_hash") or ""
        ok, maybe_new_hash = verify_and_upgrade_password(password, ph)
        if not ok:
            register_login_failure(user_key)
            raise HTTPException(status_code=401, detail="Invalid credentials")

        with conn.cursor() as cur2:
            if maybe_new_hash:
                cur2.execute(
                    "UPDATE `users` SET `password_hash`=%s, `last_login`=NOW() WHERE `id`=%s",
                    (maybe_new_hash, u["id"]),
                )
            else:
                cur2.execute("UPDATE `users` SET `last_login`=NOW() WHERE `id`=%s", (u["id"],))
        conn.commit()

        payload: Dict[str, Any] = {
            "role": "agent",
            "user_id": int(u["id"]),
            "user_email": u.get("email"),
            "agent_code": u.get("agent_code"),
            "agent_name": u.get("agent_name"),
        }
        token = create_token(payload, DEFAULT_AUTH_EXP_MINUTES)
        resp = JSONResponse(
            {
                "status": "OK",
                "role": "agent",
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            }
        )
        _set_cookie(resp, token)
        reset_login_attempts(user_key)
        return resp
    finally:
        conn.close()


# ---------- AGENT LOGIN  User ID + Password ----------


@router.post("/login/agent-user")
def login_agent_by_user_id(
    request: Request,
    user_id: int = Form(...),
    password: str = Form(...),
    _=Depends(require_csrf),
) -> JSONResponse:
    if not user_id or not password:
        raise HTTPException(status_code=422, detail="user_id and password are required")

    user_key = f"user:{user_id}"
    check_login_rate_limit(request, user_key)

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM `users` WHERE `id`=%s", (user_id,))
            u = cur.fetchone() or None
        if not u:
            register_login_failure(user_key)
            raise HTTPException(status_code=404, detail="User not found")
        if int(u.get("is_active") or 0) != 1:
            register_login_failure(user_key)
            raise HTTPException(status_code=403, detail="User inactive")
        if str(u.get("role") or "").lower() != "agent":
            register_login_failure(user_key)
            raise HTTPException(status_code=403, detail="Role not permitted (requires agent)")

        ph = u.get("password_hash") or ""
        ok, maybe_new_hash = verify_and_upgrade_password(password, ph)
        if not ok:
            register_login_failure(user_key)
            raise HTTPException(status_code=401, detail="Invalid credentials")

        with conn.cursor() as cur2:
            if maybe_new_hash:
                cur2.execute(
                    "UPDATE `users` SET `password_hash`=%s, `last_login`=NOW() WHERE `id`=%s",
                    (maybe_new_hash, u["id"]),
                )
            else:
                cur2.execute("UPDATE `users` SET `last_login`=NOW() WHERE `id`=%s", (u["id"],))
        conn.commit()

        payload: Dict[str, Any] = {
            "role": "agent",
            "user_id": int(u["id"]),
            "user_email": u.get("email"),
            "agent_code": u.get("agent_code"),
            "agent_name": u.get("agent_name"),
        }
        token = create_token(payload, DEFAULT_AUTH_EXP_MINUTES)
        resp = JSONResponse(
            {
                "status": "OK",
                "role": "agent",
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            }
        )
        _set_cookie(resp, token)
        reset_login_attempts(user_key)
        return resp
    finally:
        conn.close()


# ---------- ADMIN & SUPERUSER LOGIN  User ID + Password ----------


@router.post("/login/user")
def login_admin_or_superuser(
    request: Request,
    user_id: int = Form(...),
    password: str = Form(...),
    _=Depends(require_csrf),
) -> JSONResponse:
    if not user_id or not password:
        raise HTTPException(status_code=422, detail="user_id and password are required")

    user_key = f"user:{user_id}"
    check_login_rate_limit(request, user_key)

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM `users` WHERE `id`=%s", (user_id,))
            u = cur.fetchone() or None
        if not u:
            register_login_failure(user_key)
            raise HTTPException(status_code=404, detail="User not found")
        if int(u.get("is_active") or 0) != 1:
            register_login_failure(user_key)
            raise HTTPException(status_code=403, detail="User inactive")

        role = str(u.get("role") or "").lower()
        if role not in ("admin", "superuser"):
            register_login_failure(user_key)
            raise HTTPException(status_code=403, detail="Role not permitted")

        ph = u.get("password_hash") or ""
        ok, maybe_new_hash = verify_and_upgrade_password(password, ph)
        if not ok:
            register_login_failure(user_key)
            raise HTTPException(status_code=401, detail="Invalid credentials")

        with conn.cursor() as cur2:
            if maybe_new_hash:
                cur2.execute(
                    "UPDATE `users` SET `password_hash`=%s, `last_login`=NOW() WHERE `id`=%s",
                    (maybe_new_hash, u["id"]),
                )
            else:
                cur2.execute("UPDATE `users` SET `last_login`=NOW() WHERE `id`=%s", (u["id"],))
        conn.commit()

        payload: Dict[str, Any] = {
            "role": role,
            "user_id": int(u["id"]),
            "user_email": u.get("email"),
            "agent_code": u.get("agent_code"),
            "agent_name": u.get("agent_name"),
        }
        token = create_token(payload, DEFAULT_AUTH_EXP_MINUTES)
        resp = JSONResponse(
            {
                "status": "OK",
                "role": role,
                "user_id": int(u["id"]),
                "user_email": u.get("email"),
                "agent_code": u.get("agent_code"),
                "agent_name": u.get("agent_name"),
            }
        )
        _set_cookie(resp, token)
        reset_login_attempts(user_key)
        return resp
    finally:
        conn.close()


# ---------- Logout & Identity ----------


@router.post("/logout")
def logout_post() -> RedirectResponse:
    resp = RedirectResponse(url="/ui/", status_code=303)
    resp.delete_cookie(TOKEN_COOKIE_NAME, path="/")
    return resp


@router.get("/logout")
def logout_get() -> RedirectResponse:
    resp = RedirectResponse(url="/ui/", status_code=302)
    resp.delete_cookie(TOKEN_COOKIE_NAME, path="/")
    return resp


@router.get("/me")
def me(request: Request) -> JSONResponse:
    token = request.cookies.get(TOKEN_COOKIE_NAME)
    if not token:
        return JSONResponse(status_code=401, content={"status": "ANON"})
    payload = decode_token(token)
    if not payload:
        return JSONResponse(status_code=401, content={"status": "INVALID"})
    return JSONResponse(status_code=200, content={"status": "OK", "identity": payload})
# ===== END FILE: api\auth_api.py =====

################################################################################
# ===== FILE: api\disparities.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\disparities.py
# SIZE: 5,592 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/disparities.py
from __future__ import annotations
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from typing import Dict, Any, List
from datetime import datetime, date
from calendar import monthrange
import csv, io
from src.ingestion.db import get_conn

router = APIRouter(prefix="/api/disparities", tags=["Disparities"])

def _parse_month_year(label: str) -> date:
    parts = (label or "").split()
    months = {"Jan":1,"Feb":2,"Mar":3,"Apr":4,"May":5,"Jun":6,"Jul":7,"Aug":8,"Sep":9,"Oct":10,"Nov":11,"Dec":12}
    if len(parts) != 2 or parts[0] not in months:
        raise ValueError("Month label not recognized. Use 'Mon YYYY', e.g. 'Jun 2025'.")
    y = int(parts[1]); m = months[parts[0]]
    return date(y, m, 1)

@router.get("/pay-date")
def pay_date_disparities(agent_code: str, month_year: str) -> Dict[str, Any]:
    try:
        start = _parse_month_year(month_year)
        end = date(start.year, start.month, monthrange(start.year, start.month)[1])
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT `policy_no`,`holder`,`pay_date`,`premium`,`MONTH_YEAR`
                FROM `statement`
                WHERE `agent_code`=%s AND `MONTH_YEAR`=%s
                ORDER BY `pay_date` DESC
            """, (agent_code, month_year))
            rows = cur.fetchall() or []

        disparities: List[Dict[str, Any]] = []
        total_premium_affected = 0.0
        future_dated_count = 0
        past_dated_count = 0

        for r in rows:
            pay_val = r.get('pay_date')
            pd: date
            try:
                if isinstance(pay_val, date):
                    pd = pay_val
                else:
                    s = str(pay_val or "")
                    if "-" in s:
                        pd = datetime.strptime(s[:10], "%Y-%m-%d").date()
                    elif "/" in s:
                        pd = datetime.strptime(s[:10], "%d/%m/%Y").date()
                    else:
                        continue
            except Exception:
                continue

            if not (start <= pd <= end):
                days_diff = (pd - end).days
                prem = float(r.get('premium') or 0.0)
                total_premium_affected += prem
                if days_diff > 0: future_dated_count += 1
                else: past_dated_count += 1
                disparities.append({
                    "policy_no": r.get('policy_no'),
                    "holder_name": r.get('holder'),
                    "premium": prem,
                    "expected_month": month_year,
                    "pay_date": pd.isoformat(),
                    "days_difference": days_diff
                })

        return {
            "summary": {
                "total_disparities": len(disparities),
                "future_dated_count": future_dated_count,
                "past_dated_count": past_dated_count,
                "total_premium_affected": round(total_premium_affected, 2)
            },
            "disparities": disparities
        }
    finally:
        conn.close()

@router.get("/pay-date.csv")
def pay_date_disparities_csv(agent_code: str, month_year: str):
    try:
        start = _parse_month_year(month_year)
        end = date(start.year, start.month, monthrange(start.year, start.month)[1])
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT `policy_no`,`holder`,`pay_date`,`premium`,`MONTH_YEAR`
                FROM `statement`
                WHERE `agent_code`=%s AND `MONTH_YEAR`=%s
                ORDER BY `pay_date` DESC
            """, (agent_code, month_year))
            rows = cur.fetchall() or []

        disparities: List[Dict[str, Any]] = []
        for r in rows:
            pay_val = r.get('pay_date')
            pd: date
            try:
                if isinstance(pay_val, date):
                    pd = pay_val
                else:
                    s = str(pay_val or "")
                    if "-" in s:
                        pd = datetime.strptime(s[:10], "%Y-%m-%d").date()
                    elif "/" in s:
                        pd = datetime.strptime(s[:10], "%d/%m/%Y").date()
                    else:
                        continue
            except Exception:
                continue

            if not (start <= pd <= end):
                days_diff = (pd - end).days
                prem = float(r.get('premium') or 0.0)
                disparities.append({
                    "policy_no": r.get('policy_no'),
                    "holder_name": r.get('holder'),
                    "premium": prem,
                    "expected_month": month_year,
                    "pay_date": pd.isoformat(),
                    "days_difference": days_diff
                })

        buf = io.StringIO()
        headers = ["policy_no","holder_name","premium","expected_month","pay_date","days_difference"]
        writer = csv.DictWriter(buf, fieldnames=headers)
        writer.writeheader()
        for d in disparities:
            writer.writerow(d)
        buf.seek(0)
        return StreamingResponse(buf, media_type="text/csv")
    finally:
        conn.close()
# ===== END FILE: api\disparities.py =====

################################################################################
# ===== FILE: api\ingestion_api.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\ingestion_api.py
# SIZE: 12,527 bytes
# ENCODING: utf-8
# ===== START =====
# pyright: reportCallIssue=false
# src/api/ingestion_api.py
from __future__ import annotations

from pathlib import Path
from typing import Dict, Any, List, Optional

from fastapi import APIRouter, HTTPException, UploadFile, File, Form

from src.ingestion.parser_db_integration import ParserDBIntegration
from src.ingestion.run_logger import RunLogger
from src.ingestion.commission import compute_expected_for_upload_dynamic, insert_expected_rows

# Import the parser module once; resolve and call inside a wrapper.
import src.parser.parser_db_ready_fixed_Version4 as parser_v4

router = APIRouter(prefix="/api/ingestion", tags=["Ingestion"])


def _as_int(value: Any) -> Optional[int]:
    """Safely convert to int for values that may be Any | None."""
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        try:
            return int(value)
        except ValueError:
            return None
    try:
        return int(value)
    except Exception:
        return None


def _parse_with_v4(func_name: str, path: str) -> Any:
    """
    Resolve a symbol from parser_v4 and call it.
    Encapsulating the call here prevents Pylance from flagging 'module is not callable'.
    """
    obj = getattr(parser_v4, func_name, None)
    if obj is None or not callable(obj):
        raise HTTPException(
            status_code=500,
            detail=f"Parser function '{func_name}' not available or not callable in parser_v4.",
        )
    return obj(path)


@router.get("/health")
def ingestion_health() -> Dict[str, Any]:
    return {"status": "ok", "module": "ingestion_api"}


@router.post("/one")
async def ingest_one(
    doc_type: str = Form(...),  # 'statement' | 'schedule' | 'terminated'
    file: UploadFile = File(...),
    agent_code: Optional[str] = Form(None),
    agent_name: Optional[str] = Form(None),
    month_year_hint: Optional[str] = Form(None),
    dry_run: bool = Form(False),
) -> Dict[str, Any]:
    project_root = Path(__file__).resolve().parents[2]
    logger = RunLogger(project_root)
    filename = file.filename or "upload.pdf"
    try:
        content = await file.read()
        tmp = project_root / "tmp_ingestion_upload"
        tmp.mkdir(parents=True, exist_ok=True)
        target = tmp / filename
        with target.open("wb") as f:
            f.write(content)

        # Parse to DataFrame based on doc_type via wrapper
        doc = doc_type.lower().strip()
        if doc == "statement":
            df = _parse_with_v4("extract_statement_data", str(target))
        elif doc == "schedule":
            df = _parse_with_v4("extract_schedule_data", str(target))
        elif doc == "terminated":
            df = _parse_with_v4("extract_terminated_data", str(target))
        else:
            raise HTTPException(status_code=400, detail="Invalid doc_type")

        rows_raw: List[Dict[str, Any]] = [] if df is None else df.to_dict(orient="records")  # type: ignore[attr-defined]
        # Normalize keys to str so type is precisely List[Dict[str, Any]]
        rows: List[Dict[str, Any]] = [{str(k): v for k, v in r.items()} for r in rows_raw]

        integ = ParserDBIntegration()
        summary = integ.process(
            doc_type_key=doc,
            agent_code=str(agent_code or ""),
            agent_name=agent_name or None,
            df_rows=rows,
            file_path=target,
            month_year_hint=month_year_hint or None,
        )
        summary.setdefault("status", "success")

        # CSV/JSON logs for observability
        logger.log_json(summary)
        logger.log_csv(
            {
                "type": summary.get("doc_type", doc.upper()),
                "file": filename,
                "rows_parsed": len(rows),
                "agent_code": summary.get("agent_code", "") or (agent_code or ""),
                "agent_name": summary.get("agent_name", "") or (agent_name or ""),
                "upload_id": summary.get("upload_id", ""),
                "rows_inserted": summary.get("rows_inserted", 0),
                "moved_to": summary.get("moved_to", ""),
                "status": summary.get("status", "success"),
                "error": summary.get("error", ""),
            }
        )

        # If statement & not dry_run & ingestion succeeded, compute dynamic expected commissions
        if (
            not dry_run
            and summary.get("doc_type") == "STATEMENT"
            and summary.get("upload_id") is not None
            and summary.get("status") == "success"
        ):
            upid = _as_int(summary.get("upload_id"))
            if upid is not None:
                rows_exp = compute_expected_for_upload_dynamic(upload_id=upid)
                inserted = insert_expected_rows(rows_exp)
                summary["expected_rows_inserted"] = inserted

        return summary
    except HTTPException:
        # Already has meaningful HTTP status/detail
        raise
    except Exception as e:
        # Log API-level failure as api_error
        logger.log_csv(
            {
                "type": doc_type.upper(),
                "file": filename,
                "rows_parsed": "",
                "agent_code": agent_code or "",
                "agent_name": agent_name or "",
                "upload_id": "",
                "rows_inserted": "",
                "moved_to": "",
                "status": "api_error",
                "error": str(e),
            }
        )
        logger.log_json(
            {
                "status": "api_error",
                "error": str(e),
                "doc_type": doc_type.upper(),
                "agent_code": agent_code or "",
                "agent_name": agent_name or "",
            }
        )
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/bulk")
async def ingest_bulk_dir(
    dir_path: str = Form(...),  # e.g., "data/incoming"
    override_agent_code: Optional[str] = Form(None),
    override_agent_name: Optional[str] = Form(None),
    dry_run: bool = Form(False),
) -> Dict[str, Any]:
    project_root = Path(__file__).resolve().parents[2]
    logger = RunLogger(project_root)
    try:
        base = Path(dir_path)
        if not base.exists() or not base.is_dir():
            raise HTTPException(status_code=404, detail=f"Directory not found: {base}")

        integ = ParserDBIntegration()
        results: List[Dict[str, Any]] = []

        for p in sorted(base.iterdir()):
            if not p.is_file():
                continue

            name = p.name.lower()
            if "statement" in name:
                doc = "statement"
                df = _parse_with_v4("extract_statement_data", str(p))
            elif "schedule" in name:
                doc = "schedule"
                df = _parse_with_v4("extract_schedule_data", str(p))
            elif "terminat" in name:
                doc = "terminated"
                df = _parse_with_v4("extract_terminated_data", str(p))
            else:
                continue

            try:
                rows_raw: List[Dict[str, Any]] = [] if df is None else df.to_dict(orient="records")  # type: ignore[attr-defined]
                rows: List[Dict[str, Any]] = [{str(k): v for k, v in r.items()} for r in rows_raw]

                if dry_run:
                    summary = {
                        "status": "DRY_RUN",
                        "doc_type": doc.upper(),
                        "agent_code": override_agent_code or "",
                        "agent_name": override_agent_name or "",
                        "month_year": None,
                        "upload_id": None,
                        "rows_inserted": 0,
                        "moved_to": None,
                    }
                    results.append(summary)
                    logger.log_csv(
                        {
                            "type": doc.upper(),
                            "file": p.name,
                            "rows_parsed": len(rows),
                            "agent_code": override_agent_code or "",
                            "agent_name": override_agent_name or "",
                            "upload_id": "",
                            "rows_inserted": 0,
                            "moved_to": "",
                            "status": "DRY_RUN",
                            "error": "",
                        }
                    )
                    logger.log_json(summary)
                    continue

                summary = integ.process(
                    doc_type_key=doc,
                    agent_code=str(override_agent_code or ""),
                    agent_name=override_agent_name or None,
                    df_rows=rows,
                    file_path=p,
                    month_year_hint=None,
                )
                summary.setdefault("status", "success")
                results.append(summary)

                logger.log_json(summary)
                logger.log_csv(
                    {
                        "type": summary.get("doc_type", doc.upper()),
                        "file": p.name,
                        "rows_parsed": len(rows),
                        "agent_code": summary.get("agent_code", "") or (override_agent_code or ""),
                        "agent_name": summary.get("agent_name", "") or (override_agent_name or ""),
                        "upload_id": summary.get("upload_id", ""),
                        "rows_inserted": summary.get("rows_inserted", 0),
                        "moved_to": summary.get("moved_to", ""),
                        "status": summary.get("status", "success"),
                        "error": summary.get("error", ""),
                    }
                )

                # Dynamic expected commissions (Statements only, not dry-run, success only)
                if (
                    not dry_run
                    and doc == "statement"
                    and summary.get("upload_id") is not None
                    and summary.get("status") == "success"
                ):
                    upid = _as_int(summary.get("upload_id"))
                    if upid is not None:
                        rows_exp = compute_expected_for_upload_dynamic(upload_id=upid)
                        inserted = insert_expected_rows(rows_exp)
                        logger.log_csv(
                            {
                                "type": "EXPECTED_COMMISSIONS",
                                "file": p.name,
                                "rows_parsed": len(rows_exp),
                                "agent_code": summary.get("agent_code", "") or (override_agent_code or ""),
                                "agent_name": summary.get("agent_name", "") or (override_agent_name or ""),
                                "upload_id": summary.get("upload_id", ""),
                                "rows_inserted": inserted,
                                "moved_to": summary.get("moved_to", ""),
                                "status": "success",
                                "error": "",
                            }
                        )
            except Exception as e:
                err = {
                    "status": "api_error",
                    "error": str(e),
                    "doc_type": doc.upper(),
                    "agent_code": override_agent_code or "",
                    "agent_name": override_agent_name or "",
                    "month_year": None,
                    "upload_id": None,
                    "rows_inserted": 0,
                    "moved_to": None,
                }
                results.append(err)
                logger.log_csv(
                    {
                        "type": doc.upper(),
                        "file": p.name,
                        "rows_parsed": "",
                        "agent_code": override_agent_code or "",
                        "agent_name": override_agent_name or "",
                        "upload_id": "",
                        "rows_inserted": "",
                        "moved_to": "",
                        "status": "api_error",
                        "error": str(e),
                    }
                )
                logger.log_json(err)

        return {"status": "OK", "count": len(results), "results": results}
    except HTTPException:
        raise
    except Exception as e:
        logger.log_json({"status": "api_error", "error": str(e), "dir_path": dir_path})
        raise HTTPException(status_code=500, detail=str(e))
# ===== END FILE: api\ingestion_api.py =====

################################################################################
# ===== FILE: api\superuser_api.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\superuser_api.py
# SIZE: 9,704 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/superuser_api.py
from __future__ import annotations
from typing import Dict, Any, Optional, List
from fastapi import APIRouter, Request, Depends, HTTPException
from fastapi.responses import StreamingResponse

# Admin report functions are safely imported by their own module
from src.api import admin_reports as admin

#  Fix: import the correct function name from agent_missing
from src.api.agent_missing import missing_by_agent as agent_missing

from src.services.auth_service import decode_token, TOKEN_COOKIE_NAME

def _user_from_cookie(request: Request) -> Dict[str, Any] | None:
    tok = request.cookies.get(TOKEN_COOKIE_NAME)
    return decode_token(tok) if tok else None

def _as_int(value: Any) -> Optional[int]:
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        try:
            return int(value)
        except ValueError:
            return None
    try:
        return int(value)
    except Exception:
        return None

def require_superuser(request: Request) -> Dict[str, Any]:
    u = _user_from_cookie(request)
    role = str((u or {}).get("role") or "").lower()
    user_id_val = (u or {}).get("user_id")
    if not u or role != "superuser" or user_id_val is None:
        raise HTTPException(status_code=403, detail="Superuser authentication required")
    if _as_int(user_id_val) is None:
        raise HTTPException(status_code=400, detail="user_id must be integer or string convertible to int")
    return u or {}

router = APIRouter(prefix="/api/superuser", tags=["Superuser API"], dependencies=[Depends(require_superuser)])

@router.get("/me")
def superuser_me(request: Request) -> Dict[str, Any]:
    u = _user_from_cookie(request) or {}
    uid = _as_int(u.get("user_id"))
    return {"status": "OK", "role": u.get("role"), "user_id": uid}

#  Statements 
@router.get("/statements")
def statements_for_superuser(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    return admin.list_statements(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )

@router.get("/statements.csv")
def statements_csv_for_superuser(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    # call list_statements_csv
    return admin.list_statements_csv(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )

#  Uploads 
@router.get("/uploads")
def uploads_for_superuser(
    doc_type: Optional[str] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    return admin.list_uploads(
        doc_type=doc_type,
        agent_code=agent_code,
        month_year=month_year,
        limit=limit,
        offset=offset,
    )

#  Schedule 
@router.get("/schedule")
def schedule_for_superuser(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    latest_only: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    return admin.list_schedule(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        latest_only=latest_only,
        limit=limit,
        offset=offset,
    )

#  Terminated 
@router.get("/terminated")
def terminated_for_superuser(
    upload_id: Optional[int] = None,
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    policy_no: Optional[str] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    return admin.list_terminated(
        upload_id=upload_id,
        agent_code=agent_code,
        month_year=month_year,
        policy_no=policy_no,
        limit=limit,
        offset=offset,
    )

#  Active policies 
@router.get("/active-policies")
def active_policies_for_superuser(
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
) -> Dict[str, Any]:
    return admin.list_active_policies(
        agent_code=agent_code,
        month_year=month_year,
        status=status,
        limit=limit,
        offset=offset,
    )

#  Missing (fixed function name) 
@router.get("/missing")
def missing_for_superuser(agent_code: str, month_year: str) -> Dict[str, Any]:
    return agent_missing(agent_code=agent_code, month_year=month_year)

@router.get("/missing.csv")
def missing_csv_for_superuser(agent_code: str, month_year: str) -> StreamingResponse:
    res = missing_for_superuser(agent_code=agent_code, month_year=month_year)
    rows: List[Dict[str, Any]] = res.get("items", []) if isinstance(res, dict) else []
    return admin._dicts_to_csv_stream(rows, field_order=["policy_no", "last_seen_month", "last_premium"])

#  Audit flags 
@router.get("/audit-flags")
def audit_flags_for_superuser(
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    flag_type: Optional[str] = None,
    policy_no: Optional[str] = None,
    resolved: Optional[int] = None,
    limit: int = 200,
    offset: int = 0,
) -> Dict[str, Any]:
    return admin.list_audit_flags(
        agent_code=agent_code,
        month_year=month_year,
        flag_type=flag_type,
        limit=limit,
        offset=offset,
    )

@router.get("/audit-flags.csv")
def audit_flags_csv_for_superuser(
    agent_code: Optional[str] = None,
    month_year: Optional[str] = None,
    flag_type: Optional[str] = None,
    policy_no: Optional[str] = None,
    resolved: Optional[int] = None,
    limit: int = 100000,
    offset: int = 0,
) -> StreamingResponse:
    res = audit_flags_for_superuser(
        agent_code=agent_code,
        month_year=month_year,
        flag_type=flag_type,
        policy_no=policy_no,
        resolved=resolved,
        limit=limit,
        offset=offset,
    )
    rows: List[Dict[str, Any]] = res.get("items", []) if isinstance(res, dict) else []
    return admin._dicts_to_csv_stream(rows, field_order=[
        "id","agent_code","policy_no","month_year","flag_type","severity",
        "flag_detail","expected_value","actual_value","created_at",
        "resolved","resolved_by","resolved_at","resolution_notes"
    ])

#  Uploads tracker 
@router.get("/uploads/tracker")
def uploads_tracker_for_superuser(agent_code: str, months_back: int = 36) -> Dict[str, Any]:
    return admin.uploads_tracker(agent_code=agent_code, months_back=months_back)

@router.get("/uploads/tracker.csv")
def uploads_tracker_csv_for_superuser(agent_code: str, months_back: int = 36) -> StreamingResponse:
    res = uploads_tracker_for_superuser(agent_code=agent_code, months_back=months_back)
    rows = res.get("items", []) if isinstance(res, dict) else []
    csv_rows: List[Dict[str, Any]] = []
    for r in rows:
        csv_rows.append({
            "month_year": r.get("month_year"),
            "statement": 1 if r.get("statement_present") else 0,
            "schedule": 1 if r.get("schedule_present") else 0,
            "terminated": 1 if r.get("terminated_present") else 0,
            "statement_upload_id": r.get("statement_upload_id"),
            "schedule_upload_id": r.get("schedule_upload_id"),
            "terminated_upload_id": r.get("terminated_upload_id"),
        })
    return admin._dicts_to_csv_stream(csv_rows, field_order=[
        "month_year","statement","schedule","terminated",
        "statement_upload_id","schedule_upload_id","terminated_upload_id"
    ])
# ===== END FILE: api\superuser_api.py =====

################################################################################
# ===== FILE: api\ui_pages.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\ui_pages.py
# SIZE: 13,453 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/ui_pages.py
from __future__ import annotations
from fastapi import APIRouter
from fastapi.responses import HTMLResponse

router = APIRouter(prefix="/ui", tags=["UI Pages"])


def _base_html(body: str) -> str:
    return f"""<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ICRS  UI</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"/>
  <style>
    body {{ background:#f9fafb; }}
    a.text-link {{ text-decoration:none }}
  </style>
</head>
<body>
{body}
</body>
</html>"""


# ---------------------------
# Landing (styled as requested)
# ---------------------------
@router.get("/", response_class=HTMLResponse)
async def landing_page() -> HTMLResponse:
    # Full-page HTML (standalone head) per your spec
    return HTMLResponse(r"""<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ICRS  Welcome</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet"/>
  <style>
    body{
      margin:0;min-height:100vh;display:flex;align-items:center;justify-content:center;
      background:
        radial-gradient(circle at 10% 10%, #22d3ee33 0, transparent 45%),
        radial-gradient(circle at 90% 90%, #a855f733 0, transparent 45%),
        #0b1020;
      color:#e5e7eb;font-family:system-ui,-apple-system,BlinkMacSystemFont,"SF Pro Text",sans-serif;
    }
    .wrap{max-width:980px;width:100%;padding:24px;position:relative}
    /* Top-left tiny buttons */
    .top-left{
      position:absolute;left:24px;top:24px;display:flex;gap:.5rem;flex-wrap:wrap;
    }
    .btn-top{
      --bs-btn-padding-y:.25rem; --bs-btn-padding-x:.6rem; --bs-btn-font-size:.72rem;
      border-radius:999px; background:rgba(255,255,255,.08); color:#e5e7eb; border:1px solid rgba(255,255,255,.2)
    }
    .btn-top:hover{ background:rgba(255,255,255,.15); color:#fff }
    .brand{display:flex;gap:12px;align-items:center;justify-content:center;margin-bottom:18px}
    .brand .logo{font-size:20px}
    .brand h1{font-size:20px;letter-spacing:.18em;text-transform:uppercase;margin:0}

    /* Prominent Agent card in the center */
    .cardy{
      background:#0f172a;border:1px solid #1f2937;border-radius:16px;padding:28px 22px;
      box-shadow:0 24px 70px rgba(0,0,0,.6);
    }
    .btn-grad{background:linear-gradient(90deg,#22d3ee,#a855f7);border:none;border-radius:999px}
    .agent-title{
      display:flex;align-items:center;gap:.6rem;font-weight:800;font-size:1.35rem;letter-spacing:.02em;justify-content:center;
    }
    .footer{
      margin-top:24px;text-align:center;color:#9ca3af;font-size:.9rem
    }
  </style>
</head>
<body>
  <div class="wrap">

    <!-- Small Admin / Superuser buttons at the top-left -->
    <div class="top-left">
      <a class="btn btn-top" href="/ui/login/admin" title="Admin Login" aria-label="Admin Login"></a>
      <a class="btn btn-top" href="/ui/login/superuser" title="Superuser Login" aria-label="Superuser Login"></a>
    </div>

    <!-- Centered Agent card -->
    <div class="brand">
      <div class="logo"></div>
      <h1>ICRS</h1>
    </div>

    <div class="row justify-content-center">
      <div class="col-md-6 col-lg-5">
        <div class="cardy text-center">
          <div class="agent-title mb-3"><span>Agent</span></div>
          <a class="btn btn-grad w-100" href="/ui/agent/"><span class="me-1"></span>Open Agent Dashboard</a>
        </div>
      </div>
    </div>

    <div class="footer">
      contact <a class="text-link" href="mailto:nannztrades@gmail.com">nannztrades@gmail.com</a> for any info or assistance
    </div>
  </div>
</body>
</html>""")


# ---------------------------
# Agent Login (agent_code + password)
# ---------------------------
@router.get("/login/agent", response_class=HTMLResponse)
async def login_agent_page() -> HTMLResponse:
    body = r"""
<div class="container py-4">
  <div class="d-flex align-items-center justify-content-between mb-2">
    <h3 class="mb-0">Agent Login</h3>
    <a class="btn btn-sm btn-outline-secondary" href="/ui/">&larr; Back</a>
  </div>

  <!-- Pressing Enter submits because this is a real <form> with type=submit -->
  <form onsubmit="return agentLogin(event, this);">
    <div class="mb-3">
      <label class="form-label">Agent Code</label>
      <input name="agent_code" class="form-control" autocomplete="username" required>
    </div>
    <div class="mb-3">
      <label class="form-label">Password</label>
      <input name="code_password" type="password" class="form-control" autocomplete="current-password" required>
    </div>
    <div id="agentMsg" class="small text-muted mb-2"></div>
    <button type="submit" class="btn btn-primary">Login</button>
  </form>
</div>
<script>
function setMsg(id, txt, kind){
  const el = document.getElementById(id);
  if(!el) return;
  el.textContent = txt || '';
  el.className = 'small';
  if(kind === 'error'){ el.classList.add('text-danger'); }
  else if(kind === 'success'){ el.classList.add('text-success'); }
  else { el.classList.add('text-muted'); }
}
function toBody(obj){
  const p = new URLSearchParams();
  Object.entries(obj).forEach(([k,v]) => p.append(k, v));
  return p.toString();
}
async function getCsrf(){
  const r = await fetch('/api/auth/csrf', {credentials:'same-origin'});
  if (!r.ok){
    throw new Error('Failed to get CSRF token');
  }
  const j = await r.json();
  return j.csrf_token;
}
async function agentLogin(e, form){
  e.preventDefault();
  const code = (form.agent_code.value || '').trim();
  const pass = form.code_password.value || '';
  if(!code || !pass){
    setMsg('agentMsg','Agent Code and Password are required','error');
    return false;
  }
  try{
    const csrf = await getCsrf();
    const r = await fetch('/api/auth/login/agent', {
      method:'POST',
      headers:{
        'Content-Type':'application/x-www-form-urlencoded',
        'X-CSRF-Token': csrf
      },
      body: toBody({agent_code: code, password: pass}),
      credentials:'same-origin'
    });
    if(!r.ok){
      const j = await r.json().catch(()=>({}));
      setMsg('agentMsg', j.detail || 'Login failed','error');
      return false;
    }
    setMsg('agentMsg','Login OK, redirecting...','success');
    window.location.href = '/ui/agent/';
  }catch(err){
    setMsg('agentMsg', String(err || 'Login error'),'error');
  }
  return false;
}
</script>
"""
    return HTMLResponse(_base_html(body))


# -----------------------------------------
# Admin Login (user_id + password)  Admin only label
#   - Enter key supported (type="submit")
#   - Back button to /ui/
#   - Role-aware redirect (still in JS)
# -----------------------------------------
def _admin_login_body() -> str:
    return r"""
<div class="container py-4">
  <div class="d-flex align-items-center justify-content-between mb-2">
    <h3 class="mb-0">Admin Login</h3>
    <a class="btn btn-sm btn-outline-secondary" href="/ui/">&larr; Back</a>
  </div>

  <form onsubmit="return adminLogin(event, this);">
    <div class="mb-3">
      <label class="form-label">User ID</label>
      <input name="user_id" type="number" class="form-control" autocomplete="username" required>
    </div>
    <div class="mb-3">
      <label class="form-label">Password</label>
      <input name="password" type="password" class="form-control" autocomplete="current-password" required>
    </div>
    <div id="adminMsg" class="small text-muted mb-2"></div>
    <button type="submit" class="btn btn-primary">Login</button>
  </form>
</div>
<script>
function setMsg(id, txt, kind){
  const el = document.getElementById(id);
  if(!el) return;
  el.textContent = txt || '';
  el.className = 'small';
  if(kind === 'error'){ el.classList.add('text-danger'); }
  else if(kind === 'success'){ el.classList.add('text-success'); }
  else { el.classList.add('text-muted'); }
}
function toBody(obj){
  const p = new URLSearchParams();
  Object.entries(obj).forEach(([k,v]) => p.append(k, v));
  return p.toString();
}
async function getCsrf(){
  const r = await fetch('/api/auth/csrf', {credentials:'same-origin'});
  if (!r.ok){ throw new Error('Failed to get CSRF token'); }
  const j = await r.json();
  return j.csrf_token;
}
async function adminLogin(e, form){
  e.preventDefault();
  const uid = (form.user_id.value || '').trim();
  const pass = (form.password.value || '');
  if(!uid || !pass){
    setMsg('adminMsg','User ID and Password are required','error');
    return false;
  }
  try{
    const csrf = await getCsrf();
    const r = await fetch('/api/auth/login/user', {
      method:'POST',
      headers:{ 'Content-Type':'application/x-www-form-urlencoded', 'X-CSRF-Token': csrf },
      body: toBody({user_id: uid, password: pass}),
      credentials:'same-origin'
    });
    if(!r.ok){
      const j = await r.json().catch(()=>({}));
      setMsg('adminMsg', j.detail || 'Login failed','error');
      return false;
    }
    setMsg('adminMsg','Login OK, checking role...','success');

    // Role-aware redirect (admin/superuser/agent)
    const meResp = await fetch('/api/auth/me', { credentials:'same-origin' });
    if (!meResp.ok) {
      setMsg('adminMsg', 'Could not verify session after login','error');
      return false;
    }
    const me = await meResp.json();
    const role = (me.identity?.role || '').toLowerCase();

    if (role === 'admin')        window.location.href = '/ui/admin/';
    else if (role === 'superuser') window.location.href = '/ui/superuser/';
    else if (role === 'agent')     window.location.href = '/ui/agent/';
    else                           window.location.href = '/ui/';
  }catch(err){
    setMsg('adminMsg', String(err || 'Login error'),'error');
  }
  return false;
}
</script>
"""


# -----------------------------------------
# Superuser Login (user_id + password)  Superuser only label
#   - Enter key supported (type="submit")
#   - Back button to /ui/
#   - Role-aware redirect (still in JS)
# -----------------------------------------
def _superuser_login_body() -> str:
    return r"""
<div class="container py-4">
  <div class="d-flex align-items-center justify-content-between mb-2">
    <h3 class="mb-0">Superuser Login</h3>
    <a class="btn btn-sm btn-outline-secondary" href="/ui/">&larr; Back</a>
  </div>

  <form onsubmit="return suLogin(event, this);">
    <div class="mb-3">
      <label class="form-label">User ID</label>
      <input name="user_id" type="number" class="form-control" autocomplete="username" required>
    </div>
    <div class="mb-3">
      <label class="form-label">Password</label>
      <input name="password" type="password" class="form-control" autocomplete="current-password" required>
    </div>
    <div id="suMsg" class="small text-muted mb-2"></div>
    <button type="submit" class="btn btn-primary">Login</button>
  </form>
</div>
<script>
function setMsg(id, txt, kind){
  const el = document.getElementById(id);
  if(!el) return;
  el.textContent = txt || '';
  el.className = 'small';
  if(kind === 'error'){ el.classList.add('text-danger'); }
  else if(kind === 'success'){ el.classList.add('text-success'); }
  else { el.classList.add('text-muted'); }
}
function toBody(obj){
  const p = new URLSearchParams();
  Object.entries(obj).forEach(([k,v]) => p.append(k, v));
  return p.toString();
}
async function getCsrf(){
  const r = await fetch('/api/auth/csrf', {credentials:'same-origin'});
  if (!r.ok){ throw new Error('Failed to get CSRF token'); }
  const j = await r.json();
  return j.csrf_token;
}
async function suLogin(e, form){
  e.preventDefault();
  const uid = (form.user_id.value || '').trim();
  const pass = (form.password.value || '');
  if(!uid || !pass){
    setMsg('suMsg','User ID and Password are required','error');
    return false;
  }
  try{
    const csrf = await getCsrf();
    const r = await fetch('/api/auth/login/user', {
      method:'POST',
      headers:{ 'Content-Type':'application/x-www-form-urlencoded', 'X-CSRF-Token': csrf },
      body: toBody({user_id: uid, password: pass}),
      credentials:'same-origin'
    });
    if(!r.ok){
      const j = await r.json().catch(()=>({}));
      setMsg('suMsg', j.detail || 'Login failed','error');
      return false;
    }
    setMsg('suMsg','Login OK, checking role...','success');

    // Role-aware redirect (superuser/admin/agent)
    const meResp = await fetch('/api/auth/me', { credentials:'same-origin' });
    if (!meResp.ok) {
      setMsg('suMsg', 'Could not verify session after login','error');
      return false;
    }
    const me = await meResp.json();
    const role = (me.identity?.role || '').toLowerCase();

    if (role === 'superuser')   window.location.href = '/ui/superuser/';
    else if (role === 'admin')  window.location.href = '/ui/admin/';
    else if (role === 'agent')  window.location.href = '/ui/agent/';
    else                        window.location.href = '/ui/';
  }catch(err){
    setMsg('suMsg', String(err || 'Login error'),'error');
  }
  return false;
}
</script>
"""


@router.get("/login/admin", response_class=HTMLResponse)
async def login_admin_page() -> HTMLResponse:
    return HTMLResponse(_base_html(_admin_login_body()))


@router.get("/login/superuser", response_class=HTMLResponse)
async def login_superuser_page() -> HTMLResponse:
    return HTMLResponse(_base_html(_superuser_login_body()))
# ===== END FILE: api\ui_pages.py =====

################################################################################
# ===== FILE: api\uploads.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\uploads.py
# SIZE: 4,655 bytes
# ENCODING: utf-8
# ===== START =====

# src/api/uploads.py
from __future__ import annotations
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Request

from src.ingestion.parser_db_integration import ParserDBIntegration
from src.services.auth_service import decode_token, TOKEN_COOKIE_NAME
from src.parser.parser_db_ready_fixed_Version4 import (
    extract_statement_data,
    extract_schedule_data,
    extract_terminated_data,
)

router = APIRouter(prefix="/api", tags=["Uploads"])

ALLOWED_DOC_TYPES = {"statement", "schedule", "terminated"}

def _safe_filename(orig: str | None, agent_code: str, doc_type: str) -> str:
    """
    Build a safe filename:
    - If orig is None or empty, generate: {timestamp}_{agent_code}_{doc_type}.pdf
    - Strip any path components; keep basename only.
    """
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    if not orig:
        return f"{ts}_{agent_code}_{doc_type}.pdf"
    name = Path(orig).name
    if not name.strip():
        return f"{ts}_{agent_code}_{doc_type}.pdf"
    return name

def _require_uploader(request: Request, agent_code: str) -> None:
    """
    Gate uploads by role:
    - Agents may only upload for their own agent_code.
    - Admin/Superuser may upload for anyone.
    """
    tok = request.cookies.get(TOKEN_COOKIE_NAME)
    u = decode_token(tok) if tok else None
    if not u:
        raise HTTPException(status_code=403, detail="Authentication required")
    role = str((u.get("role") or "")).lower()
    if role == "agent":
        if str(u.get("agent_code") or "") != str(agent_code):
            raise HTTPException(status_code=403, detail="Agents may only upload for their own agent_code")
    elif role in ("admin", "superuser"):
        return
    else:
        raise HTTPException(status_code=403, detail="Role not permitted to upload")

@router.post("/pdf-enhanced/upload/{doc_type}")
async def upload_and_ingest(
    request: Request,
    doc_type: str,
    file: UploadFile = File(...),
    agent_code: str = Form(...),
    month_year: str = Form(...),
    agent_name: str = Form(""),
) -> Dict[str, Any]:
    """
    Accept a PDF upload, parse it, and persist via ParserDBIntegration.
    doc_type: statement | schedule | terminated
    """
    # Auth guard
    _require_uploader(request, agent_code)

    # Validate doc type
    doc_type_norm = doc_type.lower().strip()
    if doc_type_norm not in ALLOWED_DOC_TYPES:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported doc_type '{doc_type}'. Use one of {sorted(ALLOWED_DOC_TYPES)}"
        )

    # Save incoming file
    project_root = Path(__file__).resolve().parents[2]
    incoming = project_root / "data" / "incoming"
    incoming.mkdir(parents=True, exist_ok=True)

    filename = file.filename or "upload.pdf"
    safe_name = _safe_filename(filename, agent_code, doc_type_norm)
    target = incoming / safe_name

    contents = await file.read()
    with target.open("wb") as f:
        f.write(contents)

    # Parse to DataFrame -> rows list[dict] with str keys (Pylance-safe)
    try:
        if doc_type_norm == "statement":
            df = extract_statement_data(str(target))
        elif doc_type_norm == "schedule":
            df = extract_schedule_data(str(target))
        else:  # terminated
            df = extract_terminated_data(str(target))

        rows_raw = [] if df is None else df.to_dict(orient="records")
        # Normalize keys to str so type is precisely List[Dict[str, Any]]
        rows: List[Dict[str, Any]] = [{str(k): v for k, v in r.items()} for r in rows_raw]

        integ = ParserDBIntegration()
        summary = integ.process(
            doc_type_key=doc_type_norm,
            agent_code=str(agent_code or ""),
            agent_name=agent_name or None,
            df_rows=rows,
            file_path=target,
            month_year_hint=month_year or None,
        )

        return {
            "status": "success",
            "message": "PDF uploaded and processed.",
            "upload_id": summary.get("upload_id"),
            "records_count": summary.get("rows_inserted"),
            "agent_code": summary.get("agent_code") or agent_code,
            "doc_type": summary.get("doc_type"),
            "month_year": summary.get("month_year"),
            "file_saved_as": safe_name,
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
# ===== END FILE: api\uploads.py =====

################################################################################
# ===== FILE: api\uploads_secure.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\api\uploads_secure.py
# SIZE: 4,462 bytes
# ENCODING: utf-8
# ===== START =====
# src/api/uploads_secure.py
from __future__ import annotations

from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Request
from typing import Dict, Any
import os
import io

from pypdf import PdfReader
from pypdf.errors import PdfStreamError

from src.services.auth_service import decode_token, TOKEN_COOKIE_NAME

router = APIRouter(prefix="/api/uploads-secure", tags=["Uploads Secure"])

# Max size is envtunable; default 5MB if not set
UPLOAD_MAX_BYTES: int = int(os.getenv("UPLOAD_MAX_BYTES", str(5 * 1024 * 1024)))


def _read_text(pdf_bytes: bytes, max_pages: int = 2) -> str:
    """
    Besteffort PDF text extraction for cheap validation.
    Any parsing error (including truncated streams) is treated as empty text.
    """
    try:
        buf = io.BytesIO(pdf_bytes)
        reader = PdfReader(buf)
        pages = min(max_pages, len(reader.pages))
        chunks = []
        for i in range(pages):
            try:
                page_text = reader.pages[i].extract_text() or ""
                chunks.append(page_text)
            except Exception:
                # ignore perpage extraction problems
                continue
        return "\n".join(chunks).lower()
    except PdfStreamError:
        # Truncated / nonPDF stream  treat as no text, let marker logic handle it
        return ""
    except Exception:
        return ""


def _markers_for(file_type: str):
    ft = file_type.lower()
    if ft == "statement":
        return ["policy", "premium", "commission", "pay date"]
    if ft == "schedule":
        return ["net commission", "total deductions", "commission batch", "income"]
    if ft == "terminated":
        return ["termination", "reason", "status", "policy"]
    return []


def _require_uploader(request: Request, agent_code: str) -> None:
    """
    Gate uploads:
      - agents: only their own agent_code
      - admin/superuser: any agent_code
    """
    tok = request.cookies.get(TOKEN_COOKIE_NAME)
    u = decode_token(tok) if tok else None
    if not u:
        raise HTTPException(status_code=403, detail="Authentication required")
    role = str((u.get("role") or "")).lower()
    if role == "agent":
        if str(u.get("agent_code") or "") != str(agent_code):
            raise HTTPException(
                status_code=403,
                detail="Agents may only upload for their own agent_code",
            )
        return
    if role in ("admin", "superuser"):
        return
    raise HTTPException(status_code=403, detail="Role not permitted to upload")


@router.post("/{file_type}")
async def validate_upload(
    file_type: str,
    agent_code: str = Form(...),
    month_year: str = Form(...),
    file: UploadFile = File(...),
    request: Request = ...,
) -> Dict[str, Any]:
    """
    Lightweight validation endpoint:
    - Enforces role + agent_code gating.
    - Enforces contenttype = PDF.
    - Enforces max size from UPLOAD_MAX_BYTES.
    - Runs cheap markerbased heuristics on first pages.
    """
    _require_uploader(request, agent_code)

    ft = file_type.lower().strip()
    if ft not in {"statement", "schedule", "terminated"}:
        raise HTTPException(status_code=400, detail="Invalid file_type")

    if file.content_type not in {"application/pdf", "application/octet-stream"}:
        raise HTTPException(status_code=400, detail="Only PDF uploads are allowed")

    content = await file.read()
    size = len(content)

    #  Shortcircuit oversize BEFORE any PDF parsing, so tests see 413
    if size > UPLOAD_MAX_BYTES:
        raise HTTPException(
            status_code=413,
            detail=f"File too large (max {UPLOAD_MAX_BYTES // (1024 * 1024)}MB)",
        )

    # Besteffort marker check on first pages
    text = _read_text(content, max_pages=2)
    markers = _markers_for(ft)
    matched = sum(1 for m in markers if m in text)

    if matched < 2:
        raise HTTPException(
            status_code=400,
            detail=f"Uploaded PDF does not look like a {ft} document. No ingestion performed.",
        )

    # Expose marker details so UI can colourcode confidence
    return {
        "status": "VALIDATED",
        "validated": True,
        "agent_code": agent_code,
        "month_year": month_year,
        "file_type": ft,
        "size_bytes": size,
        "markers_expected": markers,
        "markers_matched": matched,
        "marker_match_ratio": matched / max(len(markers), 1),
    }
# ===== END FILE: api\uploads_secure.py =====

################################################################################
# ===== FILE: audit\discrepancies.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\audit\discrepancies.py
# SIZE: 4,162 bytes
# ENCODING: utf-8
# ===== START =====

# src/audit/discrepancies.py
from __future__ import annotations
from typing import List, Dict, Any, Optional
from decimal import Decimal
from datetime import datetime

from src.ingestion.db import get_conn
from src.reports.monthly_reports import (
    _fetch_discrepancies_multiple_entries,
    _fetch_discrepancies_inception_vs_first_seen,
    _fetch_discrepancies_arrears,
    _fetch_should_be_terminated,
    _period_key_from_month_year
)

def _insert_discrepancies(rows: List[Dict[str, Any]]) -> int:
    if not rows:
        return 0
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            params = []
            for r in rows:
                params.append((
                    r['agent_code'], r.get('policy_no'), r['period'], r.get('month_year'),
                    r.get('diff_amount'), r.get('statement_id'), r.get('severity'), r.get('notes'), r.get('type')
                ))
            # Use ON DUPLICATE if unique index exists
            cur.executemany("""
                INSERT INTO `discrepancies`
                (`agent_code`,`policy_no`,`period`,`month_year`,`diff_amount`,
                 `statement_id`,`severity`,`notes`,`type`)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
                ON DUPLICATE KEY UPDATE
                  `diff_amount`=VALUES(`diff_amount`),
                  `severity`=VALUES(`severity`),
                  `notes`=VALUES(`notes`)
            """, params)
        conn.commit()
        return len(rows)
    finally:
        conn.close()

def emit_discrepancies_for_month(agent_code: str, month_year: str) -> int:
    """
    Compute discrepancies and emit to DB for dashboard.
    """
    period = _period_key_from_month_year(month_year) or month_year

    # Gather
    dups = _fetch_discrepancies_multiple_entries(agent_code, month_year)
    incs = _fetch_discrepancies_inception_vs_first_seen(agent_code, month_year)
    arrs = _fetch_discrepancies_arrears(agent_code, month_year)
    sbt  = _fetch_should_be_terminated(agent_code, month_year)

    rows: List[Dict[str, Any]] = []

    # MULTIPLE_ENTRIES_IN_MONTH
    for r in dups:
        rows.append({
            "agent_code": agent_code,
            "policy_no": r.get("policy_no"),
            "period": period,
            "month_year": month_year,
            "diff_amount": None,
            "statement_id": None,
            "severity": "MED",
            "notes": f"entries={r.get('entries')}",
            "type": "MULTIPLE_ENTRIES_IN_MONTH",
        })

    # INCEPTION_FIRST_SEEN_INCONSISTENCY
    for r in incs:
        notes = f"inception={r.get('inception')},first_seen={r.get('first_seen_date')}"
        rows.append({
            "agent_code": agent_code,
            "policy_no": r.get("policy_no"),
            "period": period,
            "month_year": month_year,
            "diff_amount": None,
            "statement_id": None,
            "severity": "HIGH",
            "notes": notes,
            "type": "INCEPTION_FIRST_SEEN_INCONSISTENCY",
        })

    # ARREARS_SUSPECT
    for r in arrs:
        total = r.get("total_premium")
        notes = f"entries={r.get('entries')},sum_premium={total}"
        rows.append({
            "agent_code": agent_code,
            "policy_no": r.get("policy_no"),
            "period": period,
            "month_year": month_year,
            "diff_amount": float(Decimal(str(total or 0.0))),
            "statement_id": None,
            "severity": "MED",
            "notes": notes,
            "type": "ARREARS_SUSPECT",
        })

    # SHOULD_BE_TERMINATED
    for r in sbt:
        rows.append({
            "agent_code": agent_code,
            "policy_no": r.get("policy_no"),
            "period": period,
            "month_year": month_year,
            "diff_amount": None,
            "statement_id": None,
            "severity": "HIGH",
            "notes": "Appears after termination recorded earlier/equal to month",
            "type": "SHOULD_BE_TERMINATED",
        })

    return _insert_discrepancies(rows)
# ===== END FILE: audit\discrepancies.py =====

################################################################################
# ===== FILE: cli\__init__.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\__init__.py
# SIZE: 0 bytes
# ENCODING: utf-8
# ===== START =====

# ===== END FILE: cli\__init__.py =====

################################################################################
# ===== FILE: cli\diagnose_agent_import.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\diagnose_agent_import.py
# SIZE: 272 bytes
# ENCODING: utf-8
# ===== START =====
# src/cli/diagnose_agent_import.py
import importlib, inspect
mod = importlib.import_module("src.api.agent_reports")
print("Imported module file:", inspect.getsourcefile(mod))
print("--- First 20 lines ---")
print("\n".join(inspect.getsource(mod).splitlines()[:20]))
# ===== END FILE: cli\diagnose_agent_import.py =====

################################################################################
# ===== FILE: cli\expected_for_upload.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\expected_for_upload.py
# SIZE: 12,355 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/expected_for_upload.py
from __future__ import annotations
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any
from src.ingestion.db import get_conn
from src.ingestion.commission import compute_expected_for_upload_dynamic, insert_expected_rows
from src.reports.monthly_reports import local_and_gcs, _period_key_from_month_year, compute_month_summary

# ----------------- Monthly Reports Row -----------------
def _insert_monthly_report_row(
    conn: Any,
    agent_code: str,
    agent_name: str,
    report_period: str,  # canonical YYYY-MM
    upload_id: int,
    summary: dict,
    pdf_path: Optional[str],
) -> int:
    from decimal import Decimal
    total_reported = Decimal(str(summary.get('total_commission_reported', 0.0)))
    total_expected = Decimal(str(summary.get('total_commission_expected', 0.0)))
    #  Unify variance: Reported  Expected (positive means reported above expected)
    variance_amount = total_reported - total_expected
    variance_percentage = Decimal("0.00")
    if total_expected != Decimal("0.00"):
        variance_percentage = (variance_amount / total_expected * Decimal("100")).quantize(Decimal("0.01"))

    overall_status = "OK"
    if summary.get('missing_policies_count', 0) > 0 or summary.get('terminated_policies_count', 0) > 0:
        overall_status = "ATTENTION"

    now_dt = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    pdf_size = 0
    try:
        import os
        pdf_size = os.path.getsize(pdf_path) if pdf_path else 0
    except Exception:
        pdf_size = 0

    sql = """
    INSERT INTO `monthly_reports`
    (`agent_code`,`agent_name`,`report_period`,`upload_id`,
     `policies_reported`,`total_premium`,`total_commission_reported`,
     `total_commission_expected`,`variance_amount`,`variance_percentage`,
     `missing_policies_count`,`commission_mismatches_count`,`data_quality_issues_count`,
     `terminated_policies_count`,`overall_status`,`report_html`,
     `report_pdf_path`,`report_pdf_s3_url`,`report_pdf_size_bytes`,
     `report_pdf_generated_at`,`generated_at`)
    VALUES
    (%s,%s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s,%s,
     %s,%s)
    """
    with conn.cursor() as cur:
        cur.execute(sql, (
            agent_code,
            agent_name,
            report_period,
            upload_id,
            int(summary.get('policies_reported', 0)),
            float(summary.get('total_premium', 0.0)),
            float(summary.get('total_commission_reported', 0.0)),
            float(summary.get('total_commission_expected', 0.0)),
            float(variance_amount),
            float(variance_percentage),
            int(summary.get('missing_policies_count', 0)),
            int(summary.get('commission_mismatches_count', 0)),
            int(summary.get('data_quality_issues_count', 0)) if summary.get('data_quality_issues_count') is not None else 0,
            int(summary.get('terminated_policies_count', 0)),
            overall_status,
            None,  # report_html
            pdf_path or None,
            None,  # report_pdf_s3_url (unused now)
            int(pdf_size),
            now_dt if pdf_path else None,
            now_dt,
        ))
    conn.commit()
    return 1

# ----------------- Monitoring (CLI runs) -----------------
def _ensure_cli_runs_table(conn: Any) -> None:
    with conn.cursor() as cur:
        cur.execute("""
        CREATE TABLE IF NOT EXISTS `cli_runs` (
          `run_id` INT NOT NULL AUTO_INCREMENT,
          `started_at` DATETIME NOT NULL,
          `ended_at` DATETIME NULL,
          `status` VARCHAR(20) NOT NULL,
          `message` TEXT NULL,
          `upload_id` INT NULL,
          `agent_code` VARCHAR(50) NULL,
          `report_period` VARCHAR(20) NULL,
          `expected_rows_computed` INT NULL,
          `expected_rows_inserted` INT NULL,
          `pdf_path` VARCHAR(255) NULL,
          PRIMARY KEY (`run_id`)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
        """)
    conn.commit()

def _log_cli_run_file(record: dict) -> None:
    log_dir = Path("logs")
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / "cli_runs.log"
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record) + "\n")

def _log_cli_run_db(conn: Any, record: dict) -> None:
    try:
        _ensure_cli_runs_table(conn)
        with conn.cursor() as cur:
            cur.execute("""
            INSERT INTO `cli_runs`
            (`started_at`,`ended_at`,`status`,`message`,
             `upload_id`,`agent_code`,`report_period`,
             `expected_rows_computed`,`expected_rows_inserted`,`pdf_path`)
            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
            """, (
                record["started_at"],
                record.get("ended_at"),
                record["status"],
                record.get("message"),
                record.get("upload_id"),
                record.get("agent_code"),
                record.get("report_period"),
                record.get("expected_rows_computed"),
                record.get("expected_rows_inserted"),
                record.get("pdf_path"),
            ))
        conn.commit()
    except Exception as e:
        record["status"] = f"{record['status']} (file)"
        record["message"] = f"{record.get('message','')} db-log-failed: {e}"
        _log_cli_run_file(record)

# ----------------- Utility -----------------
def _agent_list_for_scope(upload_id: Optional[int], month_year: Optional[str]) -> List[str]:
    """
    Returns distinct agent codes for the given upload or month label.
    Prefers upload_id when provided.
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            if upload_id is not None:
                cur.execute("""
                SELECT DISTINCT `agent_code`
                FROM `statement`
                WHERE `upload_id`=%s
                ORDER BY `agent_code`
                """, (upload_id,))
            else:
                cur.execute("""
                SELECT DISTINCT `agent_code`
                FROM `statement`
                WHERE `MONTH_YEAR`=%s
                ORDER BY `agent_code`
                """, (month_year,))
            rows = cur.fetchall() or []
        return [str(r.get("agent_code")) for r in rows if r.get("agent_code")]
    finally:
        conn.close()

# ----------------- Main CLI -----------------
def main() -> None:
    ap = argparse.ArgumentParser(
        description="Compute expected commissions, insert, render timestamped PDF, and log monthly report."
    )
    ap.add_argument("--upload-id", type=int, required=True, help="Statement upload_id.")
    ap.add_argument("--agent-code", type=str, required=True, help="Agent code or 'ALL'.")
    ap.add_argument("--agent-name", type=str, help="Agent name (ignored for ALL).")
    ap.add_argument("--month-year", type=str, required=True, help="Month label (e.g., 'Jun 2025' or 'COM_JUN_2025').")
    ap.add_argument("--out", type=str, default="D:/PROJECT/INSURANCELOCAL/reports", help="Base reports directory.")
    ap.add_argument("--user-id", type=int, help="ID of the user triggering the report (prefixes the PDF filename).")
    ap.add_argument("--skip-pdf", action="store_true", help="Skip PDF generation.")
    ap.add_argument("--dry-run", action="store_true", help="Compute only; do not insert expected rows.")
    ap.add_argument("--verbose", action="store_true", help="Verbose console output.")
    args = ap.parse_args()

    started_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # Batch mode: agent-name not required
    if args.agent_code.strip().upper() == "ALL":
        agents = _agent_list_for_scope(args.upload_id, args.month_year)
        if args.verbose:
            print(f"[batch] agents: {agents}")
        if not agents:
            print("[batch] No agents found for the given scope.")
            return

        # Map agent names
        name_map: Dict[str, str] = {}
        conn_info = get_conn()
        try:
            with conn_info.cursor() as cur:
                cur.execute("SELECT `agent_code`,`agent_name` FROM `agents`")
                for r in cur.fetchall() or []:
                    code = str(r.get("agent_code"))
                    name = str(r.get("agent_name") or code)
                    name_map[code] = name
        finally:
            conn_info.close()

        results: List[Dict[str, Any]] = []
        for ac in agents:
            an = name_map.get(ac, ac)
            results.append(_run_single_agent(args, ac, an, started_at))

        print(json.dumps({
            "mode": "ALL",
            "upload_id": args.upload_id,
            "month_year": args.month_year,
            "out": args.out,
            "count": len(results),
            "results": results,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }, indent=2))
    else:
        # Single agent mode
        if not args.agent_name:
            ap.error("--agent-name is required in SINGLE mode")
        result = _run_single_agent(args, args.agent_code, args.agent_name, started_at)
        print(json.dumps(result, indent=2))

def _run_single_agent(args: Any, agent_code: str, agent_name: str, started_at: str) -> Dict[str, Any]:
    # Compute expected rows (all agents for upload)
    rows = compute_expected_for_upload_dynamic(args.upload_id)
    if args.verbose:
        print(f"[compute-{agent_code}] rows: {len(rows)}")

    # Filter for this agent
    rows_agent = [r for r in rows if r.get('agent_code') == agent_code]

    # Insert expected rows (unless dry-run)
    inserted = 0
    if not args.dry_run:
        inserted = insert_expected_rows(rows_agent)
    if args.verbose:
        print(f"[insert-{agent_code}] inserted: {inserted}")

    # Render PDF (unless skip)
    pdf_meta = None
    if not args.skip_pdf:
        pdf_meta = local_and_gcs(agent_code, agent_name, args.month_year, Path(args.out), args.user_id)
    if args.verbose:
        print(f"[pdf-{agent_code}] {pdf_meta}")

    # Summary & monthly_reports insert
    summary = compute_month_summary(agent_code, args.month_year)
    report_period = _period_key_from_month_year(args.month_year) or args.month_year.replace('COM_', '').replace(' ', '-')

    conn = get_conn()
    try:
        _insert_monthly_report_row(
            conn=conn,
            agent_code=agent_code,
            agent_name=agent_name,
            report_period=report_period,
            upload_id=args.upload_id,
            summary=summary,
            pdf_path=(pdf_meta or {}).get('pdf_path') if pdf_meta else None,
        )
    finally:
        conn.close()

    # >>> Added: emit discrepancies immediately after monthly_reports insert
    from src.audit.discrepancies import emit_discrepancies_for_month
    emit_discrepancies_for_month(agent_code, args.month_year)
    # <<< End added

    # Monitoring log
    record = {
        "started_at": started_at,
        "ended_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "status": "SUCCESS",
        "message": None,
        "upload_id": args.upload_id,
        "agent_code": agent_code,
        "report_period": report_period,
        "expected_rows_computed": len(rows_agent),
        "expected_rows_inserted": inserted,
        "pdf_path": (pdf_meta or {}).get('pdf_path') if pdf_meta else None,
    }
    conn2 = get_conn()
    try:
        _log_cli_run_db(conn2, record)
    finally:
        conn2.close()

    return {
        "mode": "SINGLE",
        "upload_id": args.upload_id,
        "agent_code": agent_code,
        "agent_name": agent_name,
        "month_year": args.month_year,
        "report_period": report_period,
        "expected_rows_computed": record["expected_rows_computed"],
        "expected_rows_inserted": inserted,
        "pdf": pdf_meta or None,
        "summary": summary,
        "timestamp": record["ended_at"],
    }

if __name__ == "__main__":
    main()
# ===== END FILE: cli\expected_for_upload.py =====

################################################################################
# ===== FILE: cli\export_all_py_to_txt.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\export_all_py_to_txt.py
# SIZE: 5,066 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/export_all_py_to_txt.py
import argparse
import hashlib
import os
from pathlib import Path
from datetime import datetime
from typing import List, Set  # <-- added

DEFAULT_EXCLUDES = {'.venv', '.git', '__pycache__', '.vscode'}
INCLUDE_EXTS = {'.py'}

def md5_of_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()

def read_file_bytes(p: Path) -> bytes:
    # Read raw bytes to guarantee hash correctness; decode separately for text output
    with p.open('rb') as f:
        return f.read()

def decode_text(b: bytes) -> str:
    # Try UTF-8 first, then fallback with replacement to avoid crashing on odd encodings
    try:
        return b.decode('utf-8')
    except UnicodeDecodeError:
        return b.decode('utf-8', errors='replace')

def should_skip_dir(dirname: str, excludes: Set[str]) -> bool:  # <-- Set[str]
    return dirname in excludes

def collect_py_files(root: Path, excludes: Set[str]) -> List[Path]:  # <-- List[Path]
    files: List[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        # Prune excluded directories in-place for performance
        dirnames[:] = [d for d in dirnames if not should_skip_dir(d, excludes)]
        for name in filenames:
            if Path(name).suffix.lower() in INCLUDE_EXTS:
                files.append(Path(dirpath) / name)
    return sorted(files)

def format_header(rel_path: Path, size: int, digest: str) -> str:
    return (
        "\n"
        "======================================================================\n"
        f"FILE: {rel_path.as_posix()}\n"
        f"SIZE: {size} bytes | MD5: {digest}\n"
        "======================================================================\n"
    )

def add_line_numbers(text: str) -> str:
    lines = text.splitlines()
    width = len(str(len(lines)))
    return "\n".join(f"{str(i+1).rjust(width)} | {line}" for i, line in enumerate(lines))

def main():
    parser = argparse.ArgumentParser(
        description="Export the full source of every .py under a project to a single TXT (and optionally per-file TXTs)."
    )
    parser.add_argument(
        "--root", type=str, default=None,
        help="Project root to scan. Default: auto-detected (two levels up from this file)."
    )
    parser.add_argument(
        "--per-file", action="store_true",
        help="Also create one .txt per .py under exports/by_file/."
    )
    parser.add_argument(
        "--include-lines", action="store_true",
        help="Include line numbers in the combined output."
    )
    parser.add_argument(
        "--exclude", action="append", default=[],
        help="Extra directory name(s) to exclude (repeat flag to add multiple)."
    )

    args = parser.parse_args()

    # Auto-detect project root: src/cli -> src -> project root
    default_root = Path(__file__).resolve().parents[2]
    root = Path(args.root).resolve() if args.root else default_root

    # Build excludes
    excludes: Set[str] = set(DEFAULT_EXCLUDES)
    excludes.update(set(args.exclude or []))

    # Prepare export folders
    exports_dir = root / "exports"
    by_file_dir = exports_dir / "by_file"
    exports_dir.mkdir(exist_ok=True)
    if args.per_file:
        by_file_dir.mkdir(parents=True, exist_ok=True)

    # Collect files
    py_files = collect_py_files(root, excludes)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_out = exports_dir / f"ALL_PY_SOURCES_{ts}.txt"

    # Write combined
    total_bytes = 0
    with combined_out.open("w", encoding="utf-8") as out:
        header = f"Project Python sources export  {root}\nGenerated: {datetime.now().isoformat()}\n"
        out.write(header)
        out.write("-" * len(header) + "\n")

        for p in py_files:
            rel = p.relative_to(root)
            raw = read_file_bytes(p)
            text = decode_text(raw)
            digest = md5_of_bytes(raw)
            size = len(raw)
            total_bytes += size

            out.write(format_header(rel, size, digest))
            out.write(add_line_numbers(text) if args.include_lines else text)
            out.write("\n")  # trailing newline per file

            # Optional per-file export
            if args.per_file:
                target = by_file_dir / f"{rel.as_posix().replace('/', '__')}.txt"
                target.parent.mkdir(parents=True, exist_ok=True)
                with target.open("w", encoding="utf-8") as tf:
                    tf.write(format_header(rel, size, digest))
                    tf.write(add_line_numbers(text) if args.include_lines else text)
                    tf.write("\n")

    print(f"Scanned {len(py_files)} Python files under: {root}")
    print(f"Excluded dirs: {sorted(excludes)}")
    print(f"Combined export written to: {combined_out}")
    if args.per_file:
        print(f"Per-file exports written under: {by_file_dir}")
    print(f"Total bytes aggregated: {total_bytes:,}")

if __name__ == "__main__":
    main()
# ===== END FILE: cli\export_all_py_to_txt.py =====

################################################################################
# ===== FILE: cli\export_insurancelocal_py_no_tree.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\export_insurancelocal_py_no_tree.py
# SIZE: 4,265 bytes
# ENCODING: utf-8
# ===== START =====
import hashlib
import os
from pathlib import Path
from datetime import datetime
from typing import List, Set

# Root of the project to scan
PROJECT_ROOT = Path(r"D:\PROJECT\INSURANCELOCAL")

# Exclusions (directory names only, not full paths)
EXCLUDES_DIR: Set[str] = {'.git', '.venv', '__pycache__', '.vscode'}
EXCLUDES_FILE: Set[str] = {'Thumbs.db'}
INCLUDE_EXTS = {'.py'}

# Specific file(s) to ignore, relative to PROJECT_ROOT
EXCLUDE_FILES_REL: Set[Path] = {
    Path("src/__init__.py"),
}


# -------------------------
# Helpers: file reading & hashing
# -------------------------
def md5_of_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()


def read_file_bytes(p: Path) -> bytes:
    with p.open('rb') as f:
        return f.read()


def decode_text(b: bytes) -> str:
    try:
        return b.decode('utf-8')
    except UnicodeDecodeError:
        return b.decode('utf-8', errors='replace')


# -------------------------
# Helpers: file collection
# -------------------------
def should_skip_dir(dirname: str, excludes: Set[str]) -> bool:
    return dirname in excludes


def collect_py_files(root: Path, excludes: Set[str]) -> List[Path]:
    files: List[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        # Prune excluded directories in-place
        dirnames[:] = [d for d in dirnames if not should_skip_dir(d, excludes)]
        for name in filenames:
            if Path(name).suffix.lower() in INCLUDE_EXTS:
                full_path = Path(dirpath) / name
                rel_path = full_path.relative_to(root)

                # Skip specific excluded files (e.g. src/__init__.py)
                if rel_path in EXCLUDE_FILES_REL:
                    continue

                files.append(full_path)
    return sorted(files)


# -------------------------
# Helpers: formatting
# -------------------------
def format_header(rel_path: Path, size: int, digest: str) -> str:
    return (
        "\n"
        "======================================================================\n"
        f"FILE: {rel_path.as_posix()}\n"
        f"SIZE: {size} bytes | MD5: {digest}\n"
        "======================================================================\n"
    )


def add_line_numbers(text: str) -> str:
    lines = text.splitlines()
    width = len(str(len(lines)))
    return "\n".join(f"{str(i + 1).rjust(width)} | {line}" for i, line in enumerate(lines))


# -------------------------
# Main routine
# -------------------------
def main() -> None:
    root = PROJECT_ROOT

    if not root.exists() or not root.is_dir():
        raise SystemExit(f"Project root does not exist or is not a directory: {root}")

    # Prepare export folder
    exports_dir = root / "exports"
    exports_dir.mkdir(parents=True, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_out = exports_dir / f"ALL_PY_SOURCES_{ts}.txt"

    # Collect .py files
    excludes: Set[str] = set(EXCLUDES_DIR)
    py_files = collect_py_files(root, excludes)

    total_bytes = 0

    with combined_out.open("w", encoding="utf-8") as out:
        header = (
            f"Project Python sources export  {root}\n"
            f"Generated: {datetime.now().isoformat()}\n"
            f"Excluded dirs: {sorted(excludes)}\n"
            f"Excluded files: {[p.as_posix() for p in EXCLUDE_FILES_REL]}\n"
        )
        out.write(header)
        out.write("-" * len(header) + "\n\n")

        for p in py_files:
            rel = p.relative_to(root)
            raw = read_file_bytes(p)
            text = decode_text(raw)
            digest = md5_of_bytes(raw)
            size = len(raw)
            total_bytes += size

            out.write(format_header(rel, size, digest))
            # If you don't want line numbers, change the next line to: out.write(text)
            out.write(add_line_numbers(text))
            out.write("\n")  # trailing newline per file

    print(f"Scanned {len(py_files)} Python files under: {root}")
    print(f"Excluded dirs: {sorted(excludes)}")
    print(f"Excluded files: {[p.as_posix() for p in EXCLUDE_FILES_REL]}")
    print(f"Combined export written to: {combined_out}")
    print(f"Total bytes aggregated from .py files: {total_bytes:,}")


if __name__ == "__main__":
    main()
# ===== END FILE: cli\export_insurancelocal_py_no_tree.py =====

################################################################################
# ===== FILE: cli\export_insurancelocal_py_no_tree_md.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\export_insurancelocal_py_no_tree_md.py
# SIZE: 6,943 bytes
# ENCODING: utf-8
# ===== START =====
import hashlib
import os
from pathlib import Path
from datetime import datetime
from typing import List, Set

# Root of the project to scan
PROJECT_ROOT = Path(r"D:\PROJECT\INSURANCELOCAL")

# Exclusions (directory names only, not full paths)
EXCLUDES_DIR: Set[str] = {'.git', '.venv', '__pycache__', '.vscode'}
EXCLUDES_FILE: Set[str] = {'Thumbs.db'}
INCLUDE_EXTS = {'.py'}

# Specific file(s) to ignore, relative to PROJECT_ROOT
EXCLUDE_FILES_REL: Set[Path] = {
    Path("src/__init__.py"),
}


# -------------------------
# Helpers: size formatting
# -------------------------
def fmt_size(n: int) -> str:
    """Return a human-readable file size string like '10 KB'."""
    size = float(n)
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size < 1024.0:
            return f"{size:.0f} {unit}"
        size /= 1024.0
    return f"{size:.0f} PB"


# -------------------------
# Helpers: project tree
# -------------------------
def build_tree_lines(root: Path) -> List[str]:
    """
    Build a tree representation of the directory structure starting at root.
    Returns a list of lines (strings). Does not print to stdout.
    """
    lines: List[str] = []

    def _walk(current: Path, prefix: str = "") -> None:
        entries = []
        for p in sorted(current.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):
            name = p.name
            if p.is_dir() and name in EXCLUDES_DIR:
                continue
            if p.is_file() and name in EXCLUDES_FILE:
                continue
            entries.append(p)

        count = len(entries)
        for i, p in enumerate(entries):
            is_last = (i == count - 1)
            connector = " " if is_last else " "
            if p.is_dir():
                line = f"{prefix}{connector}{p.name}/"
                lines.append(line)
                extension = "    " if is_last else "   "
                _walk(p, prefix + extension)
            else:
                try:
                    stat = p.stat()
                    size_str = fmt_size(stat.st_size)
                    mtime = datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
                    line = f"{prefix}{connector}{p.name}    [{size_str} | {mtime}]"
                except OSError:
                    line = f"{prefix}{connector}{p.name}"
                lines.append(line)

    header = f"Project tree for: {root}"
    underline = "-" * len(header)
    lines.append(header)
    lines.append(underline)
    _walk(root)
    lines.append("")  # blank line after tree
    return lines


# -------------------------
# Helpers: file reading & hashing
# -------------------------
def md5_of_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()


def read_file_bytes(p: Path) -> bytes:
    with p.open('rb') as f:
        return f.read()


def decode_text(b: bytes) -> str:
    try:
        return b.decode('utf-8')
    except UnicodeDecodeError:
        return b.decode('utf-8', errors='replace')


# -------------------------
# Helpers: file collection
# -------------------------
def should_skip_dir(dirname: str, excludes: Set[str]) -> bool:
    return dirname in excludes


def collect_py_files(root: Path, excludes: Set[str]) -> List[Path]:
    files: List[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        # Prune excluded directories in-place
        dirnames[:] = [d for d in dirnames if not should_skip_dir(d, excludes)]
        for name in filenames:
            if Path(name).suffix.lower() in INCLUDE_EXTS:
                full_path = Path(dirpath) / name
                rel_path = full_path.relative_to(root)

                # Skip specific excluded files (e.g. src/__init__.py)
                if rel_path in EXCLUDE_FILES_REL:
                    continue

                files.append(full_path)
    return sorted(files)


# -------------------------
# Helpers: formatting
# -------------------------
def format_file_header(rel_path: Path, size: int, digest: str) -> str:
    """
    Header for each file in the combined TXT.
    """
    return (
        "\n"
        "======================================================================\n"
        f"FILE: {rel_path.as_posix()}\n"
        f"SIZE: {size} bytes | MD5: {digest}\n"
        "======================================================================\n"
    )


def add_line_numbers(text: str) -> str:
    """
    Optional: add line numbers to each file body.
    If you don't want line numbers, just return text.
    """
    lines = text.splitlines()
    width = len(str(len(lines))) or 1
    return "\n".join(f"{str(i + 1).rjust(width)} | {line}" for i, line in enumerate(lines))


# -------------------------
# Main routine
# -------------------------
def main() -> None:
    root = PROJECT_ROOT

    if not root.exists() or not root.is_dir():
        raise SystemExit(f"Project root does not exist or is not a directory: {root}")

    # Prepare export folder
    exports_dir = root / "exports"
    exports_dir.mkdir(parents=True, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_out = exports_dir / f"ALL_PY_SOURCES_{ts}.txt"

    # Collect tree lines
    tree_lines = build_tree_lines(root)

    # Collect .py files
    excludes: Set[str] = set(EXCLUDES_DIR)
    py_files = collect_py_files(root, excludes)

    total_bytes = 0

    with combined_out.open("w", encoding="utf-8") as out:
        # Write project tree first
        for line in tree_lines:
            out.write(line + "\n")

        # Extra separator between tree and sources section
        out.write("\n\n")
        out.write("########## PYTHON SOURCES ##########\n")
        out.write(f"Root: {root}\n")
        out.write(f"Generated: {datetime.now().isoformat()}\n")
        out.write(f"Excluded dirs: {sorted(excludes)}\n")
        out.write(f"Excluded files: {[p.as_posix() for p in EXCLUDE_FILES_REL]}\n")
        out.write("####################################\n\n")

        # Then write every .py file body
        for p in py_files:
            rel = p.relative_to(root)
            raw = read_file_bytes(p)
            text = decode_text(raw)
            digest = md5_of_bytes(raw)
            size = len(raw)
            total_bytes += size

            out.write(format_file_header(rel, size, digest))
            # Choose whether you want line numbers:
            #   - with numbers: add_line_numbers(text)
            #   - plain:        text
            out.write(add_line_numbers(text))
            out.write("\n")  # trailing newline per file

    print(f"Scanned {len(py_files)} Python files under: {root}")
    print(f"Excluded dirs: {sorted(excludes)}")
    print(f"Excluded files: {[p.as_posix() for p in EXCLUDE_FILES_REL]}")
    print(f"Combined export (tree + sources) written to: {combined_out}")
    print(f"Total bytes aggregated from .py files: {total_bytes:,}")


if __name__ == "__main__":
    main()
# ===== END FILE: cli\export_insurancelocal_py_no_tree_md.py =====

################################################################################
# ===== FILE: cli\export_insurancelocal_py_with_tree.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\export_insurancelocal_py_with_tree.py
# SIZE: 6,015 bytes
# ENCODING: utf-8
# ===== START =====
import hashlib
import os
from pathlib import Path
from datetime import datetime
from typing import List, Set

# Root of the project to scan
PROJECT_ROOT = Path(r"D:\PROJECT\INSURANCELOCAL")

# Exclusions (directory names only, not full paths)
EXCLUDES_DIR: Set[str] = {'.git', '.venv', '__pycache__', '.vscode'}
EXCLUDES_FILE: Set[str] = {'Thumbs.db'}
INCLUDE_EXTS = {'.py'}


# -------------------------
# Helpers: size formatting
# -------------------------
def fmt_size(n: int) -> str:
    """Return a human-readable file size string like '10 KB'."""
    size = float(n)
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size < 1024.0:
            return f"{size:.0f} {unit}"
        size /= 1024.0
    return f"{size:.0f} PB"


# -------------------------
# Helpers: project tree
# -------------------------
def print_tree_to_lines(root: Path) -> List[str]:
    """
    Build a tree representation of the directory structure starting at root.
    Returns a list of lines (strings). Does not print to stdout.
    """

    lines: List[str] = []

    def _print_tree(current: Path, prefix: str = "") -> None:
        entries = []
        for p in sorted(current.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):
            name = p.name
            if p.is_dir() and name in EXCLUDES_DIR:
                continue
            if p.is_file() and name in EXCLUDES_FILE:
                continue
            entries.append(p)

        count = len(entries)
        for i, p in enumerate(entries):
            is_last = (i == count - 1)
            connector = " " if is_last else " "
            if p.is_dir():
                line = f"{prefix}{connector}{p.name}/"
                lines.append(line)
                extension = "    " if is_last else "   "
                _print_tree(p, prefix + extension)
            else:
                try:
                    stat = p.stat()
                    size_str = fmt_size(stat.st_size)
                    mtime = datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
                    line = f"{prefix}{connector}{p.name}    [{size_str} | {mtime}]"
                except OSError:
                    # Fallback if stat fails for some reason
                    line = f"{prefix}{connector}{p.name}"
                lines.append(line)

    header = f"Project tree for: {root}"
    underline = "-" * len(header)
    lines.append(header)
    lines.append(underline)
    _print_tree(root)
    lines.append("")  # blank line after tree
    return lines


# -------------------------
# Helpers: file reading & hashing
# -------------------------
def md5_of_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()


def read_file_bytes(p: Path) -> bytes:
    with p.open('rb') as f:
        return f.read()


def decode_text(b: bytes) -> str:
    try:
        return b.decode('utf-8')
    except UnicodeDecodeError:
        return b.decode('utf-8', errors='replace')


# -------------------------
# Helpers: file collection
# -------------------------
def should_skip_dir(dirname: str, excludes: Set[str]) -> bool:
    return dirname in excludes


def collect_py_files(root: Path, excludes: Set[str]) -> List[Path]:
    files: List[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        # Prune excluded directories in-place
        dirnames[:] = [d for d in dirnames if not should_skip_dir(d, excludes)]
        for name in filenames:
            if Path(name).suffix.lower() in INCLUDE_EXTS:
                files.append(Path(dirpath) / name)
    return sorted(files)


# -------------------------
# Helpers: formatting
# -------------------------
def format_header(rel_path: Path, size: int, digest: str) -> str:
    return (
        "\n"
        "======================================================================\n"
        f"FILE: {rel_path.as_posix()}\n"
        f"SIZE: {size} bytes | MD5: {digest}\n"
        "======================================================================\n"
    )


def add_line_numbers(text: str) -> str:
    lines = text.splitlines()
    width = len(str(len(lines)))
    return "\n".join(f"{str(i + 1).rjust(width)} | {line}" for i, line in enumerate(lines))


# -------------------------
# Main routine
# -------------------------
def main() -> None:
    root = PROJECT_ROOT

    if not root.exists() or not root.is_dir():
        raise SystemExit(f"Project root does not exist or is not a directory: {root}")

    # Prepare export folder
    exports_dir = root / "exports"
    exports_dir.mkdir(parents=True, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_out = exports_dir / f"ALL_PY_SOURCES_{ts}.txt"

    # Collect tree lines
    tree_lines = print_tree_to_lines(root)

    # Collect .py files
    excludes: Set[str] = set(EXCLUDES_DIR)
    py_files = collect_py_files(root, excludes)

    total_bytes = 0

    with combined_out.open("w", encoding="utf-8") as out:
        # Write project tree first
        for line in tree_lines:
            out.write(line + "\n")

        # Extra separator between tree and sources section
        out.write("\n\n")
        out.write("########## PYTHON SOURCES ##########\n")
        out.write("\n")

        for p in py_files:
            rel = p.relative_to(root)
            raw = read_file_bytes(p)
            text = decode_text(raw)
            digest = md5_of_bytes(raw)
            size = len(raw)
            total_bytes += size

            out.write(format_header(rel, size, digest))
            # If you don't want line numbers, change the next line to: out.write(text)
            out.write(add_line_numbers(text))
            out.write("\n")  # trailing newline per file

    print(f"Scanned {len(py_files)} Python files under: {root}")
    print(f"Excluded dirs: {sorted(excludes)}")
    print(f"Combined export (tree + sources) written to: {combined_out}")
    print(f"Total bytes aggregated from .py files: {total_bytes:,}")


if __name__ == "__main__":
    main()
# ===== END FILE: cli\export_insurancelocal_py_with_tree.py =====

################################################################################
# ===== FILE: cli\ingest_bulk.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\ingest_bulk.py
# SIZE: 7,460 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/ingest_bulk.py
from __future__ import annotations

import argparse
import re
from pathlib import Path
from typing import List, Dict, Any

from src.ingestion.parser_db_integration import ParserDBIntegration
from src.ingestion.run_logger import RunLogger
from src.ingestion.commission import compute_expected_for_upload_dynamic, insert_expected_rows
from src.parser.parser_db_ready_fixed_Version4 import (
    extract_statement_data,
    extract_schedule_data,
    extract_terminated_data,
)


# ---- Filename token detection ------------------------------------------------

TOKEN_MAP = {
    "statement": ["statement"],
    "schedule": ["schedule"],
    "terminated": ["terminated", "termination"],
}

def detect_type_from_name(name: str) -> str:
    """Detect doc type by filename tokens (case-insensitive)."""
    n = name.lower()
    for key, tokens in TOKEN_MAP.items():
        for t in tokens:
            if t in n:
                return key
    # Common fallback for "terminat..." fragments
    if re.search(r"terminat", n):
        return "terminated"
    raise ValueError(f"Cannot detect type from filename: {name}")


# ---- Parse helpers (Pylance-safe rows) --------------------------------------

def _normalize_rows(df) -> List[Dict[str, Any]]:
    """
    Convert a pandas DataFrame to List[Dict[str, Any]] with all keys coerced to str,
    satisfying Pylance's invariance for List[Dict[str, Any]].
    """
    rows_raw = [] if df is None else df.to_dict(orient="records")
    rows: List[Dict[str, Any]] = [{str(k): v for k, v in r.items()} for r in rows_raw]
    return rows

def _parse_to_rows(doc_type: str, path: Path) -> List[Dict[str, Any]]:
    """Dispatch to the correct extractor and return normalized rows."""
    doc = doc_type.lower().strip()
    if doc == "statement":
        df = extract_statement_data(str(path))
    elif doc == "schedule":
        df = extract_schedule_data(str(path))
    elif doc == "terminated":
        df = extract_terminated_data(str(path))
    else:
        raise ValueError(f"Unknown doc_type: {doc_type}")
    return _normalize_rows(df)


# ---- CLI entry ---------------------------------------------------------------

def cli_main():
    ap = argparse.ArgumentParser(
        description="Bulk ingest files (parse  df_rows  ParserDBIntegration.process)"
    )
    ap.add_argument("--dir", "-d", required=True,
                    help="Directory containing files to ingest (e.g., data/incoming)")
    ap.add_argument("--dry-run", action="store_true",
                    help="Parse onlydo NOT write to DB")
    ap.add_argument("--agent-code", help="Override agent code for all files (optional)")
    ap.add_argument("--agent-name", help="Override agent name for all files (optional)")
    ap.add_argument("--month-year", help="Month label hint for all files (optional)")
    args = ap.parse_args()

    project_root = Path(__file__).resolve().parents[2]
    logger = RunLogger(project_root)
    base = Path(args.dir)

    if not base.exists() or not base.is_dir():
        raise FileNotFoundError(f"Directory not found: {base}")

    summaries: List[Dict[str, Any]] = []
    integ = ParserDBIntegration()  # current __init__ takes no arguments

    for p in sorted(base.iterdir()):
        if not p.is_file():
            continue

        try:
            # Detect doc type from filename, then parse  normalized rows
            doc_type = detect_type_from_name(p.name)
            rows = _parse_to_rows(doc_type, p)

            if args.dry_run:
                # Simulated summaryno DB writes
                summary = {
                    "type": doc_type.upper(),
                    "file": p.name,
                    "rows_parsed": len(rows),
                    "agent_code": args.agent_code or "",
                    "agent_name": args.agent_name or "",
                    "upload_id": "",
                    "rows_inserted": 0,
                    "moved_to": "",
                    "status": "DRY_RUN",
                    "error": "",
                }
                summaries.append(summary)
                logger.log_csv(summary)
                logger.log_json(summary)
                continue

            # Real ingestion via integration.process (df_rows path)
            result = integ.process(
                doc_type_key=doc_type,
                agent_code=str(args.agent_code or ""),
                agent_name=args.agent_name or None,
                df_rows=rows,
                file_path=p,
                month_year_hint=args.month_year or None,
            )

            # Standardize and log
            summary = {
                "type": doc_type.upper(),
                "file": p.name,
                "rows_parsed": len(rows),
                "agent_code": result.get("agent_code") or (args.agent_code or ""),
                "agent_name": result.get("agent_name") or (args.agent_name or ""),
                "upload_id": result.get("upload_id", ""),
                "rows_inserted": result.get("rows_inserted", 0),
                "moved_to": result.get("moved_to", ""),
                "status": "success",
                "error": "",
            }
            summaries.append(summary)
            logger.log_csv(summary)
            logger.log_json(summary)

            # Dynamic expected commissions (Statements only, not dry-run)
            if doc_type == "statement" and result.get("upload_id"):
                rows_exp = compute_expected_for_upload_dynamic(upload_id=int(result["upload_id"]))
                inserted = insert_expected_rows(rows_exp)
                logger.log_csv({
                    "type": "EXPECTED_COMMISSIONS",
                    "file": p.name,
                    "rows_parsed": len(rows_exp),
                    "agent_code": summary.get("agent_code", ""),
                    "agent_name": summary.get("agent_name", ""),
                    "upload_id": summary.get("upload_id", ""),
                    "rows_inserted": inserted,
                    "moved_to": summary.get("moved_to", ""),
                    "status": "success",
                    "error": "",
                })

        except Exception as e:
            err = {
                "type": "ERROR",
                "file": p.name,
                "rows_parsed": "",
                "agent_code": args.agent_code or "",
                "agent_name": args.agent_name or "",
                "upload_id": "",
                "rows_inserted": "",
                "moved_to": "",
                "status": "failure",
                "error": str(e),
            }
            summaries.append(err)
            logger.log_csv(err)
            logger.log_json(err)

    # Console report
    print("\n=== Bulk Ingestion Report ===")
    total = len(summaries)
    ok = sum(1 for s in summaries if s.get("status") in ("success", "DRY_RUN"))
    fail = total - ok
    print(f"Files processed: {total} | success/DRY_RUN: {ok} | failed: {fail}")
    for s in summaries:
        print(f"- {s.get('type')}: file={s.get('file')} upload_id={s.get('upload_id')} "
              f"rows_inserted={s.get('rows_inserted')} status={s.get('status')}")
    print("============================\n")


if __name__ == "__main__":
    cli_main()
# ===== END FILE: cli\ingest_bulk.py =====

################################################################################
# ===== FILE: cli\ingest_one.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\ingest_one.py
# SIZE: 4,908 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/ingest_one.py
from __future__ import annotations

import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional

from src.ingestion.parser_db_integration import ParserDBIntegration
from src.ingestion.run_logger import RunLogger
from src.parser.parser_db_ready_fixed_Version4 import (
    extract_statement_data,
    extract_schedule_data,
    extract_terminated_data,
)


def _normalize_rows(df) -> List[Dict[str, Any]]:
    """
    Convert a pandas DataFrame to List[Dict[str, Any]] with all keys coerced to str,
    satisfying Pylance's invariance for List[Dict[str, Any]].
    """
    rows_raw = [] if df is None else df.to_dict(orient="records")
    rows: List[Dict[str, Any]] = [{str(k): v for k, v in r.items()} for r in rows_raw]
    return rows


def _parse_to_rows(doc_type: str, path: Path) -> List[Dict[str, Any]]:
    doc = doc_type.lower().strip()
    if doc == "statement":
        df = extract_statement_data(str(path))
    elif doc == "schedule":
        df = extract_schedule_data(str(path))
    elif doc == "terminated":
        df = extract_terminated_data(str(path))
    else:
        raise ValueError(f"Unknown doc_type: {doc_type}")
    return _normalize_rows(df)


def cli_main():
    ap = argparse.ArgumentParser(
        description="Ingest one insurance file (parse  df_rows  ParserDBIntegration.process)"
    )
    ap.add_argument("--type", "-t", required=True, choices=["statement", "schedule", "terminated"],
                    help="Document type to parse & insert")
    ap.add_argument("--file", "-f", required=True, help="Path to PDF or text/CSV dump")
    ap.add_argument("--agent-code", help="Agent code (override). If omitted, parser output in rows is used.")
    ap.add_argument("--agent-name", help="Agent name (override)")
    ap.add_argument("--month-year", help="Month label hint (e.g., 'Jun 2025' or 'COM_JUN_2025')")
    ap.add_argument("--dry-run", action="store_true", help="Parse onlydo NOT write to DB")
    args = ap.parse_args()

    project_root = Path(__file__).resolve().parents[2]
    logger = RunLogger(project_root)

    p = Path(args.file)
    if not p.exists():
        raise FileNotFoundError(f"File not found: {p}")

    # Parse  normalized df_rows
    rows = _parse_to_rows(args.type, p)

    # DRY-RUN path: do not call process(), only log a simulated summary
    if args.dry_run:
        summary = {
            "type": args.type.upper(),
            "file": p.name,
            "rows_parsed": len(rows),
            "agent_code": args.agent_code or "",
            "agent_name": args.agent_name or "",
            "upload_id": "",
            "rows_inserted": 0,
            "moved_to": "",
            "status": "DRY_RUN",
            "error": ""
        }
        logger.log_csv(summary)
        logger.log_json(summary)
        print("\n=== Ingestion (DRY-RUN) Summary ===")
        for k, v in summary.items():
            print(f"{k}: {v}")
        print("==============================\n")
        return

    # Real ingestion: call integration.process with df_rows
    integ = ParserDBIntegration()
    try:
        result = integ.process(
            doc_type_key=args.type.lower().strip(),
            agent_code=str(args.agent_code or ""),
            agent_name=args.agent_name or None,
            df_rows=rows,
            file_path=p,
            month_year_hint=args.month_year or None,
        )

        # Standardize and log
        summary = {
            "type": args.type.upper(),
            "file": p.name,
            "rows_parsed": len(rows),
            "agent_code": result.get("agent_code") or (args.agent_code or ""),
            "agent_name": result.get("agent_name") or (args.agent_name or ""),
            "upload_id": result.get("upload_id", ""),
            "rows_inserted": result.get("rows_inserted", 0),
            "moved_to": result.get("moved_to", ""),
            "status": "success",
            "error": ""
        }
        logger.log_csv(summary)
        logger.log_json(summary)

        print("\n=== Ingestion Summary ===")
        for k, v in result.items():
            print(f"{k}: {v}")
        print("=========================\n")

    except Exception as e:
        err = {
            "type": args.type.upper(),
            "file": p.name,
            "rows_parsed": len(rows),
            "agent_code": args.agent_code or "",
            "agent_name": args.agent_name or "",
            "upload_id": "",
            "rows_inserted": 0,
            "moved_to": "",
            "status": "failure",
            "error": str(e)
        }
        logger.log_csv(err)
        logger.log_json(err)
        print("\n[ERROR] Ingestion failed:", e, "\n")
        raise


if __name__ == "__main__":
    cli_main()
# ===== END FILE: cli\ingest_one.py =====

################################################################################
# ===== FILE: cli\list_routes.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\list_routes.py
# SIZE: 1,958 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations
import argparse
from importlib import import_module
from fastapi.routing import APIRoute
from typing import List


def load_app():
    # Use your dynamic router registration main
    mod = import_module("src.main")
    return getattr(mod, "app")


def list_routes(fmt: str = "table"):
    app = load_app()
    rows: List[dict] = []
    for route in app.routes:
        if isinstance(route, APIRoute):
            # Coerce to str first so type-checkers see Iterable[str]
            methods_list: List[str] = [str(m) for m in route.methods]
            methods = ",".join(sorted(methods_list))

            tags_list: List[str] = [str(t) for t in (route.tags or [])]
            tags = ",".join(tags_list)

            path = route.path
            name = route.name
            rows.append({"methods": methods, "path": path, "name": name, "tags": tags})
    if fmt == "csv":
        print("methods,path,name,tags")
        for r in rows:
            print(f"{r['methods']},{r['path']},{r['name']},{r['tags']}")
    else:
        # pretty table
        if not rows:
            print("No routes found.")
            return
        w_m = max(6, *(len(r["methods"]) for r in rows))
        w_p = max(6, *(len(r["path"]) for r in rows))
        w_n = max(6, *(len(r["name"]) for r in rows))
        w_t = max(6, *(len(r["tags"]) for r in rows))
        print(f"{'METHODS'.ljust(w_m)}  {'PATH'.ljust(w_p)}  {'NAME'.ljust(w_n)}  {'TAGS'.ljust(w_t)}")
        print("-" * (w_m + w_p + w_n + w_t + 6))
        for r in rows:
            print(f"{r['methods'].ljust(w_m)}  {r['path'].ljust(w_p)}  {r['name'].ljust(w_n)}  {r['tags'].ljust(w_t)}")


if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="List all FastAPI routes")
    ap.add_argument("--format", choices=["table", "csv"], default="table")
    args = ap.parse_args()
    list_routes(fmt=args.format)
# ===== END FILE: cli\list_routes.py =====

################################################################################
# ===== FILE: cli\reset_password.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\reset_password.py
# SIZE: 957 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/reset_password.py
from __future__ import annotations
import argparse
from src.ingestion.db import get_conn
from src.services.auth_service import hash_password

def main():
    ap = argparse.ArgumentParser(description="Reset a user's password to Argon2")
    ap.add_argument("--user-id", type=int, required=True, help="User ID in the `users` table")
    ap.add_argument("--new-password", type=str, required=True, help="New plaintext password")
    args = ap.parse_args()

    hashed = hash_password(args.new_password)
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "UPDATE `users` SET `password_hash`=%s, `is_active`=1 WHERE `id`=%s",
                (hashed, args.user_id),
            )
        conn.commit()
        print(f"[OK] Password reset for user_id={args.user_id} (argon2).")
    finally:
        conn.close()

if __name__ == "__main__":
    main()
# ===== END FILE: cli\reset_password.py =====

################################################################################
# ===== FILE: cli\show_tree.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\show_tree.py
# SIZE: 2,097 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/show_tree.py
import os
from pathlib import Path

EXCLUDES_DIR = {'.git', '.venv', '__pycache__'}
EXCLUDES_FILE = {'Thumbs.db'}

def print_tree(root: Path, prefix: str = ""):
    # Gather entries
    entries = []
    for p in sorted(root.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):
        name = p.name
        if p.is_dir() and name in EXCLUDES_DIR:
            continue
        if p.is_file() and name in EXCLUDES_FILE:
            continue
        entries.append(p)

    count = len(entries)
    for i, p in enumerate(entries):
        is_last = (i == count - 1)
        connector = " " if is_last else " "
        print(prefix + connector + p.name)
        if p.is_dir():
            extension = "    " if is_last else "   "
            print_tree(p, prefix + extension)

def main():
    root = Path(__file__).resolve().parents[2]  # go up from src/cli to project root
    print(f"Project tree for: {root}\n")
    print_tree(root)

    # Also write to file for sharing/reference
    out = root / "project_tree.txt"
    with out.open("w", encoding="utf-8") as f:
        # Capture the same output
        def write_tree(r: Path, prefix: str = ""):
            entries = []
            for p in sorted(r.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):
                name = p.name
                if p.is_dir() and name in EXCLUDES_DIR:
                    continue
                if p.is_file() and name in EXCLUDES_FILE:
                    continue
                entries.append(p)
            count = len(entries)
            for i, p in enumerate(entries):
                is_last = (i == count - 1)
                connector = " " if is_last else " "
                f.write(prefix + connector + p.name + "\n")
                if p.is_dir():
                    extension = "    " if is_last else "   "
                    write_tree(p, prefix + extension)
        write_tree(root)
    print(f"\nSaved to {out}")

if __name__ == "__main__":
    main()
# ===== END FILE: cli\show_tree.py =====

################################################################################
# ===== FILE: cli\show_tree_detailed.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\cli\show_tree_detailed.py
# SIZE: 2,061 bytes
# ENCODING: utf-8
# ===== START =====

# src/cli/show_tree_detailed.py
import os
from pathlib import Path
from datetime import datetime

EXCLUDES_DIR = {'.git', '.venv', '__pycache__'}
EXCLUDES_FILE = {'Thumbs.db'}

def fmt_size(n: int) -> str:
    for unit in ['B','KB','MB','GB','TB']:
        if n < 1024.0:
            return f"{n:.0f} {unit}"
        n /= 1024.0
    return f"{n:.0f} PB"

def print_tree(root: Path, prefix: str = "", lines = None):
    entries = []
    for p in sorted(root.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):
        name = p.name
        if p.is_dir() and name in EXCLUDES_DIR:
            continue
        if p.is_file() and name in EXCLUDES_FILE:
            continue
        entries.append(p)

    count = len(entries)
    for i, p in enumerate(entries):
        is_last = (i == count - 1)
        connector = " " if is_last else " "
        if p.is_dir():
            line = f"{prefix}{connector}{p.name}/"
            print(line)
            if lines is not None: lines.append(line)
            extension = "    " if is_last else "   "
            print_tree(p, prefix + extension, lines)
        else:
            size = fmt_size(p.stat().st_size)
            mtime = datetime.fromtimestamp(p.stat().st_mtime).strftime("%Y-%m-%d %H:%M")
            line = f"{prefix}{connector}{p.name}    [{size} | {mtime}]"
            print(line)
            if lines is not None: lines.append(line)

def main():
    # Go up two levels from this file to project root (src/cli -> src -> root)
    root = Path(__file__).resolve().parents[2]
    header = f"Project tree for: {root}"
    print(header)
    print("-" * len(header))
    lines = [header, "-" * len(header)]
    print_tree(root, lines=lines)

    # Save alongside project root for alignment
    out = root / "project_tree_detailed.txt"
    with out.open("w", encoding="utf-8") as f:
        for line in lines:
            f.write(line + "\n")
    print(f"\nSaved a copy to: {out}")

if __name__ == "__main__":
    main()
# ===== END FILE: cli\show_tree_detailed.py =====

################################################################################
# ===== FILE: ingestion\__init__.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ingestion\__init__.py
# SIZE: 0 bytes
# ENCODING: utf-8
# ===== START =====

# ===== END FILE: ingestion\__init__.py =====

################################################################################
# ===== FILE: ingestion\audit_flags.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ingestion\audit_flags.py
# SIZE: 3,007 bytes
# ENCODING: utf-8
# ===== START =====

# src/ingestion/audit_flags.py
from __future__ import annotations
from typing import Optional, Dict, List
from datetime import datetime
from .db import get_conn

def emit_supposed_to_be_terminated(period_date_iso: str) -> int:
    """
    Flag policies that appear in `statement` AFTER their recorded termination_date.
    period_date_iso: 'YYYY-MM-DD' anchor for the month being audited (e.g., '2025-07-28').
    """
    conn = get_conn()
    try:
        inserted = 0
        with conn.cursor() as cur:
            # Find policies terminated on or before period, but still present in statements after that termination
            cur.execute("""
                SELECT s.`policy_no`, s.`agent_code`, s.`MONTH_YEAR`, s.`statement_id`
                FROM `statement` s
                JOIN `terminated` t ON t.`policy_no` = s.`policy_no`
                WHERE t.`termination_date` IS NOT NULL
                  AND s.`period_date` > t.`termination_date`
            """)
            rows = cur.fetchall()
            for r in rows:
                cur.execute("""
                    INSERT INTO `audit_flags`
                    (`agent_code`,`policy_no`,`month_year`,`flag_type`,`severity`,`flag_detail`,`created_at`,`resolved`)
                    VALUES (%s,%s,%s,%s,%s,%s,NOW(),0)
                """, (
                    r.get('agent_code'), r.get('policy_no'), r.get('MONTH_YEAR'),
                    'SUPPOSED_TO_BE_TERMINATED', 'high',
                    'Appeared in statement after termination date'
                ))
                inserted += cur.rowcount
        conn.commit()
        return inserted
    finally:
        conn.close()

def emit_multiple_entries_in_month(period_month_year: str) -> int:
    """
    Flag policies that appear multiple times in the same MONTH_YEAR (duplicate rows).
    """
    conn = get_conn()
    try:
        inserted = 0
        with conn.cursor() as cur:
            cur.execute("""
                SELECT s.`policy_no`, s.`agent_code`, s.`MONTH_YEAR`, COUNT(*) AS cnt
                FROM `statement` s
                WHERE s.`MONTH_YEAR`=%s
                GROUP BY s.`policy_no`, s.`agent_code`, s.`MONTH_YEAR`
                HAVING cnt > 1
            """, (period_month_year,))
            rows = cur.fetchall()
            for r in rows:
                cur.execute("""
                    INSERT INTO `audit_flags`
                    (`agent_code`,`policy_no`,`month_year`,`flag_type`,`severity`,`flag_detail`,`created_at`,`resolved`)
                    VALUES (%s,%s,%s,%s,%s,%s,NOW(),0)
                """, (
                    r.get('agent_code'), r.get('policy_no'), r.get('MONTH_YEAR'),
                    'MULTIPLE_ENTRIES_IN_MONTH', 'medium',
                    f"Duplicate entries in month; count={r.get('cnt')}"
                ))
                inserted += cur.rowcount
        conn.commit()
        return inserted
    finally:
        conn.close()
# ===== END FILE: ingestion\audit_flags.py =====

################################################################################
# ===== FILE: ingestion\commission.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ingestion\commission.py
# SIZE: 9,300 bytes
# ENCODING: utf-8
# ===== START =====

# src/ingestion/commission.py
from __future__ import annotations

from datetime import datetime, date
from typing import Dict, List, Optional, Tuple, Any, Union
from decimal import Decimal, ROUND_HALF_UP
import calendar

from src.ingestion.db import get_conn

Rule = Dict[str, Any]

MONTHS = {
    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
    'jul': 7, 'aug': 8, 'sep': 9, 'sept': 9, 'oct': 10, 'nov': 11, 'dec': 12
}


def _parse_date(s: Optional[Union[str, date, datetime]]) -> Optional[datetime]:
    if s is None:
        return None
    if isinstance(s, datetime):
        return s
    if isinstance(s, date):
        return datetime(s.year, s.month, s.day)
    try:
        return datetime.strptime(str(s), '%Y-%m-%d')
    except Exception:
        return None


def _period_date_from_month_year(month_year: Optional[str]) -> Optional[datetime]:
    if not month_year:
        return None
    s = str(month_year).strip()
    import re
    m = re.search(r'COM_([A-Za-z]{3})_(\d{4})', s, flags=re.IGNORECASE)
    if not m:
        m = re.search(r'([A-Za-z]{3,9})\s+(\d{4})', s, flags=re.IGNORECASE)
    if m:
        mon = m.group(1)[:3].lower()
        yr = int(m.group(2))
        mm = MONTHS.get(mon)
        if mm:
            last_day = calendar.monthrange(yr, mm)[1]
            return datetime(yr, mm, last_day)
    return None


def load_rules(conn) -> List[Dict[str, Any]]:
    rules: List[Dict[str, Any]] = []
    with conn.cursor() as cur:
        cur.execute(
            """
            SELECT `policy_type`,`policy_name`,`month_from`,`month_to`,
                   `commission_percent`,`effective_from`,`effective_to`
            FROM `commission_rules`
            ORDER BY `policy_type`,`month_from`
            """
        )
        for r in cur.fetchall():
            rules.append(r)
    return rules


def pick_percent_by_bucket(
    rules: List[Dict[str, Any]],
    policy_type: str,
    age_months: Optional[int],
    period_dt: Optional[datetime]
) -> Optional[float]:
    if not policy_type or age_months is None:
        return None
    for rule in rules:
        if str(rule.get('policy_type', '')).upper() != str(policy_type).upper():
            continue
        mf = int(rule.get('month_from') or 0)
        mt = int(rule.get('month_to') or 0)
        if not (mf <= age_months <= mt):
            continue
        ef = _parse_date(rule.get('effective_from'))
        et = _parse_date(rule.get('effective_to'))
        if period_dt is not None:
            if ef and period_dt < ef:
                continue
            if et and period_dt > et:
                continue
        return float(rule.get('commission_percent') or 0.0)
    return None


def bucket_percent_from_com_rate(
    rules: List[Dict[str, Any]],
    policy_type: str,
    com_rate: Optional[float],
    period_dt: Optional[datetime]
) -> Optional[float]:
    if com_rate is None:
        return None
    target = float(com_rate)
    for rule in rules:
        if str(rule.get('policy_type', '')).upper() != str(policy_type).upper():
            continue
        pct = float(rule.get('commission_percent') or 0.0)
        ef = _parse_date(rule.get('effective_from'))
        et = _parse_date(rule.get('effective_to'))
        if period_dt is not None:
            if ef and period_dt < ef:
                continue
            if et and period_dt > et:
                continue
        if abs(pct - target) < 1e-6:
            return pct
    return None


def months_between(inception_iso: Optional[Union[str, date, datetime]],
                   period_dt: Optional[datetime]) -> Optional[int]:
    inc = _parse_date(inception_iso)
    if not inc or not period_dt:
        return None
    if inc > period_dt:
        return None
    return (period_dt.year - inc.year) * 12 + (period_dt.month - inc.month) + 1


def _first_seen_cache(conn, policy_nos: List[str]) -> Dict[str, Optional[datetime]]:
    if not policy_nos:
        return {}
    uniq = list(set(policy_nos))
    placeholders = ",".join(["%s"] * len(uniq))
    sql = f"""
        SELECT `policy_no`,`first_seen_date`
        FROM `active_policies`
        WHERE `policy_no` IN ({placeholders})
    """
    cache: Dict[str, Optional[datetime]] = {p: None for p in uniq}
    with conn.cursor() as cur:
        cur.execute(sql, uniq)
        for r in cur.fetchall():
            fs = r.get('first_seen_date') if r else None
            cache[r.get('policy_no')] = _parse_date(fs) if fs else None
    return cache


def compute_expected_for_upload_dynamic(upload_id: int) -> List[Dict[str, Any]]:
    conn = get_conn()
    try:
        rules = load_rules(conn)
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT `agent_code`,`policy_no`,`policy_type`,`premium`,`com_rate`,
                       `inception`,`MONTH_YEAR`,`period_date`
                FROM `statement`
                WHERE `upload_id`=%s
                """,
                (upload_id,)
            )
            rows = cur.fetchall()

        policy_nos = [str(r.get('policy_no')) for r in rows if r.get('policy_no') is not None]
        fs_cache = _first_seen_cache(conn, policy_nos)

        agg: Dict[Tuple[str, str], Decimal] = {}

        for r in rows:
            agent_code_val = r.get('agent_code')
            policy_no_val = r.get('policy_no')
            policy_type_val = r.get('policy_type')
            premium_val = r.get('premium')
            com_rate_val = r.get('com_rate')
            month_year_val = r.get('MONTH_YEAR')
            period_date_val = r.get('period_date')

            if agent_code_val is None or policy_no_val is None:
                continue
            if premium_val is None:
                continue

            agent_code = str(agent_code_val).strip()
            policy_no = str(policy_no_val).strip()
            policy_type = str(policy_type_val or "").strip()

            premium = Decimal(str(premium_val))
            com_rate: Optional[float] = float(com_rate_val) if com_rate_val is not None else None

            month_year_raw = str(month_year_val or "").strip()
            period_dt = _parse_date(period_date_val) or _period_date_from_month_year(month_year_raw)
            if period_dt is None:
                continue

            period_key = f"{period_dt.year:04d}-{period_dt.month:02d}"

            # A) via inception
            age_a = months_between(r.get('inception'), period_dt)
            pct_a = pick_percent_by_bucket(rules, policy_type, age_a, period_dt)

            # B) via com_rate
            pct_b = bucket_percent_from_com_rate(rules, policy_type, com_rate, period_dt)

            # C) via first_seen_date
            fs = fs_cache.get(policy_no)
            pct_c = None
            if fs is not None:
                age_c = (period_dt.year - fs.year) * 12 + (period_dt.month - fs.month) + 1
                pct_c = pick_percent_by_bucket(rules, policy_type, age_c, period_dt)

            if pct_a is not None:
                pct = Decimal(str(pct_a))
            elif pct_b is not None:
                pct = Decimal(str(pct_b))
            elif pct_c is not None:
                pct = Decimal(str(pct_c))
            else:
                pct = Decimal("0")

            expected_amt = (premium * pct / Decimal("100")).quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)
            key = (agent_code, period_key)
            agg[key] = agg.get(key, Decimal("0.00")) + expected_amt

        out_rows: List[Dict[str, Any]] = []
        for (agent, period), amt in agg.items():
            out_rows.append({
                'agent_code': agent,
                'period': period,                  # canonical YYYY-MM
                'expected_amount': amt,            # Decimal for DECIMAL(12,2)
                'calc_basis': f'dynamic; rules={len(rules)}; upload_id={upload_id}',
                'upload_id': upload_id,
            })
        return out_rows
    finally:
        conn.close()


def insert_expected_rows(rows: List[Dict[str, Any]]) -> int:
    if not rows:
        return 0

    for r in rows:
        if not r.get('period') or r.get('upload_id') is None:
            raise ValueError(f"Row missing required keys: period={r.get('period')} upload_id={r.get('upload_id')}")

    conn = get_conn()
    try:
        with conn.cursor() as cur:
            params = [
                (r['agent_code'], r['period'], r['expected_amount'], r.get('calc_basis'), r['upload_id'])
                for r in rows
            ]
            cur.executemany(
                """
                INSERT INTO `expected_commissions`
                (`agent_code`,`period`,`expected_amount`,`calc_basis`,`upload_id`)
                VALUES (%s,%s,%s,%s,%s)
                ON DUPLICATE KEY UPDATE
                  `expected_amount`=VALUES(`expected_amount`),
                  `calc_basis`=VALUES(`calc_basis`)
                """,
                params
            )
        conn.commit()
        return len(rows)
    finally:
        conn.close()
# ===== END FILE: ingestion\commission.py =====

################################################################################
# ===== FILE: ingestion\db.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ingestion\db.py
# SIZE: 829 bytes
# ENCODING: utf-8
# ===== START =====
# src/ingestion/db.py
import os
import pymysql
from dotenv import load_dotenv

load_dotenv()

def get_conn():
    """Get a raw pymysql connection for legacy code."""
    user = os.getenv("DB_USER")
    password = os.getenv("DB_PASSWORD")
    host = os.getenv("DB_HOST", "localhost")
    database = os.getenv("DB_NAME", "railway")
    port = int(os.getenv("DB_PORT", "3306"))
    
    #  Type-safe:  Validate required env vars
    if not user or not password: 
        raise ValueError("DB_USER and DB_PASSWORD must be set in environment variables")
    
    return pymysql.connect(
        host=host,
        user=user,
        password=password,
        database=database,
        port=port,
        charset="utf8mb4",
        autocommit=False,
        cursorclass=pymysql.cursors.DictCursor
    )
# ===== END FILE: ingestion\db.py =====

################################################################################
# ===== FILE: ingestion\parser_db_integration.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ingestion\parser_db_integration.py
# SIZE: 12,931 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime, date

from src.ingestion.db import get_conn
from src.ingestion.run_logger import RunLogger

MONTHS = {
    "jan": 1,
    "feb": 2,
    "mar": 3,
    "apr": 4,
    "may": 5,
    "jun": 6,
    "jul": 7,
    "aug": 8,
    "sep": 9,
    "sept": 9,
    "oct": 10,
    "nov": 11,
    "dec": 12,
}


def _first_of_month_from_label(label: Optional[str]) -> Optional[date]:
    if not label:
        return None
    s = str(label).strip()
    parts = s.split()
    if len(parts) == 2 and parts[1].isdigit():
        mon = parts[0][:3].lower()
        mm = MONTHS.get(mon)
        if mm:
            return date(int(parts[1]), mm, 1)
    s2 = s.replace("-", "_")
    toks = s2.split("_")
    if len(toks) >= 3 and toks[-2].isalpha() and toks[-1].isdigit():
        mon = toks[-2][:3].lower()
        mm = MONTHS.get(mon)
        if mm:
            return date(int(toks[-1]), mm, 1)
    return None


def _infer_agent_code(rows: List[Dict[str, Any]], fallback: str) -> str:
    for r in rows:
        for k in ("agent_code", "AgentCode", "AGENT_CODE"):
            v = r.get(k)
            if isinstance(v, str) and v.strip():
                return v.strip()
    return fallback or ""


def _infer_month_year(rows: List[Dict[str, Any]], hint: Optional[str]) -> Optional[str]:
    if hint:
        return hint
    for r in rows:
        for k in ("MONTH_YEAR", "month_year", "MonthYear"):
            val = r.get(k)
            if isinstance(val, str) and val.strip():
                s = val.strip()
                s2 = s.replace("-", "_")
                toks = s2.split("_")
                # e.g. COM_JUL_2025 or JUL_2025
                if len(toks) >= 3 and toks[-2].isalpha() and toks[-1].isdigit():
                    mon = toks[-2].title()[:3]
                    return f"{mon} {toks[-1]}"
                parts = s.split()
                if len(parts) == 2 and parts[1].isdigit():
                    return f"{parts[0].title()[:3]} {parts[1]}"
                return s
    return None


def _safe_str(v: Any) -> Optional[str]:
    if v is None:
        return None
    s = str(v).strip()
    return s if s else None


def _decimal_or_none(v: Any) -> Optional[float]:
    try:
        if v is None or (isinstance(v, str) and not v.strip()):
            return None
        return float(str(v).replace(",", ""))
    except Exception:
        return None


class ParserDBIntegration:
    """
    Persist parsed rows to MySQL (uploads + row tables), or return a summary if DB is down.
    """

    def process(
        self,
        doc_type_key: str,
        agent_code: str,
        agent_name: Optional[str],
        df_rows: List[Dict[str, Any]],
        file_path: Path,
        month_year_hint: Optional[str],
    ) -> Dict[str, Any]:
        doc = (doc_type_key or "").lower().strip()
        if doc not in ("statement", "schedule", "terminated"):
            raise ValueError(f"Unsupported doc_type_key '{doc_type_key}'")

        eff_agent_code = _infer_agent_code(df_rows, agent_code)
        eff_agent_name = agent_name or eff_agent_code or None
        month_label = _infer_month_year(df_rows, month_year_hint)
        first_of_month = _first_of_month_from_label(month_label)

        upload_id: Optional[int] = None
        rows_inserted = 0

        project_root = Path(__file__).resolve().parents[2]
        logger = RunLogger(project_root)

        try:
            # --- DB writes ---
            conn = get_conn()
            try:
                # uploads
                with conn.cursor() as cur:
                    cur.execute(
                        """
                        INSERT INTO `uploads`
                        (`agent_code`,`AgentName`,`doc_type`,`FileName`,
                         `UploadTimestamp`,`month_year`,`is_active`)
                        VALUES (%s,%s,%s,%s,NOW(),%s,1)
                        """,
                        (
                            _safe_str(eff_agent_code),
                            _safe_str(eff_agent_name),
                            doc.upper(),
                            Path(file_path).name,
                            _safe_str(month_label),
                        ),
                    )
                    upload_id = cur.lastrowid

                # rows
                with conn.cursor() as cur:
                    if doc == "statement":
                        for r in df_rows:
                            cur.execute(
                                """
                                INSERT INTO `statement`
                                (`upload_id`,`agent_code`,`policy_no`,`holder`,
                                 `policy_type`,`pay_date`,`receipt_no`,
                                 `premium`,`com_rate`,`com_amt`,`inception`,
                                 `MONTH_YEAR`,`AGENT_LICENSE_NUMBER`,`period_date`)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
                                """,
                                (
                                    upload_id,
                                    _safe_str(r.get("agent_code")) or _safe_str(eff_agent_code),
                                    _safe_str(r.get("policy_no")),
                                    _safe_str(r.get("holder")),
                                    _safe_str(r.get("policy_type")),
                                    _safe_str(r.get("pay_date")),
                                    _safe_str(r.get("receipt_no")),
                                    _decimal_or_none(r.get("premium")),
                                    _decimal_or_none(r.get("com_rate")),
                                    _decimal_or_none(r.get("com_amt")),
                                    _safe_str(r.get("inception")),
                                    _safe_str(r.get("MONTH_YEAR"))
                                    or _safe_str(r.get("month_year"))
                                    or _safe_str(month_label),
                                    _safe_str(r.get("AGENT_LICENSE_NUMBER")),
                                    first_of_month,
                                ),
                            )
                        rows_inserted = len(df_rows)
                    elif doc == "schedule":
                        for r in df_rows:
                            cur.execute(
                                """
                                INSERT INTO `schedule`
                                (`upload_id`,`agent_code`,`agent_name`,
                                 `commission_batch_code`,`total_premiums`,`income`,
                                 `total_deductions`,`net_commission`,`month_year`)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
                                """,
                                (
                                    upload_id,
                                    _safe_str(r.get("agent_code")) or _safe_str(eff_agent_code),
                                    _safe_str(r.get("agent_name")) or _safe_str(eff_agent_name),
                                    _safe_str(r.get("commission_batch_code")),
                                    _decimal_or_none(r.get("total_premiums")),
                                    _decimal_or_none(r.get("income")),
                                    _decimal_or_none(r.get("total_deductions")),
                                    _decimal_or_none(r.get("net_commission")),
                                    _safe_str(r.get("month_year")) or _safe_str(month_label),
                                ),
                            )
                        rows_inserted = len(df_rows)
                    else:  # terminated
                        for r in df_rows:
                            cur.execute(
                                """
                                INSERT INTO `terminated`
                                (`upload_id`,`agent_code`,`policy_no`,`holder`,`surname`,
                                 `other_name`,`receipt_no`,`paydate`,`premium`,`com_rate`,
                                 `com_amt`,`policy_type`,`inception`,`status`,`agent_name`,
                                 `reason`,`month_year`,`AGENT_LICENSE_NUMBER`,`termination_date`)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
                                """,
                                (
                                    upload_id,
                                    _safe_str(r.get("agent_code")) or _safe_str(eff_agent_code),
                                    _safe_str(r.get("policy_no")),
                                    _safe_str(r.get("holder")),
                                    _safe_str(r.get("surname")),
                                    _safe_str(r.get("other_name")),
                                    _safe_str(r.get("receipt_no")),
                                    _safe_str(r.get("paydate")),
                                    _decimal_or_none(r.get("premium")),
                                    _decimal_or_none(r.get("com_rate")),
                                    _decimal_or_none(r.get("com_amt")),
                                    _safe_str(r.get("policy_type")),
                                    _safe_str(r.get("inception")),
                                    _safe_str(r.get("status")),
                                    _safe_str(r.get("agent_name")) or _safe_str(eff_agent_name),
                                    _safe_str(r.get("reason")),
                                    _safe_str(r.get("month_year")) or _safe_str(month_label),
                                    _safe_str(r.get("AGENT_LICENSE_NUMBER")),
                                    _safe_str(r.get("termination_date")),
                                ),
                            )
                        rows_inserted = len(df_rows)

                conn.commit()
            finally:
                conn.close()

            # --- Move file to processed/ ---
            moved_to: Optional[str] = None
            try:
                root = Path(file_path).resolve().parents[2]
                processed_dir = root / "data" / "processed"
                processed_dir.mkdir(parents=True, exist_ok=True)
                stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                out_name = f"{stamp}_{eff_agent_code or 'unknown'}_{doc}_{Path(file_path).name}"
                dest = processed_dir / out_name
                if Path(file_path).exists():
                    Path(file_path).replace(dest)
                moved_to = str(dest)
            except Exception:
                moved_to = None

            return {
                "status": "success",
                "doc_type": doc.upper(),
                "agent_code": eff_agent_code,
                "agent_name": eff_agent_name,
                "month_year": month_label,
                "upload_id": upload_id,
                "rows_inserted": rows_inserted,
                "moved_to": moved_to,
            }
        except Exception as e:
            # On DB or other failure, still try to move the file and log db_error
            moved_to: Optional[str] = None
            try:
                root = Path(file_path).resolve().parents[2]
                processed_dir = root / "data" / "processed"
                processed_dir.mkdir(parents=True, exist_ok=True)
                stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                out_name = f"{stamp}_{eff_agent_code or 'unknown'}_{doc}_{Path(file_path).name}"
                dest = processed_dir / out_name
                if Path(file_path).exists():
                    Path(file_path).replace(dest)
                moved_to = str(dest)
            except Exception:
                moved_to = None

            error_summary: Dict[str, Any] = {
                "status": "db_error",
                "error": str(e),
                "doc_type": doc.upper(),
                "agent_code": eff_agent_code,
                "agent_name": eff_agent_name,
                "month_year": month_label,
                "upload_id": None,
                "rows_inserted": 0,
                "moved_to": moved_to,
            }

            logger.log_json(error_summary)
            logger.log_csv(
                {
                    "type": doc.upper(),
                    "file": Path(file_path).name,
                    "rows_parsed": len(df_rows),
                    "agent_code": eff_agent_code,
                    "agent_name": eff_agent_name,
                    "upload_id": "",
                    "rows_inserted": 0,
                    "moved_to": moved_to or "",
                    "status": "db_error",
                    "error": str(e),
                }
            )
            return error_summary
# ===== END FILE: ingestion\parser_db_integration.py =====

################################################################################
# ===== FILE: ingestion\run_logger.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ingestion\run_logger.py
# SIZE: 1,986 bytes
# ENCODING: utf-8
# ===== START =====

# src/ingestion/run_logger.py
from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import Dict, Any

__all__ = ['RunLogger']

class RunLogger:
    def __init__(self, project_root: Path):
        self.root = Path(project_root)
        self.log_dir = self.root / 'logs'
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.csv_path = self.log_dir / 'ingestion.log'
        self.jsonl_path = self.log_dir / 'ingestion.jsonl'

    def _now(self) -> str:
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    def log_csv(self, payload: Dict[str, Any]) -> None:
        keys = ['ts','type','file','rows_parsed','agent_code','agent_name','upload_id',
                'rows_inserted','moved_to','status','error']
        line = {
            'ts': self._now(),
            'type': payload.get('type',''),
            'file': payload.get('file',''),
            'rows_parsed': payload.get('rows_parsed',''),
            'agent_code': payload.get('agent_code',''),
            'agent_name': payload.get('agent_name',''),
            'upload_id': payload.get('upload_id',''),
            'rows_inserted': payload.get('rows_inserted',''),
            'moved_to': payload.get('moved_to',''),
            'status': payload.get('status',''),
            'error': payload.get('error',''),
        }
        write_header = not self.csv_path.exists()
        with self.csv_path.open('a', encoding='utf-8') as f:
            if write_header:
                f.write(','.join(keys) + '\n')
            f.write(','.join(str(line[k]).replace('\n',' ').replace(',',';') for k in keys) + '\n')

    def log_json(self, payload: Dict[str, Any]) -> None:
        import json
        payload_out = dict(payload)
        payload_out['ts'] = self._now()
        with self.jsonl_path.open('a', encoding='utf-8') as f:
            f.write(json.dumps(payload_out, ensure_ascii=False) + '\n')
# ===== END FILE: ingestion\run_logger.py =====

################################################################################
# ===== FILE: main.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\main.py
# SIZE: 16,279 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

import importlib
import importlib.util
import os
import traceback
from typing import Optional, Dict, Any

from fastapi import FastAPI, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import RedirectResponse, JSONResponse
from fastapi.openapi.docs import get_swagger_ui_html
from starlette.middleware.trustedhost import TrustedHostMiddleware
from starlette.middleware.base import BaseHTTPMiddleware

from src.utils.security_headers import SecurityHeadersMiddleware
from src.utils.request_id import RequestIDMiddleware


# ---------------------------------------------------------------------------
# Import diagnostics (traceback-enabled)
# ---------------------------------------------------------------------------

IMPORT_DIAG: Dict[str, Dict[str, Any]] = {}
# Structure:
# IMPORT_DIAG[import_name] = {
#   "status": "missing" | "error" | "ok",
#   "message": "<short error str>" or None,
#   "trace": "<full traceback>" or None
# }


def _record_import_diag(import_name: str, status: str, exc: Optional[BaseException] = None) -> None:
    d: Dict[str, Any] = {"status": status, "message": None, "trace": None}
    if exc is not None:
        d["message"] = f"{type(exc).__name__}: {exc}"
        d["trace"] = traceback.format_exc()
    IMPORT_DIAG[import_name] = d


def _print_import_failure(import_name: str, friendly_label: str) -> None:
    """
    Print a clear message for router registration failure:
    - Module missing: keep the original style.
    - Import error: show short error + full traceback.
    """
    diag = IMPORT_DIAG.get(import_name)
    if not diag or diag.get("status") == "missing":
        print(f"  {friendly_label} (module missing)")
        return

    if diag.get("status") == "error":
        print(f" {friendly_label}  import failed")
        msg = diag.get("message")
        tr = diag.get("trace")
        if msg:
            print(f"     {msg}")
        if tr:
            # Print traceback on its own line(s) for readability
            print(tr)
        return

    # Fallback (shouldn't hit if status recorded properly)
    print(f"  {friendly_label} (module not registered; unknown status)")


# ---------------------------------------------------------------------------
# Optional import helpers (now with traceback logging)
# ---------------------------------------------------------------------------

def _opt_attr(module: str, attr: str):
    """
    Safely import an attribute from a module if it exists.
    Returns None if the module or attribute is missing, or if import fails.
    Also records detailed diagnostics and prints traceback on failure.
    """
    spec = importlib.util.find_spec(module)
    if not spec:
        _record_import_diag(module, "missing")
        return None
    try:
        mod = importlib.import_module(module)
        _record_import_diag(module, "ok")
        return getattr(mod, attr, None)
    except Exception as e:
        _record_import_diag(module, "error", e)
        # Print once here so errors are visible even before router registration
        print(f" Attribute import failed for {module}.{attr}")
        print(f"     {type(e).__name__}: {e}")
        print(traceback.format_exc())
        return None


def _find_router(spec_name: str, import_name: str):
    """
    Safely import a FastAPI router from a module if it exists.
    Returns None if the module or 'router' attribute is missing.
    Also records detailed diagnostics and prints traceback on failure.
    """
    spec = importlib.util.find_spec(spec_name)
    if not spec:
        _record_import_diag(import_name, "missing")
        return None
    try:
        mod = importlib.import_module(import_name)
        router = getattr(mod, "router", None)
        _record_import_diag(import_name, "ok")
        return router
    except Exception as e:
        _record_import_diag(import_name, "error", e)
        print(f" Router import failed for {import_name}")
        print(f"     {type(e).__name__}: {e}")
        print(traceback.format_exc())
        return None


# ---------------------------------------------------------------------------
# Optional auth helpers
# ---------------------------------------------------------------------------

decode_token = _opt_attr("src.services.auth_service", "decode_token")
TOKEN_COOKIE_NAME = _opt_attr("src.services.auth_service", "TOKEN_COOKIE_NAME") or "access_token"


# ---------------------------------------------------------------------------
# Routers (loaded dynamically so missing modules don't break startup)
# ---------------------------------------------------------------------------

# Core & uploads
uploads_router = _find_router("src.api.uploads", "src.api.uploads")
uploads_secure_router = _find_router("src.api.uploads_secure", "src.api.uploads_secure")
ingestion_router = _find_router("src.api.ingestion_api", "src.api.ingestion_api")

# Data APIs / explorers
agent_reports_router = _find_router("src.api.agent_reports", "src.api.agent_reports")
admin_reports_router = _find_router("src.api.admin_reports", "src.api.admin_reports")
disparities_router = _find_router("src.api.disparities", "src.api.disparities")
agent_missing_router = _find_router("src.api.agent_missing", "src.api.agent_missing")

# Wrapper APIs
agent_api_router = _find_router("src.api.agent_api", "src.api.agent_api")
superuser_api_router = _find_router("src.api.superuser_api", "src.api.superuser_api")

# Auth
auth_router = _find_router("src.api.auth_api", "src.api.auth_api")

# Admin users / agents
admin_users_router = _find_router("src.api.admin_users", "src.api.admin_users")
admin_agents_router = _find_router("src.api.admin_agents", "src.api.admin_agents")

# UI
ui_router = _find_router("src.api.ui_pages", "src.api.ui_pages")
admin_dashboard_router = _find_router("src.ui.admin_dashboard", "src.ui.admin_dashboard")
agent_dashboard_router = _find_router("src.ui.agent_dashboard", "src.ui.agent_dashboard")
superuser_dashboard_router = _find_router("src.ui.superuser_dashboard", "src.ui.superuser_dashboard")


# ---------------------------------------------------------------------------
# FastAPI application
# ---------------------------------------------------------------------------

app = FastAPI(
    title="ICRS  Insurance Commission Reconciliation System",
    description=(
        "Open (cookie-auth) API for ingesting PDFs, computing expected commissions, "
        "and generating monthly reports."
    ),
    version="1.0.0",
    # Disable public docs; we will add guarded endpoints below
    docs_url=None,
    redoc_url=None,
    openapi_url=None,
)

# CORS (dev: permissive; tighten for production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # tighten/whitelist for prod
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ---------------------------------------------------------------------------
# Proxy / HTTPS awareness & security middleware
# ---------------------------------------------------------------------------

class HTTPSRedirectAwareMiddleware(BaseHTTPMiddleware):
    """
    Trust X-Forwarded-Proto (e.g., on Railway) so generated URLs and security
    decisions see the original scheme.
    """

    async def dispatch(self, request: Request, call_next):
        if request.headers.get("x-forwarded-proto", "http") == "https":
            request.scope["scheme"] = "https"
        return await call_next(request)


# TrustedHost: start permissive, tighten in production if you have a fixed host.
app.add_middleware(TrustedHostMiddleware, allowed_hosts=["*"])

# Request ID + basic access log
app.add_middleware(RequestIDMiddleware)

# Security headers (HSTS, CSP, etc.)
app.add_middleware(SecurityHeadersMiddleware)


# ---------------------------------------------------------------------------
# Configurable docs / OpenAPI guard (merged behavior)
# ---------------------------------------------------------------------------

def require_docs_access(request: Request):
    """
    Allow viewing of /docs and /openapi.json based on role.

    - Default (no env vars): admin + superuser can see docs.
    - DOCS_PUBLIC=1        : anyone can see docs (no auth).
    - DOCS_ALLOWED_ROLES   : comma-separated list of allowed roles, e.g. "admin,superuser,agent".
    """
    # Optional environment switches
    DOCS_PUBLIC = bool(int(os.getenv("DOCS_PUBLIC", "0")))  # 1 => public
    DOCS_ALLOWED_ROLES = set(
        (os.getenv("DOCS_ALLOWED_ROLES", "admin,superuser") or "admin,superuser")
        .lower()
        .split(",")
    )

    # Public docs (e.g., dev)
    if DOCS_PUBLIC:
        return {"role": "public"}  # no auth required

    # Cookie-auth path
    if not decode_token:
        raise HTTPException(status_code=500, detail="Auth service not available")

    token = request.cookies.get(TOKEN_COOKIE_NAME)
    payload: Optional[dict] = decode_token(token) if token else None
    role = str((payload or {}).get("role") or "").lower()

    if not payload or role not in DOCS_ALLOWED_ROLES:
        raise HTTPException(status_code=403, detail="Docs access not permitted for this role")

    return payload


@app.get("/docs", include_in_schema=False)
def guarded_docs(request: Request, _=Depends(require_docs_access)):
    """
    Swagger UI, role-gated via require_docs_access.
    """
    return get_swagger_ui_html(openapi_url="/openapi.json", title="ICRS API Docs")


@app.get("/openapi.json", include_in_schema=False)
def guarded_openapi(request: Request, _=Depends(require_docs_access)):
    """
    OpenAPI JSON, role-gated via require_docs_access.
    """
    return JSONResponse(app.openapi())


# ---------------------------------------------------------------------------
# Health & Info endpoints
# ---------------------------------------------------------------------------

@app.get("/health", tags=["Health"])
def health():
    return {"status": "ok"}


@app.get("/api/info", tags=["Health"])
def api_info():
    registered = []
    if uploads_router:
        registered.append("Uploads")
    if uploads_secure_router:
        registered.append("Uploads Secure")
    if ingestion_router:
        registered.append("Ingestion")

    if agent_reports_router:
        registered.append("Agent Reports")
    if admin_reports_router:
        registered.append("Admin Reports")
    if disparities_router:
        registered.append("Disparities")
    if agent_missing_router:
        registered.append("Agent Missing")

    if agent_api_router:
        registered.append("Agent API")
    if superuser_api_router:
        registered.append("Superuser API")

    if admin_users_router:
        registered.append("Admin Users")
    if admin_agents_router:
        registered.append("Admin Agents")

    if auth_router:
        registered.append("Auth")

    if ui_router:
        registered.append("UI Landing")
    if agent_dashboard_router:
        registered.append("Agent Dashboard (UI)")
    if admin_dashboard_router:
        registered.append("Admin Dashboard (UI)")
    if superuser_dashboard_router:
        registered.append("Superuser Dashboard (UI)")

    return {
        "name": "ICRS  Insurance Commission Reconciliation System",
        "version": "1.0.0",
        "docs": "/docs (role-gated)",
        "registered_modules": registered,
        "auth": "COOKIE",
        "ui": {
            "landing": "/ui/",
            "agent": "/ui/agent",
            "admin": "/ui/admin",
            "superuser": "/ui/superuser",
        },
    }


# ---------------------------------------------------------------------------
# Router registration (preserves prefixes from your static version)
# ---------------------------------------------------------------------------

# Core & uploads
if uploads_router:
    app.include_router(uploads_router)
    print(" Uploads router registered")
else:
    _print_import_failure("src.api.uploads", "Uploads router NOT registered")

if uploads_secure_router:
    app.include_router(uploads_secure_router)
    print(" Uploads Secure router registered")
else:
    _print_import_failure("src.api.uploads_secure", "Uploads Secure router NOT registered")

# Ingestion router already has prefix="/api/ingestion" in its definition
if ingestion_router:
    app.include_router(ingestion_router)
    print(" Ingestion router registered at /api/ingestion")
else:
    _print_import_failure("src.api.ingestion_api", "Ingestion router NOT registered")

# Data APIs
if agent_reports_router:
    app.include_router(agent_reports_router)
    print(" Agent Reports router registered at /api/agent")
else:
    _print_import_failure("src.api.agent_reports", "Agent Reports router NOT registered")

if admin_reports_router:
    app.include_router(admin_reports_router)
    print(" Admin Reports router registered at /api/admin")
else:
    _print_import_failure("src.api.admin_reports", "Admin Reports router NOT registered")

if disparities_router:
    app.include_router(disparities_router)
    print(" Disparities router registered at /api/disparities")
else:
    _print_import_failure("src.api.disparities", "Disparities router NOT registered")

if agent_missing_router:
    app.include_router(agent_missing_router)
    print(" Agent Missing router registered at /api/agent")
else:
    _print_import_failure("src.api.agent_missing", "Agent Missing router NOT registered")

# Wrapper APIs
if agent_api_router:
    app.include_router(agent_api_router)
    print(" Agent API router registered at /api/agent")
else:
    _print_import_failure("src.api.agent_api", "Agent API router NOT registered")

if superuser_api_router:
    app.include_router(superuser_api_router)
    print(" Superuser API router registered at /api/superuser")
else:
    _print_import_failure("src.api.superuser_api", "Superuser API router NOT registered")

# Admin users / agents
if admin_users_router:
    app.include_router(admin_users_router)
    print(" Admin Users router registered at /api/admin/users")
else:
    _print_import_failure("src.api.admin_users", "Admin Users router NOT registered")

if admin_agents_router:
    app.include_router(admin_agents_router)
    print(" Admin Agents router registered at /api/admin/agents")
else:
    _print_import_failure("src.api.admin_agents", "Admin Agents router NOT registered")

# Auth
if auth_router:
    app.include_router(auth_router)
    print(" Auth router registered at /api/auth")
else:
    _print_import_failure("src.api.auth_api", "Auth router NOT registered")

# UI routers (landing + dashboards)
if ui_router:
    app.include_router(ui_router)
    print(" Landing (UI) registered at /ui/")
else:
    _print_import_failure("src.api.ui_pages", "Landing (UI) router NOT registered")

if agent_dashboard_router:
    app.include_router(agent_dashboard_router)
    print(" Agent Dashboard router mounted at /ui/agent")
else:
    _print_import_failure("src.ui.agent_dashboard", "Agent Dashboard router NOT mounted")

if admin_dashboard_router:
    app.include_router(admin_dashboard_router)
    print(" Admin Dashboard router mounted at /ui/admin")
else:
    _print_import_failure("src.ui.admin_dashboard", "Admin Dashboard router NOT mounted")

if superuser_dashboard_router:
    app.include_router(superuser_dashboard_router)
    print(" Superuser Dashboard router mounted at /ui/superuser")
else:
    _print_import_failure("src.ui.superuser_dashboard", "Superuser Dashboard router NOT mounted")


# ---------------------------------------------------------------------------
# Root redirect
# ---------------------------------------------------------------------------

@app.get("/", include_in_schema=False)
def root_redirect():
    return RedirectResponse(url="/ui/", status_code=302)
# ===== END FILE: main.py =====

################################################################################
# ===== FILE: models.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\models.py
# SIZE: 3,505 bytes
# ENCODING: utf-8
# ===== START =====
# src/models.py
from sqlalchemy import Column, Integer, String, Text, DateTime, Numeric, Boolean, Date, DECIMAL
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class Upload(Base):
    __tablename__ = 'uploads'
    UploadID = Column(Integer, primary_key=True, autoincrement=True)
    agent_code = Column(String(50))
    AgentName = Column(String(255))
    doc_type = Column(String(20))  # STATEMENT, SCHEDULE, TERMINATED
    FileName = Column(String(500))
    UploadTimestamp = Column(DateTime, default=datetime.now)
    month_year = Column(String(20))
    is_active = Column(Boolean, default=True)

class Statement(Base):
    __tablename__ = 'statement'
    statement_id = Column(Integer, primary_key=True, autoincrement=True)
    upload_id = Column(Integer)
    agent_code = Column(String(50))
    policy_no = Column(String(100))
    holder = Column(String(255))
    policy_type = Column(String(100))
    pay_date = Column(Date)
    receipt_no = Column(String(100))
    premium = Column(DECIMAL(15, 2))
    com_rate = Column(DECIMAL(5, 2))
    com_amt = Column(DECIMAL(15, 2))
    inception = Column(Date)
    MONTH_YEAR = Column(String(20))
    AGENT_LICENSE_NUMBER = Column(String(100))

class Schedule(Base):
    __tablename__ = 'schedule'
    schedule_id = Column(Integer, primary_key=True, autoincrement=True)
    upload_id = Column(Integer)
    agent_code = Column(String(50))
    agent_name = Column(String(255))
    commission_batch_code = Column(String(100))
    total_premiums = Column(DECIMAL(15, 2))
    income = Column(DECIMAL(15, 2))
    total_deductions = Column(DECIMAL(15, 2))
    net_commission = Column(DECIMAL(15, 2))
    month_year = Column(String(20))

class Terminated(Base):
    __tablename__ = 'terminated'
    terminated_id = Column(Integer, primary_key=True, autoincrement=True)
    upload_id = Column(Integer)
    agent_code = Column(String(50))
    policy_no = Column(String(100))
    holder = Column(String(255))
    surname = Column(String(255))
    other_name = Column(String(255))
    receipt_no = Column(String(100))
    paydate = Column(Date)
    premium = Column(DECIMAL(15, 2))
    com_rate = Column(DECIMAL(5, 2))
    com_amt = Column(DECIMAL(15, 2))
    policy_type = Column(String(100))
    inception = Column(Date)
    status = Column(String(50))
    agent_name = Column(String(255))
    reason = Column(Text)
    month_year = Column(String(20))
    AGENT_LICENSE_NUMBER = Column(String(100))
    termination_date = Column(Date)

class Agent(Base):
    __tablename__ = 'agents'
    id = Column(Integer, primary_key=True, autoincrement=True)
    agent_code = Column(String(50), unique=True, nullable=False)
    agent_name = Column(String(255))
    license_number = Column(String(100))
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.now)

class User(Base):
    __tablename__ = 'users'
    id = Column(Integer, primary_key=True, autoincrement=True)
    email = Column(String(255), unique=True, nullable=False)
    password_hash = Column(String(255), nullable=False)
    agent_code = Column(String(50))
    role = Column(String(20), default='agent')  # agent, admin, superuser
    is_active = Column(Boolean, default=True)
    is_verified = Column(Boolean, default=False)
    last_login = Column(DateTime)
    created_at = Column(DateTime, default=datetime.now)
# ===== END FILE: models.py =====

################################################################################
# ===== FILE: parser\__init__.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\parser\__init__.py
# SIZE: 0 bytes
# ENCODING: utf-8
# ===== START =====

# ===== END FILE: parser\__init__.py =====

################################################################################
# ===== FILE: parser\parser_db_ready_fixed_Version4.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\parser\parser_db_ready_fixed_Version4.py
# SIZE: 30,365 bytes
# ENCODING: utf-8
# ===== START =====
#!/usr/bin/env python3
"""
Parser (fixed)  Version4 with GUI

Changes vs Version3:
 - Robust extraction for Schedule lines that include "PREMIUM DEDUCTION" and "PENSIONS" (optional).
 - Terminated records:  normalize termination month to YYYY-MM-01 for DB DATE consistency.

GUI: 
 - select a PDF / text dump,
 - choose mode (Schedule, Terminated, Statement),
 - extract and preview results,
 - export CSV.

CLI (unchanged):
 - python parser_db_ready_fixed_Version4.py --mode Statement --input statementmayraw.csv --output statement_out.csv
 - python parser_db_ready_fixed_Version4.py --mode Schedule --input schedulerawcsv.csv --output schedule_out.csv
 - python parser_db_ready_fixed_Version4.py --mode Terminated --input terminatedraw.csv --output terminated_out.csv
"""
from pathlib import Path
import argparse
import pdfplumber
import pandas as pd
import re
import unicodedata
from datetime import datetime
from decimal import Decimal, ROUND_HALF_UP
import sys
import os

# Optional GUI deps
try:
    import tkinter as tk
    from tkinter import filedialog, messagebox, ttk
except Exception:
    tk = None

# -------------------------
# Utilities
# -------------------------
MONTHS = {
    'jan': 1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'sept':9,'oct':10,'nov':11,'dec':12
}

def to_iso_date(date_str:  str) -> str:
    """Try multiple formats; return 'YYYY-MM-DD' or ''."""
    if not date_str or not isinstance(date_str, str):
        return ""
    s = date_str.strip()
    s = unicodedata.normalize("NFKC", s)
    fmts = [
        "%Y-%m-%d","%Y/%m/%d","%d/%m/%Y","%d-%b-%y","%d-%b-%Y","%d-%B-%Y",
        "%d %b %Y","%d %B %Y","%d-%m-%Y","%d/%m/%y","%m/%d/%Y","%m-%d-%Y"
    ]
    for f in fmts:
        try:
            return datetime.strptime(s, f).strftime("%Y-%m-%d")
        except Exception:
            pass
    # month-year to first of month
    m = re.search(r'([A-Za-z]{3,9})\.?\s+(\d{4})', s)
    if m:
        mon = m.group(1).lower()[:3]
        yr = int(m.group(2))
        mm = MONTHS.get(mon)
        if mm:
            return f"{yr: 04d}-{mm:02d}-01"
    # dateutil fallback
    try:
        from dateutil import parser as du_parser
        dt = du_parser.parse(s, dayfirst=True, fuzzy=True)
        return dt.strftime("%Y-%m-%d")
    except Exception: 
        return ""

def clean_decimal_2dp(v) -> str:
    """Return '' or normalized 2dp string; handles (negative) and currency symbols."""
    if v is None:
        return ""
    s = str(v).strip()
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s)
    s = re.sub(r'[$,]', '', s)
    neg = False
    if s.startswith("(") and s.endswith(")"):
        neg = True
        s = s[1:-1]
    # last numeric blob on the line is usually the value
    m = re.search(r'(-?\d+(?:[.,]\d+)?)(?! .*\d)', s)
    if not m:
        return ""
    try:
        d = Decimal(m.group(1).replace(",", ""))
        if neg:
            d = -d
        d = d.quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)
        return format(d, "f")
    except Exception:
        return ""

def month_year_to_first_iso(month_year_str: str) -> str:
    """COM_Jul_2025 or 'Jul 2025' -> '2025-07-01' (first of month anchor)."""
    if not month_year_str or not isinstance(month_year_str, str):
        return ""
    s = month_year_str.strip()
    s = re.sub(r'\s+', ' ', s)
    # Pattern 1: "Jul 2025"
    parts = s.split()
    if len(parts) == 2 and re.match(r'^\d{4}$', parts[1]):
        mon = parts[0][: 3].lower()
        mm = MONTHS.get(mon)
        if mm:
            return f"{int(parts[1]):04d}-{mm:02d}-01"
    # Pattern 2: "COM_JUL_2025"
    m = re.search(r'COM_([A-Z]{3})_(\d{4})', s, re.IGNORECASE)
    if m:
        mon = m.group(1).lower()[: 3]
        mm = MONTHS.get(mon)
        if mm:
            return f"{int(m.group(2)):04d}-{mm:02d}-01"
    return ""

# -------------------------
# Agent metadata extraction (robust)
# -------------------------
AGENT_CODE_PATTERNS = [
    r'AGENCY\s+ACCOUNT\s+NO[:\s]*([0-9A-Z\-]+)',
    r'AGENT\s+ACCOUNT\s+NO[:\s]*([0-9A-Z\-]+)',
    r'AGENT\s+ACCONT\s+NO[:\s]*([0-9A-Z\-]+)',
    r'AGENCY\s+ACCT[:\s]*([0-9A-Z\-]+)',
    r'AGENT\s+CODE[:\s]*([0-9A-Z\-]+)'
]

ADDRESS_KEYWORDS = [
    'PO BOX','P . O . BOX','P.O. BOX','P . O .Box','BOX','CANTONMENTS','P O BOX',
    'TEL:', 'TEL', 'PHONE', 'FAX', 'FAX:', 'P.O.', 'CT', 'P.O BOX', 'TOLL-FREE', 'TOLL FREE'
]

def _line_looks_like_address(ln: str) -> bool:
    if not ln:
        return False
    s = ln.upper()
    for kw in ADDRESS_KEYWORDS: 
        if kw in s: 
            return True
    if len(re.findall(r'[A-Z]', s)) < 3 and len(re.findall(r'\d', s)) >= 3:
        return True
    if 'COMPANY' in s or ('LIFE' in s and 'SIC' in s):
        return True
    return False

def find_agent_code_from_lines(lines) -> str:
    if not lines:
        return ""
    text = "\n".join(lines)
    for p in AGENT_CODE_PATTERNS:
        m = re.search(p, text, re.IGNORECASE)
        if m:
            return m.group(1).strip()
    try:
        if len(lines) >= 7:
            target_line = lines[6]
            if not _line_looks_like_address(target_line):
                tokens = re.split(r'\s{2,}|\t|\s', target_line.strip())
                if len(tokens) >= 4:
                    candidate = re.sub(r'[^0-9A-Za-z\-]', '', tokens[3])
                    if re.match(r'^\d{3,6}$', candidate) and not re.match(r'^20\d{2}$', candidate):
                        return candidate
                tokens2 = target_line.strip().split()
                if len(tokens2) >= 4:
                    cand2 = re.sub(r'[^0-9A-Za-z\-]', '', tokens2[3])
                    if re.match(r'^\d{3,6}$', cand2) and not re.match(r'^20\d{2}$', cand2):
                        return cand2
    except Exception:
        pass
    for ln in lines[: 12]:
        if _line_looks_like_address(ln):
            continue
        m = re.search(r'\b(\d{3,6})\b', ln)
        if m:
            val = m.group(1)
            if re.match(r'^20\d{2}$', val):
                continue
            return val
    return ""

def find_agent_license_from_lines(lines) -> str:
    s = "\n".join(lines) if lines else ""
    m = re.search(r'(?:AGENT\s+LICENSE\s+NO[:\s]*|AGENCY\s+LICENSE\s+NO[:\s]*|AGENT\s+LICENSE[:\s]*)(T?\d+)', s, re.IGNORECASE)
    if m:
        return m.group(1).strip()
    m2 = re.search(r'\bT[-]?\d{3,}\b', s, re.IGNORECASE)
    if m2:
        return re.sub(r'[\s\-]', '', m2.group(0))
    return ""

def find_commission_batch_code(lines) -> str:
    s = "\n".join(lines or [])
    m = re.search(r'(COM_[A-Z]{3}_\d{4})', s, re.IGNORECASE)
    if m:
        return m.group(1).strip()
    m2 = re.search(r'Com_[A-Za-z]{3}_\d{4}', s, re.IGNORECASE)
    if m2:
        return m2.group(0).strip()
    return ""

# -------------------------
# Input (PDF or text) extraction helpers
# -------------------------
def extract_all_lines_from_pdf(pdf_path: str):
    lines = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                for ln in text.splitlines():
                    lines.append(ln.rstrip())
    return lines

def extract_all_lines_from_file(path: str):
    """
    Accepts: 
     - PDF paths:  uses pdfplumber
     - Plain text / CSV dumps: reads text and returns lines
    """
    p = Path(path)
    if p.suffix.lower() == ".pdf":
        return extract_all_lines_from_pdf(str(p))
    txt = p.read_text(encoding='utf-8', errors='ignore')
    lines = []
    for ln in txt.splitlines():
        ln = ln.rstrip()
        if ln.startswith('"') and ln.endswith('"'):
            ln = ln[1:-1]
        lines.append(ln)
    return lines

# -------------------------
# Parsing helpers & constants
# -------------------------
POLICY_TYPES = {"GGG", "EDU", "EPP", "FAM", "FJPP", "FLE", "FNN"}

def is_valid_policy(policy_no: str) -> bool:
    policy_no = str(policy_no).strip()
    if re.match(r'^\d{2}/\d{2}/\d{4}$', policy_no):
        return False
    if policy_no.startswith("***"):
        return False
    if not policy_no: 
        return False
    return True

def parse_names_and_policy(parts):
    policy_idx = next((i for i, p in enumerate(parts) if p in POLICY_TYPES), None)
    if policy_idx is None or policy_idx < 2:
        return "", "", "", "", 1
    name_tokens = []
    for t in parts[1:policy_idx]:
        if re.match(r"^[A-Za-z]+(?: [-'][A-Za-z]+)*$", t):
            name_tokens.append(t)
        elif t in ('-', '', '/', '.', ''):
            continue
        else:
            break
    while len(name_tokens) < 3:
        name_tokens.append("")
    holder, surname, other_name = name_tokens[: 3]
    policy_type = parts[policy_idx]
    idx = policy_idx + 1
    return holder, surname, other_name, policy_type, idx

def correct_inception_agent(inception:  str, agent_name: str):
    agent_name = str(agent_name).strip()
    inception = str(inception).strip()
    match = re.match(r'^-? (\d{2})\s+(.*)', agent_name)
    if match:
        yy = match.group(1)
        name = match.group(2)
        if inception and not inception.endswith('-' + yy):
            inception = inception + '-' + yy
        agent_name = name
    return inception, agent_name

# -------------------------
# Date pattern to capture dd-Mon-YY and variants
# -------------------------
DATE_RE = re.compile(
    r'(\b\d{1,2}[-/][A-Za-z]{3,9}[-/]\d{2,4}\b|\b\d{1,2}/\d{1,2}/\d{2,4}\b|\b\d{1,2}[-/][A-Za-z]{3,9}\b)',
    flags=re.IGNORECASE
)

# -------------------------
# Extractors
# -------------------------
def extract_statement_data(path:  str) -> pd.DataFrame:
    lines = extract_all_lines_from_file(path)
    month_year = ""
    agent_license = ""
    for ln in lines:
        m = re.search(r'COM_([A-Z]{3})_(\d{4})', ln, re.IGNORECASE)
        if m:
            month_year = f"{m.group(1)} {m.group(2)}"
            break
    agent_license = find_agent_license_from_lines(lines)
    agent_code = find_agent_code_from_lines(lines)

    extracted_rows = []
    i = 0
    while i < len(lines):
        line = lines[i]
        if re.search(r'POLICY NO\.|PROPOSAL NO\.', line, re.IGNORECASE):
            is_proposal = bool(re.search(r'PROPOSAL NO\.', line, re.IGNORECASE))
            j = i + 2
            while j < len(lines):
                rowline = lines[j].strip()
                if (not rowline or rowline.upper().startswith("POLICY COUNT") or rowline.upper().startswith("PREMIUM")
                    or rowline.startswith("*** END OF FILE ***") or re.match(r'^\d{4}$', rowline)
                    or rowline.upper().startswith("TOTAL") or rowline.upper().startswith("PROPOSAL COUNT")
                    or rowline.upper().startswith("PROPOSALS") or re.search(r'NO\. HOLDER POLICY TYPE', rowline, re.IGNORECASE)):
                    break
                parts = rowline.split()
                if len(parts) < 7:
                    j += 1
                    continue
                policy_no = parts[0]
                if not is_valid_policy(policy_no):
                    j += 1
                    continue
                holder, surname, other_name, policy_type, idx = parse_names_and_policy(parts)
                row_data = parts[idx:]
                expected_fields = ["term", "pay_date", "receipt_no", "premium", "com_rate", "com_amt"]
                if is_proposal:
                    if len(row_data) > 0 and not row_data[0].isdigit():
                        row_data = ['0'] + row_data
                values = dict(zip(expected_fields, row_data + ['']*6))
                com_amt = values["com_amt"]
                inception = ""
                agent_name = ""
                trailing = row_data[6: ] if len(row_data) > 6 else []
                if trailing:
                    rest = " ".join(trailing)
                    m = DATE_RE.search(rest)
                    if m:
                        inception = to_iso_date(m.group(0))
                        agent_name = rest[m.end():].strip()
                    else:
                        agent_name = rest.strip()
                else:
                    try:
                        idx_pos = rowline.find(str(com_amt))
                        if idx_pos != -1:
                            after = rowline[idx_pos + len(str(com_amt)):]
                            m2 = DATE_RE.search(after)
                            if m2:
                                inception = to_iso_date(m2.group(0))
                                agent_name = after[m2.end():].strip()
                    except Exception:
                        pass
                    if not inception:
                        m3 = DATE_RE.search(rowline)
                        if m3:
                            inception = to_iso_date(m3.group(0))
                inception, agent_name = correct_inception_agent(inception, agent_name)
                inception = to_iso_date(inception)
                premium = clean_decimal_2dp(values["premium"])
                com_amt_norm = clean_decimal_2dp(com_amt)
                row = {
                    "agent_code": agent_code,
                    "policy_no": policy_no,
                    "holder": holder,
                    "surname": surname,
                    "other_name": other_name,
                    "policy_type": policy_type,
                    "term": values["term"],
                    "pay_date": to_iso_date(values["pay_date"]),
                    "receipt_no": values["receipt_no"],
                    "premium":  premium,
                    "com_rate": values["com_rate"],
                    "com_amt":  com_amt_norm,
                    "inception": inception,
                    "agent_name": agent_name,
                    "MONTH_YEAR": month_year,
                    "AGENT_LICENSE_NUMBER": agent_license
                }
                extracted_rows.append(row)
                j += 1
            i = j
        else: 
            i += 1
    return pd.DataFrame(extracted_rows)

def extract_terminated_data(path: str) -> pd.DataFrame:
    lines = extract_all_lines_from_file(path)
    month_year = ""
    for ln in lines:
        m = re.search(r'COM_([A-Z]{3})_(\d{4})', ln, re.IGNORECASE)
        if m:
            month_year = f"{m.group(1)} {m.group(2)}"
            break
    agent_license = find_agent_license_from_lines(lines)
    agent_code = find_agent_code_from_lines(lines)

    extracted_rows = []
    for ln in lines:
        parts = ln.split()
        if not parts:
            continue
        first_word = parts[0]
        if first_word.upper() in {"DAVID","COMIISION","CURRENCY","POLICY","TERMINATED"}:
            continue
        if not re.match(r"[A-Z]{2,6}\d{2,}", first_word):
            continue
        rn_idx = next((idx for idx, v in enumerate(parts) if v.startswith("RN") or re.match(r'^[A-Z]{2}\d+', v)), None)
        if rn_idx is None or rn_idx < 1:
            if len(parts) < 8:
                continue
            rn_idx = 2
        name_tokens = parts[1:rn_idx]
        holder = name_tokens[0] if len(name_tokens) > 0 else ""
        surname = name_tokens[1] if len(name_tokens) > 1 else ""
        other_name = " ".join(name_tokens[2:]) if len(name_tokens) > 2 else ""
        try:
            receipt_no = parts[rn_idx]
            paydate_raw = parts[rn_idx + 1] if rn_idx + 1 < len(parts) else ""
            premium_raw = parts[rn_idx + 2] if rn_idx + 2 < len(parts) else ""
            com_rate_raw = parts[rn_idx + 3] if rn_idx + 3 < len(parts) else ""
            com_amt_raw = parts[rn_idx + 4] if rn_idx + 4 < len(parts) else ""
            pt_idx = rn_idx + 5
            policy_type = parts[pt_idx] if pt_idx < len(parts) and parts[pt_idx] in POLICY_TYPES else ""
            if policy_type: 
                inc_token = parts[pt_idx + 1] if pt_idx + 1 < len(parts) else ""
                inception = to_iso_date(inc_token)
                status = parts[pt_idx + 2] if pt_idx + 2 < len(parts) else ""
                agent_name = " ".join(parts[pt_idx + 3:]) if pt_idx + 3 < len(parts) else ""
            else:
                inception = ""
                status = ""
                agent_name = ""
        except Exception:
            continue
        paydate_iso = to_iso_date(paydate_raw)
        premium = clean_decimal_2dp(premium_raw)
        com_amt = clean_decimal_2dp(com_amt_raw)
        termination_date_iso = month_year_to_first_iso(month_year)
        row = {
            "policy_no": first_word,
            "holder":  holder,
            "surname": surname,
            "other_name":  other_name,
            "receipt_no": receipt_no,
            "paydate": paydate_iso,
            "premium": premium,
            "com_rate":  com_rate_raw,
            "com_amt": com_amt,
            "policy_type": policy_type,
            "inception": inception,
            "status":  status,
            "agent_name": agent_name,
            "MONTH_YEAR": month_year,
            "AGENT_LICENSE_NUMBER": agent_license,
            "agent_code": agent_code,
            "termination_date": termination_date_iso
        }
        extracted_rows.append(row)
    return pd.DataFrame(extracted_rows)

# -------------------------
# Schedule:  improved agent_name + optional deductions
# -------------------------
COMPANY_KEYWORDS = ['COMPANY', 'LTD', 'LIMITED', 'SIC', 'LIFE', 'BANK', 'P.O.', 'PO BOX', 'CANTONMENTS', 'WWW', '@']

def extract_schedule_data(path: str) -> pd.DataFrame:
    lines = extract_all_lines_from_file(path)
    agent_name = ""
    header_idx = None
    for idx, ln in enumerate(lines[: 12]):
        if re.search(r'COMMISSION\s+SCHEDULE|COMMISSION\s+STATEMENT|COMIISION', ln, re.IGNORECASE):
            header_idx = idx
            break
    if header_idx is None:
        header_idx = 0
    for k in range(header_idx+1, min(header_idx+6, len(lines))):
        candidate = lines[k].strip()
        if not candidate:
            continue
        upper = candidate.upper()
        if any(kw in upper for kw in COMPANY_KEYWORDS) or _line_looks_like_address(candidate):
            continue
        if len(candidate.split()) < 2:
            continue
        agent_name = candidate
        break
    if not agent_name:
        for ln in lines[:12]:
            ln_strip = ln.strip()
            if not ln_strip:
                continue
            if _line_looks_like_address(ln_strip):
                continue
            if re.search(r'^[A-Z][A-Za-z]+(?:\s+[A-Z][A-Za-z]+){0,6}$', ln_strip):
                agent_name = ln_strip
                break

    commission_batch_code = find_commission_batch_code(lines)
    agent_license = find_agent_license_from_lines(lines)
    agent_code = find_agent_code_from_lines(lines)

    total_premiums = None
    income = None
    gov_tax = None
    siclase = None
    welfareko = None
    premium_deduction = None
    pensions = None
    total_deductions = None
    net_commission = None
    document_date = None

    for ln in lines:
        # TOTAL PREMIUM - match the specific pattern on same line
        if re.search(r'TOTAL\s+PREMIUM\s+', ln, re.IGNORECASE):
            match = re.search(r'TOTAL\s+PREMIUM\s+([0-9,]+\.?\d{0,2})', ln, re.IGNORECASE)
            if match:
                total_premiums = clean_decimal_2dp(match.group(1))

        # GROSS COMMISSION / INCOME
        if re.search(r'GROSS\s+COMMISSION\s+EARNED|INCOME\b', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.\d{2})', ln)
            if m:
                income = clean_decimal_2dp(m.group(1))

        # GOV TAX
        if re.search(r'GOV\.\s*TAX', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.\d{2})', ln)
            if m:
                gov_tax = clean_decimal_2dp(m.group(1))

        # SICLASE
        if re.search(r'\bSICLASE\b', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.?\d{0,2})', ln)
            if m:
                siclase = clean_decimal_2dp(m.group(1))

        # WELFAREKO
        if re.search(r'\bWELFAREKO\b', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.?\d{0,2})', ln)
            if m:
                welfareko = clean_decimal_2dp(m.group(1))

        # PREMIUM DEDUCTION
        if re.search(r'\bPREMIUM\s+DEDUCTION\b', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.?\d{0,2})', ln)
            if m:
                premium_deduction = clean_decimal_2dp(m.group(1))

        # PENSIONS
        if re.search(r'\bPENSIONS\b', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.\d{2})', ln)
            if m:
                pensions = clean_decimal_2dp(m.group(1))

        # TOTAL DEDUCTIONS - match pattern with parentheses:  "(2,548.27)"
        if re.search(r'TOTAL\s+DEDUCTIONS', ln, re.IGNORECASE):
            m = re.search(r'\(([0-9,]+\.\d{2})\)', ln)
            if m:
                total_deductions = clean_decimal_2dp(m.group(1))

        # NET COMMISSION
        if re.search(r'NET\s+COMMISSION', ln, re.IGNORECASE):
            m = re.search(r'([0-9,]+\.\d{2})', ln)
            if m:
                net_commission = clean_decimal_2dp(m.group(1))

        # A date somewhere in the footer/header
        m = re.search(r'(\d{2}/\d{2}/\d{4})', ln)
        if m and not document_date:
            document_date = to_iso_date(m.group(1))

    row = {
        "agent_code": agent_code,
        "agent_name": agent_name,
        "AGENT_LICENSE_NUMBER": agent_license,
        "commission_batch_code": commission_batch_code,
        "total_premiums": total_premiums,
        "income": income,
        "gov_tax": gov_tax,
        "siclase": siclase,
        "welfareko": welfareko,
        "premium_deduction":  premium_deduction,
        "pensions": pensions,
        "total_deductions": total_deductions,
        "net_commission": net_commission,
        "document_date": document_date,
        "MONTH_YEAR": ""
    }
    if commission_batch_code:
        m = re.search(r'COM_([A-Z]{3})_(\d{4})', commission_batch_code, re.IGNORECASE)
        if m:
            row['MONTH_YEAR'] = f"{m.group(1)} {m.group(2)}"
    return pd.DataFrame([row])

# -------------------------
# CLI wiring
# -------------------------
def run_cli_mode(args):
    p = Path(args.input)
    if not p.exists():
        print("Input not found:", p, file=sys.stderr)
        sys.exit(2)
    mode = args.mode
    if mode == "Statement":
        df = extract_statement_data(str(p))
        out_cols = ["agent_code","policy_no","holder","surname","other_name","policy_type","term","pay_date",
                    "receipt_no","premium","com_rate","com_amt","inception","agent_name",
                    "MONTH_YEAR","AGENT_LICENSE_NUMBER"]
        for c in out_cols:
            if c not in df.columns:
                df[c] = ""
        df = df[out_cols]
        df.to_csv(args.output, index=False)
        print(f"Wrote statement DB-ready CSV:  {args.output} rows={len(df)}")
    elif mode == "Terminated":
        df = extract_terminated_data(str(p))
        out_cols = ["agent_code","policy_no","holder","surname","other_name","receipt_no","paydate","premium",
                    "com_rate","com_amt","policy_type","inception","termination_date","status","agent_name",
                    "MONTH_YEAR","AGENT_LICENSE_NUMBER"]
        for c in out_cols: 
            if c not in df.columns:
                df[c] = ""
        df = df[out_cols]
        df.to_csv(args.output, index=False)
        print(f"Wrote terminated DB-ready CSV: {args.output} rows={len(df)}")
    elif mode == "Schedule":
        df = extract_schedule_data(str(p))
        out_cols = ["agent_code","agent_name","AGENT_LICENSE_NUMBER","commission_batch_code","total_premiums",
                    "income","gov_tax","siclase","welfareko","premium_deduction","pensions",
                    "total_deductions","net_commission","document_date","MONTH_YEAR"]
        for c in out_cols: 
            if c not in df.columns:
                df[c] = ""
        df = df[out_cols]
        df.to_csv(args.output, index=False)
        print(f"Wrote schedule DB-ready CSV: {args.output} rows={len(df)}")
    else:
        print("Unknown mode", mode)
        sys.exit(3)

# -------------------------
# Minimal GUI (Tkinter)
# -------------------------
class CombinedExtractorGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Schedule, Terminated & Statement PDF Extractor (Version4)")
        self.root.geometry("1200x800")
        self.selected_file = None
        self.df = pd.DataFrame()
        self.mode = tk.StringVar(value="Schedule")

        ttk.Label(root, text="Select PDF/Text Type:").grid(row=0, column=0, sticky='w', padx=5, pady=5)
        pdf_types = ["Schedule","Terminated","Statement"]
        self.type_menu = ttk.Combobox(root, textvariable=self.mode, values=pdf_types, state="readonly")
        self.type_menu.grid(row=0, column=1, padx=5, pady=5)
        self.type_menu.current(0)

        self.file_label = ttk.Label(root, text="No file selected")
        self.file_label.grid(row=1, column=0, columnspan=2, sticky='w', padx=5)
        ttk.Button(root, text="Select File", command=self.select_file).grid(row=1, column=2, padx=5)
        ttk.Button(root, text="Extract", command=self.extract_pdf).grid(row=1, column=3, padx=5)
        ttk.Button(root, text="Export CSV", command=self.export_csv).grid(row=1, column=4, padx=5)
        ttk.Button(root, text="Save Preview as CSV", command=self.save_preview_csv).grid(row=1, column=5, padx=5)

        self.table_frame = tk.Frame(root)
        self.table_frame.grid(row=2, column=0, columnspan=6, sticky='nsew')
        root.grid_rowconfigure(2, weight=1)
        root.grid_columnconfigure(5, weight=1)

    def select_file(self):
        filetypes = [("PDF files","*.pdf"),("Text/CSV","*.csv;*.txt"),("All files","*.*")]
        fp = filedialog.askopenfilename(filetypes=filetypes)
        if fp:
            self.selected_file = fp
            self.file_label.config(text=os.path.basename(fp))

    def extract_pdf(self):
        if not self.selected_file:
            messagebox.showwarning("No file","Select a file first")
            return
        m = self.mode.get()
        try:
            if m == "Schedule":
                self.df = extract_schedule_data(self.selected_file)
            elif m == "Terminated": 
                self.df = extract_terminated_data(self.selected_file)
            elif m == "Statement":
                self.df = extract_statement_data(self.selected_file)
            else:
                self.df = pd.DataFrame()
        except Exception as e:
            messagebox.showerror("Error", f"Error during extraction:\n{e}")
            self.df = pd.DataFrame()
            return
        self.preview()

    def preview(self):
        for w in self.table_frame.winfo_children():
            w.destroy()
        if self.df is None or self.df.empty:
            ttk.Label(self.table_frame, text="No data").pack()
            return
        cols = list(self.df.columns)
        tree = ttk.Treeview(self.table_frame, columns=cols, show='headings')
        vsb = ttk.Scrollbar(self.table_frame, orient="vertical", command=tree.yview)
        hsb = ttk.Scrollbar(self.table_frame, orient="horizontal", command=tree.xview)
        tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        vsb.pack(side='right', fill='y')
        hsb.pack(side='bottom', fill='x')
        tree.pack(fill='both', expand=True)
        for c in cols:
            tree.heading(c, text=c)
            tree.column(c, width=120, anchor='w')
        for _, r in self.df.iterrows():
            vals = [r.get(c, "") for c in cols]
            tree.insert('', 'end', values=vals)

    def export_csv(self):
        if self.df is None or self.df.empty:
            messagebox.showinfo("No data", "No extracted data to export")
            return
        fp = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV","*.csv")])
        if fp:
            try:
                self.df.to_csv(fp, index=False)
                messagebox.showinfo("Saved", f"Saved to {fp}")
            except Exception as e:
                messagebox.showerror("Error", f"Failed to save CSV:\n{e}")

    def save_preview_csv(self):
        if self.df is None or self.df.empty:
            messagebox.showinfo("No data", "No extracted data to save")
            return
        base = "extracted_preview.csv"
        if self.selected_file:
            base = Path(self.selected_file).with_suffix('').name + "_extracted.csv"
        fp = filedialog.asksaveasfilename(initialfile=base, defaultextension=".csv", filetypes=[("CSV","*.csv")])
        if fp:
            try: 
                self.df.to_csv(fp, index=False)
                messagebox.showinfo("Saved", f"Saved to {fp}")
            except Exception as e:
                messagebox.showerror("Error", f"Failed to save CSV:\n{e}")

# -------------------------
# Main / CLI entry
# -------------------------
def main():
    if len(sys.argv) == 1:
        if tk is None:
            print("Tkinter not available. Use CLI arguments.", file=sys.stderr)
            return
        root = tk.Tk()
        app = CombinedExtractorGUI(root)
        root.mainloop()
        return
    ap = argparse.ArgumentParser(description="DB-ready parser (fixed) - Version4")
    ap.add_argument("--mode", choices=["Schedule","Terminated","Statement"], required=True)
    ap.add_argument("--input", "-i", required=True)
    ap.add_argument("--output", "-o", required=True)
    args = ap.parse_args()
    run_cli_mode(args)

if __name__ == "__main__":
    main()
# ===== END FILE: parser\parser_db_ready_fixed_Version4.py =====

################################################################################
# ===== FILE: reports\monthly_reports.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\reports\monthly_reports.py
# SIZE: 46,796 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations
from typing import Dict, Any, List, Optional, Tuple, cast
from decimal import Decimal, ROUND_HALF_UP
from datetime import datetime
from pathlib import Path

from src.ingestion.db import get_conn

# 
# Month & DB helpers
# 


def _period_key_from_month_year(label: Optional[str]) -> Optional[str]:
    """Mon YYYY -> YYYY-MM (e.g., 'Jun 2025' -> '2025-06')."""
    try:
        month_map = {
            "Jan": 1,
            "Feb": 2,
            "Mar": 3,
            "Apr": 4,
            "May": 5,
            "Jun": 6,
            "Jul": 7,
            "Aug": 8,
            "Sep": 9,
            "Oct": 10,
            "Nov": 11,
            "Dec": 12,
        }
        if not label:
            return None
        parts = str(label).split()
        if len(parts) != 2 or parts[0] not in month_map:
            return None
        y = int(parts[1])
        m = month_map[parts[0]]
        return f"{y:04d}-{m:02d}"
    except Exception:
        return None


def _safe_period_key(month_year: Optional[str]) -> str:
    """
    Return a guaranteed period key string for queries:
    - Prefer 'YYYY-MM' derived from 'Mon YYYY'
    - Fallback: replace space with hyphen in the given label (e.g., 'Jun 2025' -> 'Jun-2025')
    - If month_year is None or empty, return 'UNKNOWN'
    """
    if not month_year:
        return "UNKNOWN"
    pk = _period_key_from_month_year(month_year)
    return pk if pk is not None else month_year.replace(" ", "-")


def _sum_statement_commission(agent_code: str, month_year: str) -> float:
    """Gross commission (reported) from statement.com_amt."""
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT COALESCE(SUM(`com_amt`), 0.0) AS total_com "
                "FROM `statement` WHERE `agent_code`=%s AND `MONTH_YEAR`=%s",
                (agent_code, month_year),
            )
            r = cur.fetchone() or {}
            return float(r.get("total_com") or 0.0)
    finally:
        conn.close()


def _sum_statement_premium(agent_code: str, month_year: str) -> Tuple[int, float]:
    """Policies reported & total premium (reported)."""
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT COUNT(*) AS cnt, COALESCE(SUM(`premium`), 0.0) AS total_prem "
                "FROM `statement` WHERE `agent_code`=%s AND `MONTH_YEAR`=%s",
                (agent_code, month_year),
            )
            r = cur.fetchone() or {}
            return int(r.get("cnt") or 0), float(r.get("total_prem") or 0.0)
    finally:
        conn.close()


def _fetch_schedule_latest(agent_code: str, month_year: str) -> Dict[str, Any]:
    """
    Latest schedule row: income (gross), total_deductions, net_commission,
    plus optional components: siclase, premium_deduction, pensions, welfareko.
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT `income`,`total_deductions`,`net_commission`,
                       COALESCE(`siclase`,0.0)            AS siclase,
                       COALESCE(`premium_deduction`,0.0)  AS premium_deduction,
                       COALESCE(`pensions`,0.0)           AS pensions,
                       COALESCE(`welfareko`,0.0)          AS welfareko
                FROM `schedule`
                WHERE `agent_code`=%s AND `month_year`=%s
                ORDER BY `upload_id` DESC
                LIMIT 1
                """,
                (agent_code, month_year),
            )
            r = cur.fetchone() or {}
            return {
                "income": float(r.get("income") or 0.0),
                "total_deductions": float(r.get("total_deductions") or 0.0),
                "net_commission": float(r.get("net_commission") or 0.0),
                "siclase": float(r.get("siclase") or 0.0),
                "premium_deduction": float(r.get("premium_deduction") or 0.0),
                "pensions": float(r.get("pensions") or 0.0),
                "welfareko": float(r.get("welfareko") or 0.0),
            }
    finally:
        conn.close()


def _sum_expected_commission(agent_code: str, period_key: str) -> float:
    """Gross commission (expected) from expected_commissions.expected_amount (YYYY-MM)."""
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT COALESCE(SUM(`expected_amount`),0.0) AS total_expected
                FROM `expected_commissions`
                WHERE `agent_code`=%s AND `period`=%s
                """,
                (agent_code, period_key),
            )
            r = cur.fetchone() or {}
            return float(r.get("total_expected") or 0.0)
    finally:
        conn.close()


def _fetch_missing_policies(agent_code: str, month_year: str) -> List[Dict[str, Any]]:
    """
    ALL missing policies (not top 20). Columns left blank per template:
      HOLDER / SURNAME / OTHER_NAME / POLICY TYPE / Expected Premium / Expected Com Rate / REMARKS
    """
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                WITH last_seen AS (
                    SELECT policy_no,
                           MAX(MONTH_YEAR) AS last_month,
                           MAX(premium)    AS last_premium,
                           MAX(com_rate)   AS last_com_rate
                    FROM `statement`
                    WHERE `agent_code`=%s
                    GROUP BY policy_no
                )
                SELECT ls.policy_no,
                       ls.last_month    AS last_seen_month,
                       ls.last_premium  AS last_premium,
                       ls.last_com_rate AS last_com_rate
                FROM last_seen ls
                WHERE ls.last_month < %s
                ORDER BY ls.policy_no ASC
                """,
                (agent_code, month_year),
            )
            rows = list(cur.fetchall() or [])
            out: List[Dict[str, Any]] = []
            for r in rows:
                out.append(
                    {
                        "policy_no": r.get("policy_no"),
                        "holder": "",
                        "surname": "",
                        "other_name": "",
                        "policy_type": "",
                        "last_seen_month": r.get("last_seen_month"),
                        "last_premium": r.get("last_premium"),
                        "expected_premium": "",
                        "last_com_rate": r.get("last_com_rate"),
                        "expected_com_rate": "",
                        "remarks": "",
                    }
                )
            return out
    except Exception:
        return []
    finally:
        conn.close()


def _count_terminated(agent_code: str, month_year: str) -> int:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT COUNT(*) AS cnt FROM `terminated` WHERE `agent_code`=%s AND `month_year`=%s",
                (agent_code, month_year),
            )
            r = cur.fetchone() or {}
            return int(r.get("cnt") or 0)
    finally:
        conn.close()


def _multiple_entries_all(agent_code: str, month_year: str) -> List[Dict[str, Any]]:
    """All duplicate entries in month, with count & total premium; holder/name/type left blank per template."""
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT policy_no, COUNT(*) AS entries, COALESCE(SUM(premium),0.0) AS total_premium
                FROM `statement`
                WHERE `agent_code`=%s AND `MONTH_YEAR`=%s
                GROUP BY policy_no
                HAVING COUNT(*) > 1
                ORDER BY policy_no
                """,
                (agent_code, month_year),
            )
            rows = list(cur.fetchall() or [])
            out: List[Dict[str, Any]] = []
            for r in rows:
                out.append(
                    {
                        "policy_no": r.get("policy_no"),
                        "entries": r.get("entries"),
                        "holder": "",
                        "surname": "",
                        "other_name": "",
                        "policy_type": "",
                        "total_premium": r.get("total_premium"),
                        "remark": "",  # blank
                    }
                )
            return out
    finally:
        conn.close()


def _inception_inconsistency_all(agent_code: str) -> List[Dict[str, Any]]:
    """All inception vs first_seen inconsistencies across agent."""
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT s.policy_no, MIN(s.pay_date) AS first_seen_date, MAX(s.inception) AS inception
                FROM `statement` s
                WHERE s.`agent_code`=%s
                GROUP BY s.policy_no
                """,
                (agent_code,),
            )
            rows = list(cur.fetchall() or [])
            out: List[Dict[str, Any]] = []
            for r in rows:
                inc = str(r.get("inception") or "")
                fsd = str(r.get("first_seen_date") or "")
                if inc and fsd and inc[:10] != fsd[:10]:
                    cur.execute(
                        "SELECT COALESCE(SUM(premium),0.0) AS tot FROM `statement` WHERE `agent_code`=%s AND `policy_no`=%s",
                        (agent_code, r.get("policy_no")),
                    )
                    tot = (cur.fetchone() or {}).get("tot") or 0.0
                    out.append(
                        {
                            "policy_no": r.get("policy_no"),
                            "holder": "",
                            "surname": "",
                            "other_name": "",
                            "policy_type": "",
                            "total_premium": tot,
                            "inception_statement": inc,
                            "inception_active": fsd,
                            "actual_inception_date": "",  # blank for agent to fill
                        }
                    )
            return out
    finally:
        conn.close()


def _should_be_terminated_all(agent_code: str, month_year: str) -> List[Dict[str, Any]]:
    """Policies previously terminated but appearing in this month."""
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT policy_no, month_year FROM `terminated` WHERE `agent_code`=%s AND `month_year`<=%s",
                (agent_code, month_year),
            )
            terminated_rows = list(cur.fetchall() or [])
            terminated_map = {
                r["policy_no"]: r["month_year"]
                for r in terminated_rows
                if r.get("policy_no")
            }
            cur.execute(
                "SELECT DISTINCT policy_no FROM `statement` WHERE `agent_code`=%s AND `MONTH_YEAR`=%s",
                (agent_code, month_year),
            )
            appear = [
                r.get("policy_no")
                for r in (cur.fetchall() or [])
                if r.get("policy_no")
            ]
            out: List[Dict[str, Any]] = []
            for p in appear:
                if p in terminated_map:
                    out.append(
                        {
                            "policy_no": p,
                            "holder": "",
                            "surname": "",
                            "other_name": "",
                            "policy_type": "",
                            "terminated_month_year": terminated_map[p],
                            "remarks": "",  # ERROR / RESTARTED  blank
                        }
                    )
            return out
    finally:
        conn.close()


def compute_month_summary(agent_code: str, month_year: str) -> Dict[str, Any]:
    """
    Monthly Report data aligned to Commission Comparison (Net) spec and dashboard summary:
    - Commission Comparison (Net) with REPORTED / PAID / EXPECTED
      * GOV TAX always 10% of GROSS (per column)
      * SICLASE, PREMIUM DEDUCTIONS, PENSIONS (from latest schedule) applied to all three columns
      * TOTAL DEDUCTIONS = GOV TAX + SICLASE + PREMIUM DEDUCTIONS + PENSIONS
      * NET COMMISSION   = GROSS  TOTAL DEDUCTIONS
      + DIFF rows (VS REPORTED / VS PAID / VS EXPECTED)
    - Missing Policies (ALL)
    - Audit counts + duplicates + inception inconsistencies + should-be-terminated
    """
    assert isinstance(agent_code, str)
    assert isinstance(month_year, str)
    month_year = cast(str, month_year)

    policies_reported, total_premium_reported = _sum_statement_premium(
        agent_code, month_year
    )
    gross_reported = _sum_statement_commission(agent_code, month_year)  # statement
    schedule = _fetch_schedule_latest(agent_code, month_year)

    # Gross PAID (schedule income)
    gross_paid = float(schedule.get("income") or 0.0)

    # Gross EXPECTED from expected_commissions over canonical period key
    period_key: str = _safe_period_key(month_year)
    gross_expected = _sum_expected_commission(agent_code, period_key)

    # 10% Gov tax (per column)
    def ten_percent(v: float) -> float:
        return float(
            Decimal(v * 0.10).quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)
        )

    tax_reported = ten_percent(gross_reported)
    tax_paid = ten_percent(gross_paid)
    tax_expected = ten_percent(gross_expected)

    # Components (from latest schedule), applied to all columns
    comp_siclase = float(schedule.get("siclase") or 0.0)
    comp_prem = float(schedule.get("premium_deduction") or 0.0)
    comp_pensions = float(schedule.get("pensions") or 0.0)
    comp_welfareko = float(schedule.get("welfareko") or 0.0)

    # TOTAL DEDUCTIONS per column
    total_ded_reported = float(
        Decimal(tax_reported + comp_siclase + comp_prem + comp_pensions).quantize(
            Decimal("0.01")
        )
    )
    total_ded_paid = float(
        Decimal(tax_paid + comp_siclase + comp_prem + comp_pensions).quantize(
            Decimal("0.01")
        )
    )
    total_ded_expected = float(
        Decimal(tax_expected + comp_siclase + comp_prem + comp_pensions).quantize(
            Decimal("0.01")
        )
    )

    # NETS per column
    net_reported = float(
        Decimal(gross_reported - total_ded_reported).quantize(Decimal("0.01"))
    )
    net_paid = float(
        Decimal(gross_paid - total_ded_paid).quantize(Decimal("0.01"))
    )
    net_expected = float(
        Decimal(gross_expected - total_ded_expected).quantize(Decimal("0.01"))
    )

    # DIFF bundles as per spec:
    # DIFF VS REPORTED: [0, NET_REPORTED  NET_PAID, NET_REPORTED  NET_EXPECTED]
    diff_vs_reported = {
        "reported": 0.0,
        "paid": float(
            Decimal(net_reported - net_paid).quantize(Decimal("0.01"))
        ),
        "expected": float(
            Decimal(net_reported - net_expected).quantize(Decimal("0.01"))
        ),
    }
    # DIFF VS PAID: [NET_PAID  NET_REPORTED, 0, NET_PAID  NET_EXPECTED]
    diff_vs_paid = {
        "reported": float(
            Decimal(net_paid - net_reported).quantize(Decimal("0.01"))
        ),
        "paid": 0.0,
        "expected": float(
            Decimal(net_paid - net_expected).quantize(Decimal("0.01"))
        ),
    }
    # DIFF VS EXPECTED: [NET_EXPECTED  NET_REPORTED, NET_EXPECTED  NET_PAID, 0]
    diff_vs_expected = {
        "reported": float(
            Decimal(net_expected - net_reported).quantize(Decimal("0.01"))
        ),
        "paid": float(
            Decimal(net_expected - net_paid).quantize(Decimal("0.01"))
        ),
        "expected": 0.0,
    }

    # Back-compat variance vs expected (net)
    variance_amount = float(
        Decimal(net_reported - net_expected).quantize(Decimal("0.01"))
    )
    variance_percent = float(
        Decimal(
            (variance_amount / net_expected * 100) if net_expected else 0.0
        ).quantize(Decimal("0.01"))
    )

    # Counts + lists
    missing_all = _fetch_missing_policies(agent_code, month_year)
    terminated_count = _count_terminated(agent_code, month_year)
    dups_all = _multiple_entries_all(agent_code, month_year)
    incs_all = _inception_inconsistency_all(agent_code)
    sbt_all = _should_be_terminated_all(agent_code, month_year)
    audit_issues_count = len(dups_all) + len(incs_all) + len(sbt_all)

    return {
        "policies_reported": policies_reported,
        "total_premium_expected": None,
        "total_premium_reported": total_premium_reported,
        "variance_amount": variance_amount,
        "variance_percentage": variance_percent,
        "commission": {
            "reported": {
                "gross": gross_reported,
                "gov_tax": tax_reported,
                "siclase": comp_siclase,
                "premium_deductions": comp_prem,
                "pensions": comp_pensions,
                "welfareko": comp_welfareko,
                "total_deductions": total_ded_reported,
                "net": net_reported,
            },
            "paid": {
                "gross": gross_paid,
                "gov_tax": tax_paid,
                "siclase": comp_siclase,
                "premium_deductions": comp_prem,
                "pensions": comp_pensions,
                "welfareko": comp_welfareko,
                "total_deductions": total_ded_paid,
                "net": net_paid,
            },
            "expected": {
                "gross": gross_expected,
                "gov_tax": tax_expected,
                "siclase": comp_siclase,
                "premium_deductions": comp_prem,
                "pensions": comp_pensions,
                "welfareko": comp_welfareko,
                "total_deductions": total_ded_expected,
                "net": net_expected,
            },
        },
        "diffs": {
            "vs_reported": diff_vs_reported,
            "vs_paid": diff_vs_paid,
            "vs_expected": diff_vs_expected,
        },
        "missing_all": missing_all,
        "audit_counts": {
            "data_quality_issues": audit_issues_count,
            "commission_mismatches": 1 if abs(variance_amount) > 0.00001 else 0,
            "terminated_policies_in_month": terminated_count,
        },
        "dups_all": dups_all,
        "incs_all": incs_all,
        "sbt_all": sbt_all,
    }


# 
# Styled PDF output (Platypus)  Commission grid per spec + sections
# 


def local_and_gcs(
    agent_code: str,
    agent_name: str,
    month_year: str,
    out_dir: Path,
    user_id: Optional[int] = None,
) -> Dict[str, Any]:
    """
    Render PDF aligned to the template (soft green theme)
    with:
      - Small blank margins
      - Centered section titles
      - Left-aligned tables
      - Clear visual separators between sections
      - Commission Comparison (Net) grid + DIFF rows in one section,
        laid out as:

        ROW TITLE | REPORTED | PAID | EXPECTED
        GROSS COMMISSION ...
        ...
        NET COMMISSION ...
        [blank row]
        DIFF VS REPORTED ...
        DIFF VS PAID ...
        DIFF VS EXPECTED ...
    """
    assert isinstance(agent_code, str)
    assert isinstance(agent_name, str)
    assert isinstance(month_year, str)

    out_dir.mkdir(parents=True, exist_ok=True)

    period: str = _safe_period_key(month_year)
    file_stem = f"ICRS_{agent_code}_{period}"
    pdf_path = out_dir / f"{file_stem}.pdf"

    summary = compute_month_summary(agent_code, month_year)

    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.lib import colors
        from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet
        from reportlab.platypus import (
            SimpleDocTemplate,
            Paragraph,
            Spacer,
            Table,
            TableStyle,
            PageBreak,
        )
        from reportlab.platypus.flowables import HRFlowable
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.enums import TA_CENTER

        # Optional fonts
        fonts_dir = Path("assets") / "fonts"

        def _register_font(name: str, file: str) -> None:
            path = fonts_dir / file
            if path.exists():
                pdfmetrics.registerFont(TTFont(name, str(path)))

        _register_font("Montserrat", "Montserrat-Regular.ttf")
        _register_font("Montserrat-Bold", "Montserrat-Bold.ttf")
        _register_font("SourceSans", "SourceSans3-Regular.ttf")
        _register_font("SourceSans-Semibold", "SourceSans3-Semibold.ttf")

        BODY_FONT = (
            "SourceSans"
            if "SourceSans" in pdfmetrics.getRegisteredFontNames()
            else "Helvetica"
        )
        BOLD_FONT = (
            "SourceSans-Semibold"
            if "SourceSans-Semibold" in pdfmetrics.getRegisteredFontNames()
            else "Helvetica-Bold"
        )
        TITLE_FONT = (
            "Montserrat-Bold"
            if "Montserrat-Bold" in pdfmetrics.getRegisteredFontNames()
            else BOLD_FONT
        )

        styles = getSampleStyleSheet()
        styles.add(
            ParagraphStyle(
                name="DocTitle",
                fontName=TITLE_FONT,
                fontSize=16,
                leading=18,
                textColor=colors.HexColor("#1F2937"),
                spaceAfter=8,
                alignment=TA_CENTER,
            )
        )
        styles.add(
            ParagraphStyle(
                name="Meta",
                fontName=BODY_FONT,
                fontSize=10,
                leading=13,
                textColor=colors.HexColor("#374151"),
                alignment=TA_CENTER,
            )
        )
        styles.add(
            ParagraphStyle(
                name="SectionTitleCenter",
                fontName=BOLD_FONT,
                fontSize=12,
                leading=14,
                textColor=colors.HexColor("#065F46"),
                spaceBefore=16,
                spaceAfter=6,
                alignment=TA_CENTER,
            )
        )
        styles.add(
            ParagraphStyle(
                name="Body",
                fontName=BODY_FONT,
                fontSize=10,
                leading=12.5,
                textColor=colors.HexColor("#111827"),
            )
        )

        PAGE_BG = colors.HexColor("#E8F5E9")

        def _draw_bg(canvas, doc):
            canvas.saveState()
            canvas.setFillColor(PAGE_BG)
            w, h = A4
            # full-page colored bg; margins come from doc margins below
            canvas.rect(0, 0, w, h, stroke=0, fill=1)
            canvas.setFillColor(colors.HexColor("#374151"))
            canvas.setFont(
                BODY_FONT
                if BODY_FONT in pdfmetrics.getRegisteredFontNames()
                else "Helvetica",
                8,
            )
            canvas.drawRightString(w - 25, 18, f"Page {canvas.getPageNumber()}")
            canvas.restoreState()

        # Small but clear margins
        doc = SimpleDocTemplate(
            str(pdf_path),
            pagesize=A4,
            leftMargin=36,   # ~0.5 inch
            rightMargin=36,
            topMargin=40,
            bottomMargin=36,
            title=f"ICRS Report - {agent_code} - {month_year}",
            author="ICRS",
        )

        content: List[Any] = []

        def make_table(
            title: str,
            rows: List[List[Any]],
            col_widths: Optional[List[Optional[float]]] = None,
        ) -> None:
            """Add titled, left-aligned table with consistent styling."""
            content.append(Paragraph(title, styles["SectionTitleCenter"]))
            if not rows:
                content.append(Paragraph("None", styles["Body"]))
            else:
                tbl = Table(rows, colWidths=col_widths, hAlign="LEFT")
                tbl.setStyle(
                    TableStyle(
                        [
                            ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#D1FAE5")),
                            ("TEXTCOLOR", (0, 0), (-1, 0), colors.HexColor("#064E3B")),
                            ("FONTNAME", (0, 0), (-1, 0), BOLD_FONT),
                            ("FONTNAME", (0, 1), (-1, -1), BODY_FONT),
                            ("FONTSIZE", (0, 0), (-1, -1), 9),
                            ("GRID", (0, 0), (-1, -1), 0.25, colors.HexColor("#10B981")),
                            (
                                "ROWBACKGROUNDS",
                                (0, 1),
                                (-1, -1),
                                [colors.whitesmoke, colors.HexColor("#ECFDF5")],
                            ),
                            ("LEFTPADDING", (0, 0), (-1, -1), 6),
                            ("RIGHTPADDING", (0, 0), (-1, -1), 6),
                            ("TOPPADDING", (0, 0), (-1, -1), 4),
                            ("BOTTOMPADDING", (0, 0), (-1, -1), 4),
                        ]
                    )
                )
                content.append(tbl)
            # Visual marker at end of each section
            content.append(Spacer(1, 4))
            content.append(
                HRFlowable(
                    width="100%", thickness=1, color=colors.HexColor("#9CA3AF")
                )
            )
            content.append(Spacer(1, 6))

        # Title + meta
        content.append(
            Paragraph("Insurance Commission Reconciliation Report", styles["DocTitle"])
        )
        meta = (
            f"<b>Agent:</b> {agent_name} ({agent_code}) &nbsp;&nbsp; "
            f"<b>Period:</b> {month_year} &nbsp;&nbsp; "
            f"<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )
        content.append(Paragraph(meta, styles["Meta"]))
        content.append(Spacer(1, 10))

        # 
        # Commission Comparison (Net)  grid + DIFF rows
        # 
        c = summary.get("commission", {}) or {}
        rep = c.get("reported", {}) or {}
        paid = c.get("paid", {}) or {}
        exp = c.get("expected", {}) or {}

        diffs = summary.get("diffs", {}) or {}
        vs_rep = diffs.get("vs_reported", {}) or {}
        vs_paid = diffs.get("vs_paid", {}) or {}
        vs_exp = diffs.get("vs_expected", {}) or {}

        def _q(v: Any) -> float:
            try:
                return float(Decimal(v or 0.0).quantize(Decimal("0.01")))
            except Exception:
                return 0.0

        rows_commission: List[List[Any]] = [
            ["ROW TITLE", "REPORTED", "PAID", "EXPECTED"],
            [
                "GROSS COMMISSION",
                rep.get("gross", 0.0),
                paid.get("gross", 0.0),
                exp.get("gross", 0.0),
            ],
            [
                "GOV TAX",
                rep.get("gov_tax", 0.0),
                paid.get("gov_tax", 0.0),
                exp.get("gov_tax", 0.0),
            ],
            [
                "SICLASE",
                rep.get("siclase", 0.0),
                paid.get("siclase", 0.0),
                exp.get("siclase", 0.0),
            ],
            [
                "PREMIUM DEDUCTIONS",
                rep.get("premium_deductions", 0.0),
                paid.get("premium_deductions", 0.0),
                exp.get("premium_deductions", 0.0),
            ],
            [
                "PENSIONS",
                rep.get("pensions", 0.0),
                paid.get("pensions", 0.0),
                exp.get("pensions", 0.0),
            ],
            [
                "TOTAL DEDUCTIONS",
                rep.get("total_deductions", 0.0),
                paid.get("total_deductions", 0.0),
                exp.get("total_deductions", 0.0),
            ],
            [
                "NET COMMISSION",
                rep.get("net", 0.0),
                paid.get("net", 0.0),
                exp.get("net", 0.0),
            ],
            ["", "", "", ""],  # spacer row
            [
                "DIFF VS REPORTED",
                0.0,
                _q(vs_rep.get("paid", 0.0)),
                _q(vs_rep.get("expected", 0.0)),
            ],
            [
                "DIFF VS PAID",
                _q(vs_paid.get("reported", 0.0)),
                0.0,
                _q(vs_paid.get("expected", 0.0)),
            ],
            [
                "DIFF VS EXPECTED",
                _q(vs_exp.get("reported", 0.0)),
                _q(vs_exp.get("paid", 0.0)),
                0.0,
            ],
        ]

        make_table(
            "Commission Comparison (Net)",
            rows_commission,
            col_widths=[140, None, None, None],
        )

        # 
        # Missing Policies (all)
        # 
        rows_missing: List[List[Any]] = [
            [
                "Policy No",
                "HOLDER",
                "SURNAME",
                "OTHER_NAME",
                "POLICY TYPE",
                "Last Seen Month",
                "Last Premium",
                "Expected Premium",
                "Last Com Rate",
                "Expected Com Rate",
                "REMARKS (CLIENT NOT PAID / ACTUALLY MISSING / OTHER )",
            ]
        ]
        for r in summary.get("missing_all", []):
            rows_missing.append(
                [
                    r.get("policy_no", ""),
                    "",
                    "",
                    "",
                    "",
                    r.get("last_seen_month", ""),
                    r.get("last_premium", ""),
                    "",
                    r.get("last_com_rate", ""),
                    "",
                    "",
                ]
            )
        make_table(
            "Missing Policies (all)",
            rows_missing,
            col_widths=[
                80,
                80,
                80,
                80,
                80,
                90,
                80,
                90,
                80,
                90,
                None,
            ],
        )

        # 
        # Audit / Discrepancies Overview
        # 
        ac = summary.get("audit_counts", {}) or {}
        make_table(
            "Audit / Discrepancies Overview",
            rows=[
                ["Indicator", "Count"],
                ["Data quality issues", ac.get("data_quality_issues", 0)],
                ["Commission mismatches", ac.get("commission_mismatches", 0)],
                [
                    "Terminated policies in month",
                    ac.get("terminated_policies_in_month", 0),
                ],
            ],
            col_widths=[250, None],
        )

        # 
        # MULTIPLE_ENTRIES_IN_MONTH (all)
        # 
        rows_dups: List[List[Any]] = [
            [
                "Policy No",
                "Entries",
                "HOLDER",
                "SURNAME",
                "OTHER_NAME",
                "POLICY TYPE",
                "Total Premium in Statement",
                "REMARK",
                "",
                "",
            ]
        ]
        for r in summary.get("dups_all", []):
            rows_dups.append(
                [
                    r.get("policy_no", ""),
                    r.get("entries", ""),
                    "",
                    "",
                    "",
                    "",
                    r.get("total_premium", ""),
                    "",
                    "",
                    "",
                ]
            )
        make_table(
            "MULTIPLE_ENTRIES_IN_MONTH (all)",
            rows_dups,
            col_widths=[80, 60, 80, 80, 80, 80, 120, 80, 60, 60],
        )

        # 
        # INCEPTION_FIRST_SEEN_INCONSISTENCY (all)
        # 
        rows_incs: List[List[Any]] = [
            [
                "Policy No",
                "HOLDER",
                "SURNAME",
                "OTHER_NAME",
                "POLICY TYPE",
                "Total Premium in Statement",
                "Inception Date in Statement",
                "Inception Date according to Active Policies",
                "ACTUAL INCEPTION DATE (blank  agent to fill)",
                "",
            ]
        ]
        for r in summary.get("incs_all", []):
            rows_incs.append(
                [
                    r.get("policy_no", ""),
                    "",
                    "",
                    "",
                    "",
                    r.get("total_premium", ""),
                    r.get("inception_statement", ""),
                    r.get("inception_active", ""),
                    "",
                    "",
                ]
            )
        make_table(
            "INCEPTION_FIRST_SEEN_INCONSISTENCY (all)",
            rows_incs,
            col_widths=[80, 80, 80, 80, 80, 120, 130, 150, 150, 40],
        )

        # 
        # SHOULD_BE_TERMINATED
        # 
        rows_sbt: List[List[Any]] = [
            [
                "Policy No",
                "HOLDER",
                "SURNAME",
                "OTHER_NAME",
                "POLICY TYPE",
                "Terminated month year",
                "REMARKS (ERROR / RESTARTED)",
                "",
                "",
                "",
            ]
        ]
        for r in summary.get("sbt_all", []):
            rows_sbt.append(
                [
                    r.get("policy_no", ""),
                    "",
                    "",
                    "",
                    "",
                    r.get("terminated_month_year", ""),
                    "",
                    "",
                    "",
                    "",
                ]
            )
        make_table(
            "SHOULD_BE_TERMINATED",
            rows_sbt,
            col_widths=[80, 80, 80, 80, 80, 140, 160, 60, 60, 60],
        )

        content.append(PageBreak())
        doc.build(content, onFirstPage=_draw_bg, onLaterPages=_draw_bg)

        size = pdf_path.stat().st_size
        if size <= 0:
            raise RuntimeError("Generated PDF has zero size.")
        return {"pdf_path": str(pdf_path), "pdf_size_bytes": int(size)}

    except ImportError as e:
        raise RuntimeError("ReportLab is not installed. Install `reportlab`.") from e
    except Exception as e:
        raise RuntimeError(f"PDF generation failed: {e}")


# 
# CSV builder  full monthly report content
# 


def build_csv_rows(agent_code: str, agent_name: str, month_year: str) -> List[List[Any]]:
    """
    Return a list of CSV rows (each row is a list) for the Monthly Report.

    Includes:
      - Header meta (agent, period)
      - Commission Comparison (Net) grid + diff rows
      - Missing Policies (all)
      - Audit / Discrepancies Overview
      - MULTIPLE_ENTRIES_IN_MONTH (all)
      - INCEPTION_FIRST_SEEN_INCONSISTENCY (all)
      - SHOULD_BE_TERMINATED
    """
    s = compute_month_summary(agent_code, month_year) or {}

    commission = s.get("commission", {}) or {}
    reported = commission.get("reported", {}) or {}
    paid = commission.get("paid", {}) or {}
    expected = commission.get("expected", {}) or {}

    diffs = s.get("diffs", {}) or {}
    vs_rep = diffs.get("vs_reported", {}) or {}
    vs_paid = diffs.get("vs_paid", {}) or {}
    vs_exp = diffs.get("vs_expected", {}) or {}

    def _get(section: dict, key: str) -> float:
        try:
            return float(section.get(key) or 0.0)
        except Exception:
            return 0.0

    def _f(x: Any) -> float:
        try:
            return float(x or 0.0)
        except Exception:
            return 0.0

    rows: List[List[Any]] = []

    # Meta
    rows.append(["ICRS MONTHLY REPORT"])
    rows.append(["AGENT CODE", agent_code])
    rows.append(["AGENT NAME", agent_name])
    rows.append(["MONTH", month_year])
    rows.append([])

    # Commission Comparison (Net)
    rows.append(["Commission Comparison (Net)"])
    rows.append(["ROW TITLE", "REPORTED", "PAID", "EXPECTED"])
    rows.append(
        [
            "GROSS COMMISSION",
            _get(reported, "gross"),
            _get(paid, "gross"),
            _get(expected, "gross"),
        ]
    )
    rows.append(
        [
            "GOV TAX",
            _get(reported, "gov_tax"),
            _get(paid, "gov_tax"),
            _get(expected, "gov_tax"),
        ]
    )
    rows.append(
        [
            "SICLASE",
            _get(reported, "siclase"),
            _get(paid, "siclase"),
            _get(expected, "siclase"),
        ]
    )
    rows.append(
        [
            "PREMIUM DEDUCTIONS",
            _get(reported, "premium_deductions"),
            _get(paid, "premium_deductions"),
            _get(expected, "premium_deductions"),
        ]
    )
    rows.append(
        [
            "PENSIONS",
            _get(reported, "pensions"),
            _get(paid, "pensions"),
            _get(expected, "pensions"),
        ]
    )
    rows.append(
        [
            "TOTAL DEDUCTIONS",
            _get(reported, "total_deductions"),
            _get(paid, "total_deductions"),
            _get(expected, "total_deductions"),
        ]
    )
    rows.append(
        [
            "NET COMMISSION",
            _get(reported, "net"),
            _get(paid, "net"),
            _get(expected, "net"),
        ]
    )
    rows.append([])

    rows.append(
        ["DIFF VS REPORTED", 0.0, _f(vs_rep.get("paid")), _f(vs_rep.get("expected"))]
    )
    rows.append(
        ["DIFF VS PAID", _f(vs_paid.get("reported")), 0.0, _f(vs_paid.get("expected"))]
    )
    rows.append(
        [
            "DIFF VS EXPECTED",
            _f(vs_exp.get("reported")),
            _f(vs_exp.get("paid")),
            0.0,
        ]
    )

    rows.append([])
    rows.append([])

    # Missing Policies
    rows.append(["Missing Policies (all)"])
    rows.append(
        [
            "Policy No",
            "HOLDER",
            "SURNAME",
            "OTHER_NAME",
            "POLICY TYPE",
            "Last Seen Month",
            "Last Premium",
            "Expected Premium",
            "Last Com Rate",
            "Expected Com Rate",
            "REMARKS (CLIENT NOT PAID / ACTUALLY MISSING / OTHER )",
        ]
    )
    for r in s.get("missing_all", []) or []:
        rows.append(
            [
                r.get("policy_no", ""),
                "",
                "",
                "",
                "",
                r.get("last_seen_month", ""),
                r.get("last_premium", ""),
                "",
                r.get("last_com_rate", ""),
                "",
                "",
            ]
        )

    rows.append([])
    rows.append([])

    # Audit / Discrepancies
    ac = s.get("audit_counts", {}) or {}
    rows.append(["Audit / Discrepancies Overview"])
    rows.append(["Indicator", "Count"])
    rows.append(["Data quality issues", ac.get("data_quality_issues", 0)])
    rows.append(["Commission mismatches", ac.get("commission_mismatches", 0)])
    rows.append(
        [
            "Terminated policies in month",
            ac.get("terminated_policies_in_month", 0),
        ]
    )

    rows.append([])
    rows.append([])

    # MULTIPLE_ENTRIES_IN_MONTH
    rows.append(["MULTIPLE_ENTRIES_IN_MONTH (all)"])
    rows.append(
        [
            "Policy No",
            "Entries",
            "HOLDER",
            "SURNAME",
            "OTHER_NAME",
            "POLICY TYPE",
            "Total Premium in Statement",
            "REMARK",
            "",
            "",
        ]
    )
    for r in s.get("dups_all", []) or []:
        rows.append(
            [
                r.get("policy_no", ""),
                r.get("entries", ""),
                "",
                "",
                "",
                "",
                r.get("total_premium", ""),
                "",
                "",
                "",
            ]
        )

    rows.append([])
    rows.append([])

    # INCEPTION_FIRST_SEEN_INCONSISTENCY
    rows.append(["INCEPTION_FIRST_SEEN_INCONSISTENCY (all)"])
    rows.append(
        [
            "Policy No",
            "HOLDER",
            "SURNAME",
            "OTHER_NAME",
            "POLICY TYPE",
            "Total Premium in Statement",
            "Inception Date in Statement",
            "Inception Date according to Active Policies",
            "ACTUAL INCEPTION DATE (blank  agent to fill)",
            "",
        ]
    )
    for r in s.get("incs_all", []) or []:
        rows.append(
            [
                r.get("policy_no", ""),
                "",
                "",
                "",
                "",
                r.get("total_premium", ""),
                r.get("inception_statement", ""),
                r.get("inception_active", ""),
                "",
                "",
            ]
        )

    rows.append([])
    rows.append([])

    # SHOULD_BE_TERMINATED
    rows.append(["SHOULD_BE_TERMINATED"])
    rows.append(
        [
            "Policy No",
            "HOLDER",
            "SURNAME",
            "OTHER_NAME",
            "POLICY TYPE",
            "Terminated month year",
            "REMARKS (ERROR / RESTARTED)",
            "",
            "",
            "",
        ]
    )
    for r in s.get("sbt_all", []) or []:
        rows.append(
            [
                r.get("policy_no", ""),
                "",
                "",
                "",
                "",
                r.get("terminated_month_year", ""),
                "",
                "",
                "",
                "",
            ]
        )

    return rows
# ===== END FILE: reports\monthly_reports.py =====

################################################################################
# ===== FILE: services\__init__.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\services\__init__.py
# SIZE: 0 bytes
# ENCODING: utf-8
# ===== START =====

# ===== END FILE: services\__init__.py =====

################################################################################
# ===== FILE: services\active_policies.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\services\active_policies.py
# SIZE: 4,325 bytes
# ENCODING: utf-8
# ===== START =====

# src/services/active_policies.py
from __future__ import annotations

from typing import Optional, Dict, Any, List
from src.ingestion.db import get_conn

"""
Refresh active_policies snapshot up to a given month_year (e.g., 'Jun 2025')
or for a specific agent:
  - first_seen_date: earliest period_date for the policy (from statement)
  - last_seen_date: latest period_date for the policy (from statement)
  - last_premium: last premium observed
Excludes policies terminated up to and including month_year.
"""

def refresh_active_policies(agent_code: Optional[str] = None, month_year: Optional[str] = None) -> Dict[str, Any]:
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            # Build the set of terminated policies up to month_year (optional agent filter)
            term_params: List[Any] = []
            term_sql = "SELECT DISTINCT `policy_no` FROM `terminated` WHERE 1=1"
            if agent_code:
                term_sql += " AND `agent_code`=%s"; term_params.append(agent_code)
            if month_year:
                term_sql += " AND `month_year`<=%s"; term_params.append(month_year)
            cur.execute(term_sql, tuple(term_params))
            terminated = {r.get("policy_no") for r in (cur.fetchall() or []) if r.get("policy_no")}

            # Statements up to month_year (optional agent filter)
            stmt_params: List[Any] = []
            stmt_sql = (
                "SELECT `policy_no`,`agent_code`,`period_date`,`premium` "
                "FROM `statement` WHERE 1=1"
            )
            if agent_code:
                stmt_sql += " AND `agent_code`=%s"; stmt_params.append(agent_code)
            if month_year:
                stmt_sql += " AND `MONTH_YEAR`<=%s"; stmt_params.append(month_year)

            cur.execute(stmt_sql, tuple(stmt_params))
            rows = cur.fetchall() or []

            # Aggregate first_seen/last_seen/last_premium
            agg: Dict[str, Dict[str, Any]] = {}
            for r in rows:
                p = r.get("policy_no")
                if not p or p in terminated:
                    continue
                ac = r.get("agent_code")
                pd = r.get("period_date")
                prem = r.get("premium")
                if p not in agg:
                    agg[p] = {
                        "policy_no": p,
                        "agent_code": ac,
                        "first_seen_date": pd,
                        "last_seen_date": pd,
                        "last_premium": prem,
                    }
                else:
                    # Update latest observation
                    if pd and agg[p]["last_seen_date"] and pd > agg[p]["last_seen_date"]:
                        agg[p]["last_seen_date"] = pd
                        agg[p]["last_premium"] = prem
                    # Keep agent code in sync
                    agg[p]["agent_code"] = ac

            # Upsert into active_policies
            upsert_sql = """
                INSERT INTO `active_policies`
                    (`policy_no`,`agent_code`,`first_seen_date`,`last_seen_date`,`last_premium`)
                VALUES (%s,%s,%s,%s,%s)
                ON DUPLICATE KEY UPDATE
                  `agent_code` = VALUES(`agent_code`),
                  `first_seen_date` = LEAST(`first_seen_date`, VALUES(`first_seen_date`)),
                  `last_seen_date` = GREATEST(`last_seen_date`, VALUES(`last_seen_date`)),
                  `last_premium` = VALUES(`last_premium`)
            """
            inserted = 0
            for v in agg.values():
                cur.execute(
                    upsert_sql,
                    (
                        v["policy_no"],
                        v["agent_code"],
                        v["first_seen_date"],
                        v["last_seen_date"],
                        v["last_premium"],
                    )
                )
                inserted += cur.rowcount

            conn.commit()
            return {
                "status": "SUCCESS",
                "policies_upserted": inserted,
                "scope_rows": len(rows),
                "terminated_excluded": len(terminated),
            }
    finally:
        conn.close()
# ===== END FILE: services\active_policies.py =====

################################################################################
# ===== FILE: services\auth_service.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\services\auth_service.py
# SIZE: 3,294 bytes
# ENCODING: utf-8
# ===== START =====

# src/services/auth_service.py
from __future__ import annotations
import os, time, json, base64, hmac, hashlib
from typing import Dict, Any, Optional, Tuple

TOKEN_COOKIE_NAME = "access_token"
AUTH_SECRET = os.getenv("AUTH_SECRET", "change-me-please")

# ---- Token helpers ----
def _b64url(data: bytes) -> str:
    return base64.urlsafe_b64encode(data).rstrip(b"=").decode("ascii")

def _b64url_decode(s: str) -> bytes:
    pad = "=" * ((4 - len(s) % 4) % 4)
    return base64.urlsafe_b64decode(s + pad)

def create_token(payload: Dict[str, Any], exp_minutes: int = 60) -> str:
    header = {"alg": "HS256", "typ": "JWT"}
    now = int(time.time())
    body = dict(payload or {})
    body["exp"] = now + int(exp_minutes) * 60
    h = _b64url(json.dumps(header, separators=(",", ":"), ensure_ascii=False).encode("utf-8"))
    b = _b64url(json.dumps(body, separators=(",", ":"), ensure_ascii=False).encode("utf-8"))
    sig = hmac.new(AUTH_SECRET.encode("utf-8"), f"{h}.{b}".encode("utf-8"), hashlib.sha256).digest()
    s = _b64url(sig)
    return f"{h}.{b}.{s}"

def decode_token(token: Optional[str]) -> Optional[Dict[str, Any]]:
    if not token or token.count(".") != 2:
        return None
    h, b, s = token.split(".")
    expected = _b64url(hmac.new(AUTH_SECRET.encode("utf-8"), f"{h}.{b}".encode("utf-8"), hashlib.sha256).digest())
    if not hmac.compare_digest(s, expected):
        return None
    try:
        body = json.loads(_b64url_decode(b).decode("utf-8"))
    except Exception:
        return None
    exp = int(body.get("exp", 0))
    if int(time.time()) > exp:
        return None
    return body

# ---- Password hashing: Argon2 (default) + optional bcrypt via passlib ----
ALLOW_BCRYPT = bool(int(os.getenv("AUTH_ALLOW_BCRYPT", "1")))  # set to "0" to disable bcrypt

try:
    from passlib.context import CryptContext
    schemes = ["argon2", "bcrypt"] if ALLOW_BCRYPT else ["argon2"]
    _CTX: Optional[CryptContext] = CryptContext(
        schemes=schemes,
        default="argon2",
        deprecated="auto" if ALLOW_BCRYPT else "none",
    )
    _HAS_PASSLIB = True
except Exception:
    _CTX = None
    _HAS_PASSLIB = False

def _require_ctx() -> "CryptContext":
    if not _HAS_PASSLIB or _CTX is None:
        raise RuntimeError("Passlib not available. Install: pip install 'passlib[argon2,bcrypt]'")
    return _CTX

def hash_password(pw: str) -> str:
    ctx = _require_ctx()
    if not isinstance(pw, str) or not pw:
        raise ValueError("Password must be a non-empty string.")
    return ctx.hash(pw)

def verify_password(pw: str, hashed: str) -> bool:
    ctx = _require_ctx()
    if not isinstance(pw, str) or not isinstance(hashed, str) or not hashed:
        return False
    try:
        return ctx.verify(pw, hashed)
    except Exception:
        return False

def verify_and_upgrade_password(pw: str, hashed: str) -> Tuple[bool, Optional[str]]:
    """
    Verify pw; if hashed uses a deprecated scheme (e.g., bcrypt), return a new Argon2 hash.
    """
    ctx = _require_ctx()
    try:
        valid, new_hash = ctx.verify_and_update(pw, hashed)
        return bool(valid), (new_hash if new_hash else None)
    except Exception:
        return False, None
# ===== END FILE: services\auth_service.py =====

################################################################################
# ===== FILE: services\roles.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\services\roles.py
# SIZE: 3,190 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from typing import Any, Dict, Iterable, Set

from fastapi import HTTPException, Request

from src.services.auth_service import decode_token, TOKEN_COOKIE_NAME


def _normalize_roles(roles: Iterable[str]) -> Set[str]:
    """
    Normalize a collection of role names to lowercase, trimmed strings.
    Empty / whitespace-only entries are discarded.
    """
    return {str(r or "").strip().lower() for r in roles if str(r or "").strip()}


def require_role(*allowed_roles: str):
    """
    FastAPI dependency factory enforcing that the current user has one of the
    allowed roles. If no roles are provided, it only checks that the user
    is authenticated.

    Usage:

        from fastapi import APIRouter, Depends
        from src.services.roles import require_role

        router = APIRouter(
            prefix="/api/admin",
            dependencies=[Depends(require_role("admin", "superuser"))],
        )
    """

    allowed_set = _normalize_roles(allowed_roles)

    async def _dep(request: Request) -> Dict[str, Any]:
        tok = request.cookies.get(TOKEN_COOKIE_NAME)
        user = decode_token(tok) if tok else None
        if not user:
            raise HTTPException(status_code=403, detail="Authentication required")

        role = str((user or {}).get("role") or "").lower()
        if allowed_set and role not in allowed_set:
            raise HTTPException(status_code=403, detail="Forbidden")

        return user  # type: ignore[return-value]

    return _dep


async def require_agent_user(request: Request) -> Dict[str, Any]:
    """
    Convenience dependency for endpoints that must have a valid agent user
    with a non-empty agent_code.
    """
    tok = request.cookies.get(TOKEN_COOKIE_NAME)
    user = decode_token(tok) if tok else None
    if not user:
        raise HTTPException(status_code=403, detail="Agent authentication required")

    role = str((user or {}).get("role") or "").lower()
    agent_code = (user or {}).get("agent_code")

    if role != "agent" or not isinstance(agent_code, str) or not agent_code.strip():
        raise HTTPException(status_code=403, detail="Agent authentication required")

    return user


async def require_superuser_user(request: Request) -> Dict[str, Any]:
    """
    Convenience dependency for endpoints that must be accessed by a superuser,
    and that expect user_id to be numeric/intcoercible.
    """
    tok = request.cookies.get(TOKEN_COOKIE_NAME)
    user = decode_token(tok) if tok else None
    if not user:
        raise HTTPException(status_code=403, detail="Superuser authentication required")

    role = str((user or {}).get("role") or "").lower()
    user_id_val: Any = (user or {}).get("user_id")

    if role != "superuser" or user_id_val is None:
        raise HTTPException(status_code=403, detail="Superuser authentication required")

    try:
        int(user_id_val)
    except Exception:
        raise HTTPException(
            status_code=400,
            detail="user_id must be integer or string convertible to int",
        )

    return user
# ===== END FILE: services\roles.py =====

################################################################################
# ===== FILE: services\security.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\services\security.py
# SIZE: 5,147 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

import os
import time
import hmac
import hashlib
import secrets
from typing import Dict, Tuple, Optional

from fastapi import HTTPException, Request

# -----------------------------------------------------------------------------
# Environment: prefer CURRENT naming scheme (AUTH_RATE_*)
# -----------------------------------------------------------------------------
AUTH_RATE_WINDOW_SECONDS = int(os.getenv("AUTH_RATE_WINDOW_SECONDS", "900"))      # 15 minutes
AUTH_RATE_LIMIT_PER_IP   = int(os.getenv("AUTH_RATE_LIMIT_PER_IP", "50"))        # max attempts per IP per window
AUTH_LOCKOUT_THRESHOLD   = int(os.getenv("AUTH_LOCKOUT_THRESHOLD", "10"))        # failed attempts before lockout
AUTH_LOCKOUT_MINUTES     = int(os.getenv("AUTH_LOCKOUT_MINUTES", "15"))          # lockout duration in minutes

CSRF_ENFORCE = bool(int(os.getenv("CSRF_ENFORCE", "0")))
AUTH_SECRET  = os.getenv("AUTH_SECRET", "")  # used for HMAC of CSRF token (optional)

# -----------------------------------------------------------------------------
# In-memory rate limit stores (process-local). For production, swap to Redis.
# -----------------------------------------------------------------------------
_ip_attempts: Dict[str, Tuple[int, float]] = {}      # ip -> (attempts_in_window, window_start_epoch)
_user_failures: Dict[str, Tuple[int, float]] = {}    # user_key -> (fail_count, lockout_until_epoch)


def _now() -> float:
    return time.time()


def _window_bucket(start: float, window: int) -> Tuple[float, bool]:
    """Return (new_start, rotated?) for a sliding window."""
    now = _now()
    if now - start >= window:
        return now, True
    return start, False


def check_login_rate_limit(request: Request, user_key: str) -> None:
    """
    Enforce per-IP request window AND per-user lockout on repeated failures.
    Called at the start of login endpoints.
    """
    ip = request.client.host if request.client else "unknown"

    # IP window
    attempts, start = _ip_attempts.get(ip, (0, _now()))
    start, rotated = _window_bucket(start, AUTH_RATE_WINDOW_SECONDS)
    if rotated:
        attempts = 0
    attempts += 1
    _ip_attempts[ip] = (attempts, start)
    if attempts > AUTH_RATE_LIMIT_PER_IP:
        raise HTTPException(status_code=429, detail="Too many login attempts from this IP. Try later.")

    # Per-user lockout check
    fail_cnt, lockout_until = _user_failures.get(user_key, (0, 0.0))
    if lockout_until and _now() < lockout_until:
        raise HTTPException(status_code=429, detail="Account temporarily locked due to repeated failures.")


def register_login_failure(user_key: str) -> None:
    """
    Register a failed login attempt; trigger lockout if threshold reached.
    """
    cnt, lockout_until = _user_failures.get(user_key, (0, 0.0))
    if lockout_until and _now() < lockout_until:
        # still locked; keep as-is
        return
    cnt += 1
    if cnt >= AUTH_LOCKOUT_THRESHOLD:
        _user_failures[user_key] = (0, _now() + AUTH_LOCKOUT_MINUTES * 60.0)
    else:
        _user_failures[user_key] = (cnt, 0.0)


def reset_login_attempts(user_key: str) -> None:
    """
    Reset counters on successful login.
    """
    _user_failures[user_key] = (0, 0.0)

# -----------------------------------------------------------------------------
# CSRF utilities
# -----------------------------------------------------------------------------
CSRF_COOKIE_NAME = "csrf_token"
CSRF_HEADER_NAME = "X-CSRF-Token"


def _sign(value: str) -> str:
    if not AUTH_SECRET:
        # unsigned fallback (still random)
        return value
    return hmac.new(AUTH_SECRET.encode("utf-8"), value.encode("utf-8"), hashlib.sha256).hexdigest()


def issue_csrf_token() -> str:
    """
    Create a CSRF token (random + optional HMAC) that the server can validate.
    The token is returned to the client and also set as a NON-HttpOnly cookie
    by the /api/auth/csrf endpoint (see auth_api.py).
    """
    raw = secrets.token_urlsafe(32)
    sig = _sign(raw)
    return f"{raw}.{sig}"


def _verify_token(token: str) -> bool:
    if not token or "." not in token:
        return False
    raw, sig = token.split(".", 1)
    expected = _sign(raw)
    try:
        return hmac.compare_digest(sig, expected)
    except Exception:
        return False


def require_csrf(request: Request) -> Optional[dict]:
    """
    FastAPI dependency to enforce CSRF on mutating endpoints.
    - If CSRF_ENFORCE = 0, returns immediately (no-op).
    - Otherwise verifies header token matches cookie and signature.
    """
    if not CSRF_ENFORCE:
        return {"csrf": "disabled"}

    hdr = request.headers.get(CSRF_HEADER_NAME, "")
    cookie = request.cookies.get(CSRF_COOKIE_NAME, "")

    if not hdr:
        raise HTTPException(status_code=403, detail="Missing CSRF token header.")
    if hdr != cookie:
        # Require mirroring of cookie value in the header to prevent CSRF.
        raise HTTPException(status_code=403, detail="CSRF token mismatch.")
    if not _verify_token(hdr):
        raise HTTPException(status_code=403, detail="Invalid CSRF token.")

    return {"csrf": "ok"}
# ===== END FILE: services\security.py =====

################################################################################
# ===== FILE: ui\admin_dashboard.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ui\admin_dashboard.py
# SIZE: 48,006 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations
from fastapi import APIRouter
from fastapi.responses import HTMLResponse

router = APIRouter(prefix="/ui/admin", tags=["Admin Dashboard  Dark Neon"])

@router.get("/", response_class=HTMLResponse)
def admin_dashboard() -> HTMLResponse:
    return HTMLResponse(_admin_html())

def _admin_html() -> str:
    # Dark neon variant with upload PDF flow; helper notes/examples removed from UI.
    return r"""
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Admin Dashboard  ICRS  Dark Neon</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css"/>
  <style>
    :root{
      --bg:#020617;
      --bg-panel:#020617;
      --bg-main:#020617;
      --text:#e5e7eb;
      --text-muted:#9ca3af;
      --accent:#22d3ee;
      --accent2:#22c55e;
      --accent-soft:rgba(34,211,238,0.16);
      --border:#1f2937;
      --border-strong:#0f172a;
    }
    *{box-sizing:border-box;}
    body{
      margin:0;
      background:
        radial-gradient(circle at top left,#22d3ee33 0,transparent 55%),
        radial-gradient(circle at bottom right,#22c55e22 0,transparent 55%),
        radial-gradient(circle at center,#0f172a 0,#020617 60%);
      color:var(--text);
      min-height:100vh;
      font-family:system-ui,-apple-system,BlinkMacSystemFont,"SF Pro Text",sans-serif;
    }
    .shell{
      max-width:1440px;
      margin:0 auto;
      padding:18px;
    }
    .shell-inner{
      display:flex;
      gap:18px;
    }

    /* LEFT NAV */
    .left-nav{
      width:260px;
      background:rgba(15,23,42,0.96);
      border-radius:18px;
      padding:16px 14px;
      border:1px solid rgba(30,64,175,0.6);
      box-shadow:
        0 28px 80px rgba(0,0,0,0.9),
        0 0 0 1px rgba(15,23,42,0.8);
    }
    .brand-title{
      font-weight:600;
      letter-spacing:.12em;
      text-transform:uppercase;
      font-size:11px;
      display:flex;
      align-items:center;
      gap:8px;
      color:#e5e7eb;
    }
    .brand-title i{
      color:var(--accent);
      font-size:18px;
    }
    .brand-pill{
      font-size:10px;
      padding:2px 7px;
      border-radius:999px;
      border:1px solid rgba(148,163,184,0.7);
      color:var(--text-muted);
      text-transform:uppercase;
      letter-spacing:.14em;
    }
    .nav-footer-actions .btn{
      font-size:11px;
      padding:4px 9px;
      border-radius:999px;
    }
    .nav-footer-actions .btn-outline-secondary{
      border-color:#4b5563;
      color:#e5e7eb;
    }
    .nav-footer-actions .btn-outline-secondary:hover{
      background:#111827;
    }
    .nav-footer-actions .btn-outline-danger{
      border-color:#b91c1c;
    }

    .idcard{
      border-radius:12px;
      border:1px solid #1f2937;
      background:radial-gradient(circle at top left,#0f172a 0,transparent 65%),
                 radial-gradient(circle at bottom right,#0b1120 0,transparent 60%);
      font-size:12px;
      color:var(--text-muted);
    }

    .nav-pills .nav-link{
      border-radius:10px;
      font-size:13px;
      color:var(--text-muted);
      padding:7px 8px;
      display:flex;
      align-items:center;
      gap:8px;
      border:1px solid transparent;
      margin-bottom:2px;
      background:transparent;
      cursor:pointer;
    }
    .nav-pills .nav-link i{
      font-size:16px;
      color:#4b5563;
    }
    .nav-pills .nav-link:hover{
      background:rgba(15,23,42,0.95);
      color:#e5e7eb;
    }
    .nav-pills .nav-link.active{
      background:
        radial-gradient(circle at left,#22d3ee33 0,transparent 70%),
        radial-gradient(circle at right,#22c55e22 0,transparent 70%);
      color:#f9fafb;
      border-color:rgba(56,189,248,0.7);
      box-shadow:
        0 0 0 1px rgba(22,163,74,0.5),
        0 0 20px rgba(8,47,73,0.7);
    }
    .nav-pills .nav-link.active i{
      color:var(--accent);
    }

    /* MAIN */
    .main{
      flex:1;
      min-width:0;
      background:rgba(15,23,42,0.94);
      border-radius:18px;
      padding:14px;
      border:1px solid var(--border);
      box-shadow:0 30px 80px rgba(0,0,0,0.9);
    }
    .section{display:none;}
    .section.active{display:block;}

    .card{
      border-radius:16px;
      border:1px solid var(--border);
      background:
        radial-gradient(circle at top left,#0f172a 0,transparent 60%),
        radial-gradient(circle at bottom right,#020617 0,transparent 60%),
        #020617;
      box-shadow:0 18px 60px rgba(0,0,0,0.9);
    }
    .card h6{
      font-size:14px;
      letter-spacing:.12em;
      text-transform:uppercase;
      color:#e5e7eb;
    }
    .small{
      font-size:.84rem;
      color:var(--text-muted);
    }

    .table{
      color:#e5e7eb;
    }
    .table thead th{
      white-space:nowrap;
      font-size:11px;
      text-transform:uppercase;
      letter-spacing:.1em;
      color:#9ca3af;
      border-bottom-color:#1f2937;
    }
    .table tbody td{
      font-size:12px;
      vertical-align:middle;
      border-top-color:#111827;
    }

    label.form-label{
      font-size:11px;
      text-transform:uppercase;
      letter-spacing:.14em;
      color:#9ca3af;
      margin-bottom:2px;
    }
    .form-control,.form-select{
      border-radius:999px;
      font-size:12px;
      border:1px solid #374151;
      padding:6px 10px;
      background:#020617;
      color:#f9fafb;
    }
    .form-control::placeholder{color:#4b5563;}
    .form-select option{
      background:#020617;
      color:#f9fafb;
    }

    .btn{
      border-radius:999px;
      font-size:12px;
    }
    .btn-primary{
      background:radial-gradient(circle at top left,#22d3ee 0,#22c55e 70%);
      border:none;
    }
    .btn-outline-secondary{
      border-color:#4b5563;
      color:#e5e7eb;
    }
    .btn-outline-secondary:hover{
      background:#111827;
    }
    .btn-outline-primary{
      border-color:#22d3ee;
      color:#e0f2fe;
    }
    .btn-outline-primary:hover{
      background:#022c22;
    }
    .btn-outline-danger{
      border-color:#b91c1c;
      color:#fecaca;
    }
    .btn-warning{
      background:#f97316;
      border-color:#ea580c;
      color:#0f172a;
    }

    .badge-soft{
      border-radius:999px;
      font-size:10px;
      padding:2px 8px;
      background:var(--accent-soft);
      color:#e0f2fe;
      text-transform:uppercase;
      letter-spacing:.14em;
    }

    .mono{
      font-family:ui-monospace,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;
    }

    #rp_msg,#pf_msg{
      border-radius:10px;
      border:1px solid #374151;
    }
  </style>
</head>
<body>
<div class="shell">
  <div class="shell-inner">
    <!-- LEFT NAV -->
    <div class="left-nav">
      <div class="d-flex justify-content-between align-items-center mb-2">
        <div class="brand-title">
          <i class="bi bi-shield-lock-fill"></i>
          <span>ICRS ADMIN</span>
        </div>
        <span class="brand-pill">v1.0</span>
      </div>
      <div class="d-flex justify-content-between align-items-center nav-footer-actions mb-2">
        <a class="btn btn-outline-secondary btn-sm" href="/docs"><i class="bi bi-journal-code me-1"></i>Docs</a>
        <a class="btn btn-outline-danger btn-sm" href="/api/auth/logout"><i class="bi bi-box-arrow-right me-1"></i>Logout</a>
      </div>
      <div id="idcard" class="idcard py-2 px-3 mb-3">
        Verifying access
      </div>
      <div class="nav flex-column nav-pills">
        <a class="nav-link active" onclick="show('uploadpdf')"><i class="bi bi-cloud-upload"></i><span>Upload PDF</span></a>
        <a class="nav-link" onclick="show('uploads')"><i class="bi bi-cloud-arrow-up"></i><span>Uploads</span></a>
        <a class="nav-link" onclick="show('statements')"><i class="bi bi-receipt"></i><span>Statements</span></a>
        <a class="nav-link" onclick="show('schedule')"><i class="bi bi-table"></i><span>Schedule</span></a>
        <a class="nav-link" onclick="show('terminated')"><i class="bi bi-slash-circle"></i><span>Terminated</span></a>
        <a class="nav-link" onclick="show('activepolicies')"><i class="bi bi-activity"></i><span>Active Policies</span></a>
        <a class="nav-link" onclick="show('missing')"><i class="bi bi-question-circle"></i><span>Missing Policies</span></a>
        <a class="nav-link" onclick="show('auditflags')"><i class="bi bi-flag"></i><span>Audit Flags</span></a>
        <a class="nav-link" onclick="show('reports')"><i class="bi bi-graph-up-arrow"></i><span>Monthly Report</span></a>
        <a class="nav-link" onclick="show('tracker')"><i class="bi bi-calendar-week"></i><span>Uploads Tracker</span></a>
        <a class="nav-link" onclick="show('agents')"><i class="bi bi-people"></i><span>Manage Agents</span></a>
        <a class="nav-link" onclick="show('users')"><i class="bi bi-person-gear"></i><span>Manage Users</span></a>
      </div>
    </div>

    <!-- MAIN CONTENT -->
    <div class="main">

      <!-- Upload PDF (validate -> ingest) -->
      <div id="uploadpdf" class="section active">
        <div class="card p-3 mb-3">
          <div class="d-flex justify-content-between align-items-center mb-2">
            <div>
              <h6 class="mb-0">Upload &amp; Ingest PDF</h6>
              <div class="small">
                Validate then ingest STATEMENT / SCHEDULE / TERMINATED for any agent.
              </div>
            </div>
          </div>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Agent Code</label>
              <input id="pf_agent" class="form-control">
            </div>
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="pf_month" class="form-select"></select>
            </div>
            <div class="col-md-3">
              <label class="form-label">Document Type</label>
              <select id="pf_type" class="form-select">
                <option value="statement">STATEMENT</option>
                <option value="schedule">SCHEDULE</option>
                <option value="terminated">TERMINATED</option>
              </select>
            </div>
            <div class="col-md-3">
              <label class="form-label">Agent Name (optional)</label>
              <input id="pf_name" class="form-control">
            </div>
          </div>
          <div class="row g-2 mt-1 align-items-end">
            <div class="col-md-6">
              <label class="form-label">PDF File</label>
              <input id="pf_file" type="file" accept="application/pdf" class="form-control">
            </div>
            <div class="col-md-6 d-flex gap-2">
              <button class="btn btn-primary mt-4" onclick="validateAndUploadAdmin()">
                <i class="bi bi-shield-check me-1"></i>Validate &amp; Upload
              </button>
              <button class="btn btn-outline-secondary mt-4" onclick="resetUploadAdmin()">
                <i class="bi bi-arrow-counterclockwise me-1"></i>Reset
              </button>
            </div>
          </div>
          <div id="pf_msg" class="alert d-none mt-3"></div>
          <div id="pf_result" class="mt-2"></div>
        </div>
      </div>

      <!-- Uploads list -->
      <div id="uploads" class="section">
        <div class="card p-3 mb-3">
          <div class="d-flex justify-content-between align-items-center mb-2">
            <div>
              <h6 class="mb-0">Uploads</h6>
              <div class="small">Filter and inspect raw upload records.</div>
            </div>
            <span class="badge-soft">Readonly</span>
          </div>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Doc Type</label>
              <select id="up_doc_type" class="form-select">
                <option value="">(any)</option>
                <option>STATEMENT</option>
                <option>SCHEDULE</option>
                <option>TERMINATED</option>
              </select>
            </div>
            <div class="col-md-3">
              <label class="form-label">Agent Code</label>
              <input id="up_agent" class="form-control">
            </div>
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="up_month" class="form-select"></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadUploads()">
                <i class="bi bi-play-circle me-1"></i>Load
              </button>
              <a id="up_csv" class="btn btn-outline-secondary w-100" target="_blank">
                <i class="bi bi-filetype-csv me-1"></i>CSV
              </a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm align-middle">
              <thead><tr>
                <th>UploadID</th><th>Agent</th><th>Agent Name</th><th>Type</th><th>File</th>
                <th>Uploaded</th><th>Month</th><th>Active</th>
              </tr></thead>
              <tbody id="up_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Statements -->
      <div id="statements" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Statements</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="st_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="st_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Policy No</label><input id="st_pol" class="form-control"></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadStatements()">Load</button>
              <a id="st_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>ID</th><th>Upload</th><th>Agent</th><th>Policy</th><th>Holder</th><th>Type</th>
                <th>Pay Date</th><th>Premium</th><th>Com Rate</th><th>Com Amt</th><th>Month</th>
              </tr></thead>
              <tbody id="st_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Schedule -->
      <div id="schedule" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Schedule</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="sc_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="sc_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Latest Only</label>
              <select id="sc_latest" class="form-select"><option value="">(auto)</option><option value="1">Yes</option><option value="0">No</option></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadSchedule()">Load</button>
              <a id="sc_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>ScheduleID</th><th>UploadID</th><th>Agent</th><th>Agent Name</th><th>Batch Code</th>
                <th>Total Premiums</th><th>Income</th><th>Total Deductions</th><th>Net Commission</th><th>Month</th>
              </tr></thead>
              <tbody id="sc_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Terminated -->
      <div id="terminated" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Terminated</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="te_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="te_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Policy No</label><input id="te_pol" class="form-control"></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadTerminated()">Load</button>
              <a id="te_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>TerminatedID</th><th>UploadID</th><th>Agent</th><th>Policy</th><th>Holder</th><th>Type</th>
                <th>Premium</th><th>Status</th><th>Reason</th><th>Month</th><th>Termination Date</th>
              </tr></thead>
              <tbody id="te_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Active Policies -->
      <div id="activepolicies" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Active Policies</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="ap_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Last Seen Month</label><select id="ap_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Status</label>
              <select id="ap_status" class="form-select"><option value="">(any)</option><option value="ACTIVE">ACTIVE</option><option value="MISSING">MISSING</option></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadActive()">Load</button>
              <a id="ap_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>ID</th><th>Agent</th><th>Policy</th><th>Type</th><th>Holder</th><th>Inception</th>
                <th>First Seen</th><th>Last Seen</th><th>Last Seen Month</th><th>Last Premium</th><th>Last Com Rate</th><th>Status</th><th>Missing Streak</th>
              </tr></thead>
              <tbody id="ap_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Missing Policies -->
      <div id="missing" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Missing Policies</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-4"><label class="form-label">Agent Code</label><input id="mi_agent" class="form-control"></div>
            <div class="col-md-4"><label class="form-label">Month</label><select id="mi_month" class="form-select"></select></div>
            <div class="col-md-4 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadMissing()">Load</button>
              <a id="mi_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>Policy No</th><th>Holder</th><th>Policy Type</th><th>Last Seen Month</th><th>Last Premium</th><th>Last Com Rate</th>
              </tr></thead>
              <tbody id="mi_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Audit Flags -->
      <div id="auditflags" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Audit Flags</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="af_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="af_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Flag Type</label><input id="af_type" class="form-control"></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadAudit()">Load</button>
              <a id="af_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>Agent</th><th>Policy</th><th>Month</th><th>Type</th><th>Severity</th><th>Detail</th>
                <th>Expected</th><th>Actual</th><th>Created</th>
              </tr></thead>
              <tbody id="af_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Monthly Report -->
      <div id="reports" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-3">Generate &amp; Download Monthly Report</h6>
          <div class="row g-2">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="rp_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="rp_month" class="form-select"></select></div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-primary w-100" onclick="generateAgentMonth()">Generate</button>
            </div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-outline-secondary w-100" onclick="downloadLatestPDF()">Download PDF</button>
            </div>
          </div>
          <div id="rp_msg" class="alert mt-3 d-none"></div>
        </div>
      </div>

      <!-- Uploads Tracker -->
      <div id="tracker" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Uploads Tracker</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-4"><label class="form-label">Agent Code</label><input id="tr_agent" class="form-control"></div>
            <div class="col-md-4"><label class="form-label">Months Back</label><input id="tr_back" class="form-control" type="number" value="36"></div>
            <div class="col-md-4 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadTracker()">Load</button>
              <a id="tr_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>Month</th><th>Statement</th><th>Schedule</th><th>Terminated</th>
                <th>Stmt UID</th><th>Sch UID</th><th>Ter UID</th>
              </tr></thead>
              <tbody id="tr_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Manage Agents -->
      <div id="agents" class="section">
        <div class="card p-3 mb-3">
          <div class="d-flex justify-content-between align-items-center">
            <div>
              <h6 class="mb-0">Manage Agents</h6>
              <div class="small">Create, update, or deactivate agents.</div>
            </div>
            <button class="btn btn-outline-secondary btn-sm" onclick="listAgents()">Refresh List</button>
          </div>
          <div class="table-responsive mt-2">
            <table class="table table-sm">
              <thead><tr><th>Code</th><th>Name</th><th>License</th><th>Active</th><th>Actions</th></tr></thead>
              <tbody id="agentsRows"></tbody>
            </table>
          </div>
          <h6 class="mt-3">Create / Update Agent</h6>
          <div class="row g-2">
            <div class="col-md-3"><input id="aCode" class="form-control" placeholder="Code"></div>
            <div class="col-md-3"><input id="aName" class="form-control" placeholder="Name"></div>
            <div class="col-md-3"><input id="aLic" class="form-control" placeholder="License"></div>
            <div class="col-md-3">
              <select id="aActive" class="form-select"><option value="1">Active</option><option value="0">Inactive</option></select>
            </div>
          </div>
          <div class="mt-2 d-flex gap-2">
            <button class="btn btn-primary btn-sm" onclick="createAgent()">Create</button>
            <button class="btn btn-warning btn-sm" onclick="updateAgent()">Update</button>
            <span id="aMsg" class="small"></span>
          </div>
        </div>
      </div>

      <!-- Manage Users -->
      <div id="users" class="section">
        <div class="card p-3 mb-3">
          <div class="d-flex justify-content-between align-items-center">
            <div>
              <h6 class="mb-0">Manage Users</h6>
              <div class="small">Admin, superuser, and agent accounts.</div>
            </div>
            <button class="btn btn-outline-secondary btn-sm" onclick="listUsers()">Refresh List</button>
          </div>
          <div class="table-responsive mt-2">
            <table class="table table-sm">
              <thead><tr>
                <th>ID</th><th>Email</th><th>Role</th><th>Agent Code</th><th>Active</th><th>Last Login</th><th>Actions</th>
              </tr></thead>
              <tbody id="usersRows"></tbody>
            </table>
          </div>
          <h6 class="mt-3">Create / Update / Set Password</h6>
          <div class="row g-2">
            <div class="col-md-2"><input id="uId" class="form-control" placeholder="User ID (for update)"></div>
            <div class="col-md-3"><input id="uEmail" class="form-control" placeholder="user@company.com"></div>
            <div class="col-md-2">
              <select id="uRole" class="form-select"><option>admin</option><option>superuser</option><option>agent</option></select>
            </div>
            <div class="col-md-2"><input id="uAgent" class="form-control" placeholder="agent code"></div>
            <div class="col-md-1">
              <select id="uActive" class="form-select"><option value="1">Active</option><option value="0">Inactive</option></select>
            </div>
            <div class="col-md-2"><input id="uPassword" class="form-control" placeholder="(for create / set password)"></div>
          </div>
          <div class="mt-2 d-flex gap-2">
            <button class="btn btn-primary btn-sm" onclick="createUser()">Create</button>
            <button class="btn btn-warning btn-sm" onclick="updateUser()">Update</button>
            <button class="btn btn-outline-primary btn-sm" onclick="setPassword()">Set Password</button>
            <span id="uMsg" class="small"></span>
          </div>
        </div>
      </div>

    </div> <!-- /main -->
  </div>   <!-- /shell-inner -->
</div>     <!-- /shell -->

<script>
function show(id){
  document.querySelectorAll('.nav-link').forEach(a=>a.classList.remove('active'));
  document.querySelectorAll('.section').forEach(s=>s.classList.remove('active'));
  document.getElementById(id)?.classList.add('active');
  const links = document.querySelectorAll('.nav-link');
  links.forEach(el=>{
    if (el.getAttribute('onclick') === `show('${id}')`) el.classList.add('active');
  });
}
function monthLabels(n=36){
  const out=[], abbr=["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];
  const now=new Date(); let y=now.getFullYear(), m=now.getMonth();
  for(let i=0;i<n;i++){ const mm=(m-i); const year=y+Math.floor(mm/12); const mon=((mm%12)+12)%12; out.push(`${abbr[mon]} ${year}`); }
  return out;
}
function populateMonths(){
  const labels=monthLabels(36);
  ['pf_month','up_month','st_month','sc_month','te_month','rp_month','ap_month','mi_month','af_month'].forEach(id=>{
    const el=document.getElementById(id); if(!el) return; el.innerHTML='';
    const empty=document.createElement('option'); empty.value=''; empty.textContent='(any)'; el.appendChild(empty);
    labels.forEach(l=>{ const opt=document.createElement('option'); opt.value=l; opt.textContent=l; el.appendChild(opt); });
  });
}
populateMonths();

async function guard(){
  const r=await fetch('/api/auth/me', {method:'GET', credentials:'same-origin'});
  const j=await r.json();
  const card=document.getElementById('idcard');
  if (!j || j.status!=='OK' || !j.identity){ window.location.href='/ui/login/admin'; return; }
  const role=(j.identity.role||'').toLowerCase();
  if (role!=='admin'){ window.location.href='/ui/login/admin'; return; }
  const email=j.identity.user_email||j.identity.email||''; const uid=j.identity.user_id||'';
  card.className='idcard py-2 px-3 mb-3 border border-success';
  card.innerHTML=`<strong>Role:</strong> ${role}  <strong>ID:</strong> ${uid}  <strong>Email:</strong> ${email}`;
}
guard();

/* NEW: Validate & Upload (Admin for ANY agent) */
function setPfMsg(text, kind='info'){
  const m=document.getElementById('pf_msg'); m.className='alert alert-'+kind; m.textContent=text; m.classList.remove('d-none');
}
function resetUploadAdmin(){
  document.getElementById('pf_agent').value='';
  document.getElementById('pf_month').selectedIndex=0;
  document.getElementById('pf_type').value='statement';
  document.getElementById('pf_name').value='';
  document.getElementById('pf_file').value='';
  document.getElementById('pf_msg').className='alert d-none';
  document.getElementById('pf_result').innerHTML='';
}
async function validateAndUploadAdmin(){
  const agent=(document.getElementById('pf_agent').value||'').trim();
  const month=(document.getElementById('pf_month').value||'').trim();
  const dtype=(document.getElementById('pf_type').value||'statement').trim();
  const aname=(document.getElementById('pf_name').value||'').trim();
  const file=document.getElementById('pf_file').files[0];

  if(!agent || !month || !file){ setPfMsg('Agent, Month and PDF are required','warning'); return; }

  const fdv=new FormData(); fdv.append('agent_code',agent); fdv.append('month_year',month); fdv.append('file',file);
  const v = await fetch(`/api/uploads-secure/${dtype}`, {method:'POST', body:fdv, credentials:'same-origin'});
  const vj = await v.json();
  if(!v.ok){ setPfMsg(vj.detail || 'Validation failed', 'danger'); return; }
  setPfMsg(`Validated: ${vj.file_type} with ${vj.markers_matched} markers`, 'success');

  const fdi=new FormData(); fdi.append('agent_code',agent); fdi.append('month_year',month); fdi.append('agent_name',aname); fdi.append('file',file);
  const u = await fetch(`/api/pdf-enhanced/upload/${dtype}`, {method:'POST', body:fdi, credentials:'same-origin'});
  const uj = await u.json();
  if(!u.ok){ setPfMsg(uj.detail || 'Upload failed', 'danger'); return; }

  document.getElementById('pf_result').innerHTML = `
    <div class="alert alert-success">
      <div><strong>Uploaded & Ingested.</strong></div>
      <div class="mt-1"><small class="mono">upload_id=${uj.upload_id}  doc_type=${uj.doc_type}  records=${uj.records_count}  month=${uj.month_year}</small></div>
      <div class="mt-1"><small class="mono">saved_as=${uj.file_saved_as}</small></div>
    </div>`;
}

/* Uploads listing */
async function loadUploads(){
  const doc = document.getElementById('up_doc_type').value.trim();
  const agent = document.getElementById('up_agent').value.trim();
  const month = document.getElementById('up_month').value.trim();
  const url = '/api/admin/uploads?' + new URLSearchParams({doc_type:doc, agent_code:agent, month_year:month, limit:200});
  document.getElementById('up_csv').href = '/api/admin/uploads.csv?' + new URLSearchParams({doc_type:doc, agent_code:agent, month_year:month});
  const r = await fetch(url, {credentials:'same-origin'}); const j = await r.json(); const tb=document.getElementById('up_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(u=>{
    const tr=document.createElement('tr');
    const active = (u.is_active? 'Yes':'No');
    tr.innerHTML = `<td>${u.UploadID||''}</td><td>${u.agent_code||''}</td><td>${u.AgentName||''}</td><td>${u.doc_type||''}</td>
                    <td>${u.FileName||''}</td><td>${u.UploadTimestamp||''}</td><td>${u.month_year||''}</td><td>${active}</td>`;
    tb.appendChild(tr);
  });
}

/* Statements/Schedule/Terminated */
async function loadStatements(){
  const agent=document.getElementById('st_agent').value.trim();
  const month=document.getElementById('st_month').value.trim();
  const pol=document.getElementById('st_pol').value.trim();
  const url='/api/admin/statements?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol, limit:200});
  document.getElementById('st_csv').href='/api/admin/statements.csv?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('st_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(s=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${s.statement_id||''}</td><td>${s.upload_id||''}</td><td>${s.agent_code||''}</td><td>${s.policy_no||''}</td>
                  <td>${s.holder||''}</td><td>${s.policy_type||''}</td><td>${s.pay_date||''}</td><td>${s.premium||''}</td>
                  <td>${s.com_rate||''}</td><td>${s.com_amt||''}</td><td>${s.month_year||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadSchedule(){
  const agent=document.getElementById('sc_agent').value.trim();
  const month=document.getElementById('sc_month').value.trim();
  const latest=document.getElementById('sc_latest').value.trim();
  const url='/api/admin/schedule?' + new URLSearchParams({agent_code:agent, month_year:month, latest_only:latest, limit:200});
  document.getElementById('sc_csv').href='/api/admin/schedule.csv?' + new URLSearchParams({agent_code:agent, month_year:month, latest_only:latest});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('sc_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(sc=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${sc.schedule_id||''}</td><td>${sc.upload_id||''}</td><td>${sc.agent_code||''}</td><td>${sc.agent_name||''}</td>
                  <td>${sc.commission_batch_code||''}</td><td>${sc.total_premiums||''}</td><td>${sc.income||''}</td>
                  <td>${sc.total_deductions||''}</td><td>${sc.net_commission||''}</td><td>${sc.month_year||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadTerminated(){
  const agent=document.getElementById('te_agent').value.trim();
  const month=document.getElementById('te_month').value.trim();
  const pol=document.getElementById('te_pol').value.trim();
  const url='/api/admin/terminated?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol, limit:200});
  document.getElementById('te_csv').href='/api/admin/terminated.csv?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('te_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(t=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${t.terminated_id||''}</td><td>${t.upload_id||''}</td><td>${t.agent_code||''}</td><td>${t.policy_no||''}</td>
                  <td>${t.holder||''}</td><td>${t.policy_type||''}</td><td>${t.premium||''}</td><td>${t.status||''}</td>
                  <td>${t.reason||''}</td><td>${t.month_year||''}</td><td>${t.termination_date||''}</td>`;
    tb.appendChild(tr);
  });
}

/* Active/Missing/Audit */
async function loadActive(){
  const agent=document.getElementById('ap_agent').value.trim();
  const month=document.getElementById('ap_month').value.trim();
  const status=document.getElementById('ap_status').value.trim();
  const url='/api/admin/active-policies?' + new URLSearchParams({agent_code:agent, month_year:month, status, limit:200});
  document.getElementById('ap_csv').href='/api/admin/active-policies.csv?' + new URLSearchParams({agent_code:agent, month_year:month, status});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('ap_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(x=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.id||''}</td><td>${x.agent_code||''}</td><td>${x.policy_no||''}</td><td>${x.policy_type||''}</td>
                  <td>${x.holder_name||''}</td><td>${x.inception_date||''}</td><td>${x.first_seen_date||''}</td>
                  <td>${x.last_seen_date||''}</td><td>${x.last_seen_month_year||''}</td><td>${x.last_premium||''}</td>
                  <td>${x.last_com_rate||''}</td><td>${x.status||''}</td><td>${x.consecutive_missing_months||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadMissing(){
  const agent=document.getElementById('mi_agent').value.trim();
  const month=document.getElementById('mi_month').value.trim();
  const url='/api/admin/missing?' + new URLSearchParams({agent_code:agent, month_year:month});
  document.getElementById('mi_csv').href='/api/admin/missing.csv?' + new URLSearchParams({agent_code:agent, month_year:month});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('mi_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(x=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.policy_no||''}</td><td>${x.holder_name||''}</td><td>${x.policy_type||''}</td>
                  <td>${x.last_seen_month||''}</td><td>${x.last_premium||''}</td><td>${x.last_com_rate||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadAudit(){
  const agent=document.getElementById('af_agent').value.trim();
  const month=document.getElementById('af_month').value.trim();
  const flag=document.getElementById('af_type').value.trim();
  const url='/api/admin/audit-flags?' + new URLSearchParams({agent_code:agent, month_year:month, flag_type:flag, limit:200});
  document.getElementById('af_csv').href='/api/admin/audit-flags.csv?' + new URLSearchParams({agent_code:agent, month_year:month, flag_type:flag});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('af_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(a=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${a.agent_code||''}</td><td>${a.policy_no||''}</td><td>${a.month_year||''}</td>
                  <td>${a.flag_type||''}</td><td>${a.severity||''}</td><td>${a.flag_detail||''}</td>
                  <td>${a.expected_value||''}</td><td>${a.actual_value||''}</td><td>${a.created_at||''}</td>`;
    tb.appendChild(tr);
  });
}

/* Reports */
async function generateAgentMonth(){
  const agent=document.getElementById('rp_agent').value.trim();
  const month=document.getElementById('rp_month').value.trim();
  if(!agent || !month){ setRpMsg('Provide Agent Code and Month','warning'); return; }
  const form=new URLSearchParams(); form.append('agent_code',agent); form.append('month_year',month);
  const r=await fetch('/api/admin/reports/generate-agent-month',{
    method:'POST', headers:{'Content-Type':'application/x-www-form-urlencoded'}, body:form, credentials:'same-origin'
  });
  const j=await r.json();
  setRpMsg(r.ok ? 'Generated successfully' : ('Error: '+(j.detail||'unknown')), r.ok ? 'success' : 'danger');
}
function setRpMsg(text, kind='info'){
  const el=document.getElementById('rp_msg'); el.className='alert alert-'+kind; el.textContent=text; el.classList.remove('d-none');
}
async function downloadLatestPDF(){
  const agent=document.getElementById('rp_agent').value.trim();
  const month=document.getElementById('rp_month').value.trim();
  if(!agent || !month){ setRpMsg('Provide Agent Code and Month','warning'); return; }
  const list = await (await fetch(`/api/agent/reports?agent_code=${encodeURIComponent(agent)}&month_year=${encodeURIComponent(month)}`, {credentials:'same-origin'})).json();
  const items = list.items || [];
  if(!items.length){ setRpMsg('No report rows found','warning'); return; }
  const rid = items[0].report_id || items[0].id || items[0].ReportID;
  window.open(`/api/agent/reports/download/${encodeURIComponent(rid)}`, '_blank');
}

/* Tracker */
async function loadTracker(){
  const agent=document.getElementById('tr_agent').value.trim();
  const back=document.getElementById('tr_back').value.trim() || '36';
  if(!agent) return;
  const url='/api/admin/uploads/tracker?' + new URLSearchParams({agent_code:agent, months_back:back});
  document.getElementById('tr_csv').href='/api/admin/uploads/tracker.csv?' + new URLSearchParams({agent_code:agent, months_back:back});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('tr_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(x=>{
    const s = x.statement_present ? '' : '';
    const sc= x.schedule_present  ? '' : '';
    const te= x.terminated_present? '' : '';
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.month_year||''}</td><td>${s}</td><td>${sc}</td><td>${te}</td>
                  <td>${x.statement_upload_id||''}</td><td>${x.schedule_upload_id||''}</td><td>${x.terminated_upload_id||''}</td>`;
    tb.appendChild(tr);
  });
}

/* Agents */
async function listAgents(){
  const r=await fetch('/api/admin/agents', {credentials:'same-origin'}); const j=await r.json();
  const tbody=document.getElementById('agentsRows'); tbody.innerHTML='';
  (j.items||[]).forEach(x=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.agent_code||''}</td><td>${x.agent_name||''}</td><td>${x.license_number||''}</td><td>${x.is_active? '1':'0'}</td>
      <td><button class="btn btn-sm btn-outline-danger" onclick="deleteAgent('${x.agent_code}')">Deactivate</button></td>`;
    tbody.appendChild(tr);
  });
}
async function createAgent(){
  const payload={
    agent_code: document.getElementById('aCode').value.trim(),
    agent_name: document.getElementById('aName').value.trim(),
    license_number: document.getElementById('aLic').value.trim(),
    is_active: parseInt(document.getElementById('aActive').value||'1')
  };
  const r=await fetch('/api/admin/agents', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload), credentials:'same-origin'});
  const j=await r.json(); document.getElementById('aMsg').textContent = r.ok ? 'Created' : (j.detail||'Error');
  listAgents();
}
async function updateAgent(){
  const code=document.getElementById('aCode').value.trim();
  const payload={
    agent_name: document.getElementById('aName').value.trim(),
    license_number: document.getElementById('aLic').value.trim(),
    is_active: parseInt(document.getElementById('aActive').value||'1')
  };
  const r=await fetch(`/api/admin/agents/${encodeURIComponent(code)}`, {method:'PUT', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload), credentials:'same-origin'});
  const j=await r.json(); document.getElementById('aMsg').textContent = r.ok ? 'Updated' : (j.detail||'Error');
  listAgents();
}
async function deleteAgent(code){
  const r=await fetch(`/api/admin/agents/${encodeURIComponent(code)}`, {method:'DELETE', credentials:'same-origin'});
  const j=await r.json(); document.getElementById('aMsg').textContent = r.ok ? 'Deactivated' : (j.detail||'Error');
  listAgents();
}

/* Users */
async function listUsers(){
  const r=await fetch('/api/admin/users', {credentials:'same-origin'}); const j=await r.json();
  const tbody=document.getElementById('usersRows'); tbody.innerHTML='';
  (j.items||[]).forEach(u=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${u.id||''}</td><td>${u.email||''}</td><td>${u.role||''}</td><td>${u.agent_code||''}</td>
                  <td>${u.is_active? '1':'0'}</td><td>${u.last_login||''}</td>
      <td><button class="btn btn-sm btn-outline-danger" onclick="deactivateUser(${u.id})">Deactivate</button></td>`;
    tbody.appendChild(tr);
  });
}
async function createUser(){
  const payload={
    email: document.getElementById('uEmail').value.trim(),
    role: document.getElementById('uRole').value.trim(),
    agent_code: document.getElementById('uAgent').value.trim(),
    is_active: parseInt(document.getElementById('uActive').value||'1'),
    password: document.getElementById('uPassword').value.trim()
  };
  const r=await fetch('/api/admin/users', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload), credentials:'same-origin'});
  const j=await r.json(); document.getElementById('uMsg').textContent = r.ok ? 'Created' : (j.detail||'Error');
  listUsers();
}
async function updateUser(){
  const idVal = document.getElementById('uId').value.trim();
  if(!idVal){ document.getElementById('uMsg').textContent='Provide User ID for update'; return; }
  const payload={
    email: document.getElementById('uEmail').value.trim(),
    role: document.getElementById('uRole').value.trim(),
    agent_code: document.getElementById('uAgent').value.trim(),
    is_active: parseInt(document.getElementById('uActive').value||'1'),
    password: (document.getElementById('uPassword').value.trim() || null)
  };
  const r=await fetch(`/api/admin/users/${encodeURIComponent(idVal)}`, {method:'PUT', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload), credentials:'same-origin'});
  const j=await r.json(); document.getElementById('uMsg').textContent = r.ok ? 'Updated' : (j.detail||'Error');
  listUsers();
}
async function deactivateUser(id){
  const r=await fetch(`/api/admin/users/${encodeURIComponent(id)}`, {method:'DELETE', credentials:'same-origin'});
  const j=await r.json(); document.getElementById('uMsg').textContent = r.ok ? 'Deactivated' : (j.detail||'Error');
  listUsers();
}
async function setPassword(){
  const idVal = document.getElementById('uId').value.trim();
  const pwd = document.getElementById('uPassword').value.trim();
  if(!idVal || !pwd){ document.getElementById('uMsg').textContent='Provide User ID and a password'; return; }
  const r=await fetch(`/api/admin/users/${encodeURIComponent(idVal)}/password`, {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({password:pwd}), credentials:'same-origin'});
  const j=await r.json(); document.getElementById('uMsg').textContent = r.ok ? 'Password set' : (j.detail||'Error');
}
</script>
</body>
</html>
"""
# ===== END FILE: ui\admin_dashboard.py =====

################################################################################
# ===== FILE: ui\agent_dashboard.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ui\agent_dashboard.py
# SIZE: 38,126 bytes
# ENCODING: utf-8
# ===== START =====

from __future__ import annotations
from typing import Optional
from fastapi import APIRouter
from fastapi.responses import HTMLResponse

router = APIRouter(prefix="/ui/agent", tags=["Agent Dashboard  Aurora Dark"])


@router.get("/", response_class=HTMLResponse)
def agent_dashboard_root() -> HTMLResponse:
    return HTMLResponse(_agent_html())


@router.get("/{agent_code}", response_class=HTMLResponse)
def agent_dashboard_for_agent(agent_code: str) -> HTMLResponse:
    return HTMLResponse(_agent_html(preload_agent_code=agent_code))


def _agent_html(preload_agent_code: Optional[str] = None) -> str:
    preload = (
        f"<script>window.__PRELOAD_AGENT__={repr(preload_agent_code)};</script>"
        if preload_agent_code
        else ""
    )

    head = r"""
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Agent Dashboard  ICRS  Aurora Dark</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css" rel="stylesheet" />
  <style>
    :root {
      --bg: #020617;
      --bg-panel: #020617;
      --bg-main: #020617;
      --nav-bg: rgba(15,23,42,0.96);
      --nav-border: rgba(72,61,139,0.8);
      --accent: #a855f7;
      --accent-soft: rgba(168,85,247,0.18);
      --accent-alt: #22c55e;
      --accent-alt-soft: rgba(34,197,94,0.18);
      --text: #e5e7eb;
      --text-soft: #9ca3af;
      --border-subtle: #1f2937;
      --card-bg: rgba(15,23,42,0.96);
      --warn: #f59e0b;
    }

    * { box-sizing: border-box; }

    body {
      margin: 0;
      min-height: 100vh;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "SF Pro Text", sans-serif;
      color: var(--text);
      background:
        radial-gradient(circle at top left, rgba(56,189,248,0.14) 0, transparent 55%),
        radial-gradient(circle at bottom right, rgba(168,85,247,0.20) 0, transparent 55%),
        radial-gradient(circle at center, #020617 0, #020617 60%);
    }

    .shell { max-width: 1400px; margin: 0 auto; padding: 18px; }
    .shell-inner { display: flex; gap: 18px; }

    .left-nav {
      width: 250px;
      background: var(--nav-bg);
      border-radius: 18px;
      padding: 16px 14px;
      border: 1px solid var(--nav-border);
      box-shadow:
        0 26px 72px rgba(0,0,0,0.9),
        0 0 0 1px rgba(15,23,42,0.9);
    }

    .brand-title {
      display: flex; align-items: center; gap: 8px;
      font-size: 12px; font-weight: 600; text-transform: uppercase;
      letter-spacing: .14em; color: var(--text);
    }
    .brand-title i { color: var(--accent); font-size: 18px; }

    .nav-pills .nav-link {
      border-radius: 10px; font-size: 13px; color: var(--text-soft);
      padding: 7px 9px; display: flex; align-items: center; gap: 8px;
      border: 1px solid transparent; margin-bottom: 2px; background: transparent; cursor: pointer;
    }
    .nav-pills .nav-link i { font-size: 15px; color: #6b7280; }
    .nav-pills .nav-link:hover { background: rgba(15,23,42,0.98); color: var(--text); }
    .nav-pills .nav-link.active {
      background:
        radial-gradient(circle at left, rgba(168,85,247,0.25) 0, transparent 70%),
        radial-gradient(circle at right, rgba(34,197,94,0.18) 0, transparent 70%);
      color: #f9fafb;
      border-color: rgba(168,85,247,0.8);
      box-shadow: 0 0 0 1px rgba(45,212,191,0.4), 0 0 18px rgba(15,23,42,0.9);
    }
    .nav-pills .nav-link.active i { color: var(--accent); }

    .main {
      flex: 1; min-width: 0; background: rgba(15,23,42,0.96);
      border-radius: 18px; padding: 14px; border: 1px solid var(--border-subtle);
      box-shadow: 0 28px 80px rgba(0,0,0,0.9);
    }

    .section { display: none; }
    .section.active { display: block; }

    .card {
      border-radius: 16px; border: 1px solid var(--border-subtle);
      background:
        radial-gradient(circle at top left, rgba(30,64,175,0.3) 0, transparent 65%),
        radial-gradient(circle at bottom right, rgba(15,23,42,1) 0, transparent 60%);
      box-shadow: 0 18px 60px rgba(0,0,0,0.85);
    }

    .card h6 {
      font-size: 14px; text-transform: uppercase; letter-spacing: .12em; color: #e5e7eb;
    }

    label.form-label {
      font-size: 11px; text-transform: uppercase; letter-spacing: .14em; color: var(--text-soft); margin-bottom: 2px;
    }

    .form-control, .form-select {
      border-radius: 999px; font-size: 12px; border: 1px solid #374151; padding: 6px 10px; background: #020617; color: #f9fafb;
    }
    .form-control::placeholder { color: #4b5563; }
    .form-select option { background: #020617; color: #f9fafb; }

    .btn { border-radius: 999px; font-size: 12px; }
    .btn-primary { background: radial-gradient(circle at top left, var(--accent) 0, #6366f1 70%); border: none; }
    .btn-success { background: radial-gradient(circle at top left, var(--accent-alt) 0, #16a34a 70%); border: none; }
    .btn-outline-secondary { border-color: #4b5563; color: #e5e7eb; }
    .btn-outline-secondary:hover { background: #111827; }
    .btn-warning { background: var(--warn); border: none; color: #111827; }

    .badge-soft {
      border-radius: 999px; font-size: 10px; padding: 2px 8px;
      background: var(--accent-soft); color: #e0f2fe; text-transform: uppercase; letter-spacing: .14em;
    }

    .table { color: #e5e7eb; }
    .table thead th {
      white-space: nowrap; font-size: 11px; text-transform: uppercase; letter-spacing: .10em; color: #9ca3af; border-bottom-color: #1f2937;
    }
    .table tbody td {
      font-size: 12px; vertical-align: middle; border-top-color: #111827;
    }

    #rp_msg { border-radius: 10px; border: 1px solid #374151; }
    .muted { color: var(--text-soft); }
  </style>
</head>
<body>
"""
    tail = r"""
<div class="shell">
  <div class="shell-inner">
    <!-- LEFT NAV -->
    <div class="left-nav">
      <div class="brand-title mb-2">
        <i class="bi bi-person-badge-fill"></i>
        <span>ICRS Agent</span>
      </div>

      <div id="idcard" class="idcard py-2 px-3 mb-3 border border-success">
        Verifying access
      </div>

      <!-- RESTORED LOGOUT BUTTON -->
      <a href="/api/auth/logout" class="btn btn-sm btn-outline-danger w-100 mb-3" title="Logout">
        <i class="bi bi-box-arrow-right me-1"></i>Logout
      </a>

      <div class="nav flex-column nav-pills">
        <a class="nav-link active" onclick="show('summary')">
          <i class="bi bi-activity"></i><span>Summary</span>
        </a>
        <a class="nav-link" onclick="show('uploads')">
          <i class="bi bi-cloud-upload"></i><span>Uploads</span>
        </a>
        <a class="nav-link" onclick="show('tracker')">
          <i class="bi bi-calendar-week"></i><span>Uploads Tracker</span>
        </a>
        <a class="nav-link" onclick="show('statements')">
          <i class="bi bi-receipt"></i><span>Statements</span>
        </a>
        <a class="nav-link" onclick="show('schedule')">
          <i class="bi bi-table"></i><span>Schedule</span>
        </a>
        <a class="nav-link" onclick="show('terminated')">
          <i class="bi bi-slash-circle"></i><span>Terminated</span>
        </a>
        <a class="nav-link" onclick="show('missing')">
          <i class="bi bi-question-circle"></i><span>Missing</span>
        </a>
        <a class="nav-link" onclick="show('disparities')">
          <i class="bi bi-exclamation-triangle"></i><span>Pay-Date Disparities</span>
        </a>
        <a class="nav-link" onclick="show('reports')">
          <i class="bi bi-file-earmark-pdf"></i><span>Monthly Report</span>
        </a>
      </div>
    </div>

    <!-- MAIN CONTENT -->
    <div class="main">

      <!-- Summary -->
      <div id="summary" class="section active">
        <div class="card p-3">
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="sm_month" class="form-select"></select>
            </div>
            <div class="col-md-3 d-flex align-items-end gap-2">
              <button class="btn btn-primary w-100" onclick="loadSummary()">
                <i class="bi bi-arrow-repeat me-1"></i>Refresh
              </button>
              <button class="btn btn-outline-secondary w-100" onclick="exportSummaryCSV()">
                <i class="bi bi-filetype-csv me-1"></i>CSV
              </button>
            </div>
            <div class="col-md-6 small muted d-flex align-items-end">
              Commission Comparison (Net) for the selected month (Expected vs Statement vs Schedule).
            </div>
          </div>
          <div class="mt-3">
            <h6 class="mb-2">Commission Comparison (Net)</h6>
            <div class="table-responsive">
              <table class="table table-sm">
                <thead>
                  <tr>
                    <th>ROW TITLE</th>
                    <th>REPORTED</th>
                    <th>PAID</th>
                    <th>EXPECTED</th>
                  </tr>
                </thead>
                <tbody id="cm_body">
                  <tr><td colspan="4" class="text-muted">No data loaded yet.</td></tr>
                </tbody>
              </table>
            </div>
            <div id="sm_msg" class="small muted mt-1"></div>
          </div>
        </div>
      </div>

      <!-- Uploads -->
      <div id="uploads" class="section">
        <div class="card p-3">
          <div class="d-flex justify-content-between align-items-center mb-1">
            <h6 class="mb-0">Upload PDFs</h6>
            <span class="badge-soft">Agentscoped</span>
          </div>
          <div class="small muted mb-2">
            Upload your monthly Statement, Schedule, and Terminated PDFs. Agent code is inferred from your login.
          </div>

          <div class="row g-2">
            <div class="col-md-4">
              <label class="form-label">Month</label>
              <input id="up_month" class="form-control" placeholder="e.g., Jan 2026">
            </div>
            <div class="col-md-4">
              <label class="form-label">Statement</label>
              <input type="file" id="up_stmt" class="form-control" accept="application/pdf">
            </div>
            <div class="col-md-4 d-flex align-items-end">
              <button class="btn btn-success w-100" onclick="uploadDoc('statement')">
                <i class="bi bi-cloud-arrow-up me-1"></i>Upload Statement
              </button>
            </div>
          </div>

          <div class="row g-2 mt-2">
            <div class="col-md-4">
              <label class="form-label">Month</label>
              <input id="up_month2" class="form-control" placeholder="e.g., Jan 2026">
            </div>
            <div class="col-md-4">
              <label class="form-label">Schedule</label>
              <input type="file" id="up_sched" class="form-control" accept="application/pdf">
            </div>
            <div class="col-md-4 d-flex align-items-end">
              <button class="btn btn-primary w-100" onclick="uploadDoc('schedule')">
                <i class="bi bi-cloud-arrow-up me-1"></i>Upload Schedule
              </button>
            </div>
          </div>

          <div class="row g-2 mt-2">
            <div class="col-md-4">
              <label class="form-label">Month</label>
              <input id="up_month3" class="form-control" placeholder="e.g., Jan 2026">
            </div>
            <div class="col-md-4">
              <label class="form-label">Terminated</label>
              <input type="file" id="up_term" class="form-control" accept="application/pdf">
            </div>
            <div class="col-md-4 d-flex align-items-end">
              <button class="btn btn-warning w-100" onclick="uploadDoc('terminated')">
                <i class="bi bi-cloud-arrow-up me-1"></i>Upload Terminated
              </button>
            </div>
          </div>

          <div id="upMsg" class="mt-2 small muted"></div>
        </div>
      </div>

      <!-- Tracker -->
      <div id="tracker" class="section">
        <div class="card p-3">
          <div class="d-flex justify-content-between align-items-center mb-1">
            <h6 class="mb-0">Uploads Tracker</h6>
            <span class="badge-soft">Last 36 months</span>
          </div>
          <div class="d-flex gap-2 mb-2">
            <button class="btn btn-success btn-sm" onclick="loadTracker()">
              <i class="bi bi-arrow-repeat me-1"></i>Load
            </button>
          </div>
          <div class="muted small mb-2" id="trkInfo"></div>
          <div class="table-responsive">
            <table class="table table-sm">
              <thead>
                <tr>
                  <th>Month</th>
                  <th>Statement</th>
                  <th>Schedule</th>
                  <th>Terminated</th>
                  <th>Upload IDs</th>
                </tr>
              </thead>
              <tbody id="trkRows"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Statements -->
      <div id="statements" class="section">
        <div class="card p-3">
          <h6 class="mb-2">Statements</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="st_month" class="form-select"></select>
            </div>
            <div class="col-md-3">
              <label class="form-label">Policy No</label>
              <input id="st_pol" class="form-control" placeholder="optional">
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-success w-100" onclick="loadStatements()">Load</button>
              <a id="st_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="muted small mt-2" id="st_info"></div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead>
                <tr>
                  <th>ID</th><th>Policy</th><th>Holder</th><th>Type</th>
                  <th>Pay Date</th><th>Premium</th><th>Com Rate</th><th>Com Amt</th><th>Month</th>
                </tr>
              </thead>
              <tbody id="st_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Schedule -->
      <div id="schedule" class="section">
        <div class="card p-3">
          <h6 class="mb-2">Schedule (Latest Only)</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="sc_month" class="form-select"></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-success w-100" onclick="loadSchedule()">Load</button>
              <a id="sc_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="muted small mt-2" id="sc_info"></div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead>
                <tr>
                  <th>UploadID</th><th>Batch Code</th><th>Total Premiums</th>
                  <th>Income</th><th>Total Deductions</th><th>Net Commission</th>
                </tr>
              </thead>
              <tbody id="sc_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Terminated -->
      <div id="terminated" class="section">
        <div class="card p-3">
          <h6 class="mb-2">Terminated</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="te_month" class="form-select"></select>
            </div>
            <div class="col-md-3">
              <label class="form-label">Policy No</label>
              <input id="te_pol" class="form-control" placeholder="optional">
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-success w-100" onclick="loadTerminated()">Load</button>
              <a id="te_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="muted small mt-2" id="te_info"></div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead>
                <tr>
                  <th>ID</th><th>Policy</th><th>Holder</th><th>Type</th>
                  <th>Premium</th><th>Status</th><th>Reason</th>
                  <th>Month</th><th>Termination Date</th>
                </tr>
              </thead>
              <tbody id="te_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Missing -->
      <div id="missing" class="section">
        <div class="card p-3">
          <h6 class="mb-2">Missing Policies</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="mi_month" class="form-select"></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-success w-100" onclick="loadMissing()">Load</button>
              <a id="mi_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="muted small mt-2" id="mi_info"></div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead>
                <tr>
                  <th>Policy No</th><th>Last Seen Month</th><th>Last Premium</th><th>Last Com Rate</th>
                </tr>
              </thead>
              <tbody id="mi_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Pay-Date Disparities -->
      <div id="disparities" class="section">
        <div class="card p-3">
          <h6 class="mb-2">Pay-Date Disparities</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="dp_month" class="form-select"></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-success w-100" onclick="loadDisparities()">Load</button>
              <a id="dp_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="muted small mt-2" id="dp_info"></div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead>
                <tr>
                  <th>Policy No</th><th>Holder</th><th>Premium</th>
                  <th>Expected Month</th><th>Pay Date</th><th> days</th>
                </tr>
              </thead>
              <tbody id="dp_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Monthly Report -->
      <div id="reports" class="section">
        <div class="card p-3">
          <h6 class="mb-2">Generate &amp; Download Monthly Report</h6>
          <div class="row g-2">
            <div class="col-md-3">
              <label class="form-label">Month</label>
              <select id="rp_month" class="form-select"></select>
            </div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-primary w-100" onclick="generateAgentMonth()">
                <i class="bi bi-gear-wide-connected me-1"></i>Generate
              </button>
            </div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-outline-secondary w-100" onclick="downloadLatestPDF()">
                <i class="bi bi-file-earmark-pdf me-1"></i>Download PDF
              </button>
            </div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-outline-secondary w-100" onclick="exportMonthCSV()">
                <i class="bi bi-filetype-csv me-1"></i>Export CSV
              </button>
            </div>
          </div>
          <div id="rp_msg" class="alert mt-3 d-none"></div>
        </div>
      </div>

    </div> <!-- /main -->
  </div>   <!-- /shell-inner -->
</div>     <!-- /shell -->

<script>
let AGENT = '';

function show(id) {
  document.querySelectorAll('.nav-link').forEach(a => a.classList.remove('active'));
  document.querySelectorAll('.section').forEach(s => s.classList.remove('active'));
  document.getElementById(id)?.classList.add('active');
  document.querySelector(`.nav-link[onclick="show('${id}')"]`)?.classList.add('active');
}

function monthLabels(n = 36) {
  const out = [];
  const abbr = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];
  const now = new Date();
  let y = now.getFullYear(), m = now.getMonth();
  for (let i = 0; i < n; i++) {
    const mm = (m - i);
    const year = y + Math.floor(mm / 12);
    const mon = ((mm % 12) + 12) % 12;
    out.push(`${abbr[mon]} ${year}`);
  }
  return out;
}

function populateMonths() {
  const labels = monthLabels(36);
  ['sm_month','st_month','sc_month','te_month','mi_month','dp_month','rp_month'].forEach(id => {
    const el = document.getElementById(id);
    if (!el) return;
    el.innerHTML = '';
    labels.forEach(l => {
      const opt = document.createElement('option');
      opt.value = l;
      opt.textContent = l;
      el.appendChild(opt);
    });
  });
}
populateMonths();

/* Helpers */
async function fetchJSON(url, opts = {}) {
  try {
    const r = await fetch(url, { credentials: 'same-origin', ...opts });
    const ct = r.headers.get('content-type') || '';
    const j = ct.includes('application/json') ? await r.json() : {};
    return { ok: r.ok, status: r.status, json: j };
  } catch (e) {
    return { ok: false, status: 0, json: { detail: String(e) } };
  }
}
function setText(id, txt) { const el = document.getElementById(id); if (el) el.textContent = txt; }
function setHTML(id, html) { const el = document.getElementById(id); if (el) el.innerHTML = html; }

/* Auth guard */
async function guard() {
  const r = await fetchJSON('/api/auth/me', { method: 'GET' });
  const card = document.getElementById('idcard');
  if (!r.ok || !r.json || r.json.status !== 'OK' || !r.json.identity) {
    window.location.href = '/ui/login/agent';
    return;
  }
  const role = (r.json.identity.role || '').toLowerCase();
  if (role !== 'agent') {
    window.location.href = '/ui/login/agent';
    return;
  }
  AGENT = window.__PRELOAD_AGENT__ || r.json.identity.agent_code || r.json.identity.agent || '';
  const agentName = r.json.identity.agent_name || '';
  card.className = 'idcard py-2 px-3 mb-3 border border-success';
  // Show only Agent Name and Agent Code
  card.innerHTML = `<strong>Agent Name:</strong> ${agentName || ''}  <strong>Agent:</strong> ${AGENT}`;
}
guard();

/* Summary  use same Commission Comparison (Net) as monthly report */
async function loadSummary() {
  const month = document.getElementById('sm_month').value.trim();
  if (!AGENT || !month) { alert('Provide agent (auto) and month'); return; }

  const form = new URLSearchParams();
  form.append('agent_code', AGENT);
  form.append('month_year', month);
  form.append('skip_pdf', '1');    // do not generate PDF
  form.append('dry_run', '1');     // compute-only

  const r = await fetchJSON('/api/agent/reports/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: form
  });
  if (!r.ok) { setText('sm_msg', r.json?.detail || 'Error computing summary'); return; }
  setText('sm_msg', '');

  const cm = (r.json?.summary?.commission) || {};
  const diffs = (r.json?.summary?.diffs) || {};
  const rep = cm.reported || {};
  const paid = cm.paid || {};
  const exp = cm.expected || {};
  const vs_rep = diffs.vs_reported || {};
  const vs_paid = diffs.vs_paid || {};
  const vs_exp = diffs.vs_expected || {};

  function q(v) {
    const n = Number(v || 0);
    return isNaN(n) ? 0 : Math.round(n * 100) / 100;
  }

  const rows = [
    ["GROSS COMMISSION", q(rep.gross), q(paid.gross), q(exp.gross)],
    ["GOV TAX", q(rep.gov_tax), q(paid.gov_tax), q(exp.gov_tax)],
    ["SICLASE", q(rep.siclase), q(paid.siclase), q(exp.siclase)],
    ["PREMIUM DEDUCTIONS", q(rep.premium_deductions), q(paid.premium_deductions), q(exp.premium_deductions)],
    ["PENSIONS", q(rep.pensions), q(paid.pensions), q(exp.pensions)],
    ["TOTAL DEDUCTIONS", q(rep.total_deductions), q(paid.total_deductions), q(exp.total_deductions)],
    ["NET COMMISSION", q(rep.net), q(paid.net), q(exp.net)],
    ["", "", "", ""],
    ["DIFF VS REPORTED", 0, q(vs_rep.paid), q(vs_rep.expected)],
    ["DIFF VS PAID", q(vs_paid.reported), 0, q(vs_paid.expected)],
    ["DIFF VS EXPECTED", q(vs_exp.reported), q(vs_exp.paid), 0],
  ];

  const tbody = document.getElementById('cm_body');
  tbody.innerHTML = '';
  rows.forEach(rw => {
    const tr = document.createElement('tr');
    rw.forEach((cell, idx) => {
      const td = document.createElement('td');
      td.textContent = cell === "" ? "" : cell;
      tr.appendChild(td);
    });
    tbody.appendChild(tr);
  });
}

/* Summary CSV  use agent reports CSV (full monthly report) */
function exportSummaryCSV() {
  const month = document.getElementById('sm_month').value.trim();
  if (!AGENT || !month) { alert('Provide agent (auto) and month'); return; }
  const params = new URLSearchParams({ agent_code: AGENT, month_year: month, agent_name: AGENT });
  const url = '/api/agent/reports/export-csv?' + params.toString();
  window.open(url, '_blank');
}

/* Uploads  use /api/ingestion/one */
function setMsg(id, txt) { const el = document.getElementById(id); if (el) el.textContent = txt; }

async function uploadDoc(type) {
  const month =
    (type === 'statement') ? document.getElementById('up_month').value.trim()
  : (type === 'schedule')  ? document.getElementById('up_month2').value.trim()
  :                           document.getElementById('up_month3').value.trim();

  const file =
    (type === 'statement') ? document.getElementById('up_stmt').files[0]
  : (type === 'schedule')  ? document.getElementById('up_sched').files[0]
  :                           document.getElementById('up_term').files[0];

  if (!AGENT || !month || !file) { alert('Provide agent (auto), month and file'); return; }

  const body = new FormData();
  body.append('file', file);
  body.append('doc_type', type);          // statement|schedule|terminated
  body.append('agent_code', AGENT);
  body.append('agent_name', '');
  body.append('month_year_hint', month);
  body.append('dry_run', '0');

  const r = await fetchJSON('/api/ingestion/one', { method: 'POST', body });
  if (!r.ok) { setMsg('upMsg', r.json?.detail || 'Upload error'); return; }

  const u = r.json || {};
  setMsg('upMsg',
    `Uploaded  Type:${u.doc_type || type}  UploadID:${u.upload_id || ''}  Rows:${u.rows_inserted || 0}  Month:${u.month_year || month}`
  );
}

/* Tracker  try agent wrapper first then admin; degrade gracefully */
async function loadTracker() {
  if (!AGENT) return;
  const params = new URLSearchParams({ agent_code: AGENT, months_back: '36' });
  let r = await fetchJSON('/api/agent/uploads/tracker?' + params.toString()); // wrapper
  let info = '';
  if (!r.ok) {
    r = await fetchJSON('/api/admin/uploads/tracker?' + params.toString());   // admin
    if (!r.ok) {
      info = 'Uploads tracker endpoint is not available in this run.';
      setText('trkInfo', info);
      document.getElementById('trkRows').innerHTML = '';
      return;
    } else {
      info = 'Loaded via Admin tracker';
    }
  } else {
    info = 'Loaded via Agent tracker';
  }
  setText('trkInfo', info);

  const tbody = document.getElementById('trkRows');
  tbody.innerHTML = '';
  (r.json.items || []).forEach(row => {
    const tr = document.createElement('tr');
    tr.innerHTML =
      `<td>${row.month_year}</td>` +
      `<td>${(row.statement_present || row.statement) ? '' : ''}</td>` +
      `<td>${(row.schedule_present || row.schedule) ? '' : ''}</td>` +
      `<td>${(row.terminated_present || row.terminated) ? '' : ''}</td>` +
      `<td>Stmt:${row.statement_upload_id || ''}  ` +
      `Sched:${row.schedule_upload_id || ''}  ` +
      `Term:${row.terminated_upload_id || ''}</td>`;
    tbody.appendChild(tr);
  });
}

/* Statements / Schedule / Terminated  try agent wrapper then admin */
async function loadStatements() {
  const month = document.getElementById('st_month').value.trim();
  const pol   = document.getElementById('st_pol').value.trim();
  setText('st_info','');

  const params = new URLSearchParams({ agent_code: AGENT, month_year: month, policy_no: pol, limit: '200' });
  let r = await fetchJSON('/api/agent/statements?' + params.toString());
  let source = 'Agent';
  if (!r.ok) {
    r = await fetchJSON('/api/admin/statements?' + params.toString());
    source = r.ok ? 'Admin' : '';
  }
  if (!r.ok) { setText('st_info','Statements endpoint not available.'); return; }

  document.getElementById('st_csv').href =
    (source === 'Agent' ? '/api/agent/statements.csv?' : '/api/admin/statements.csv?') + new URLSearchParams({
      agent_code: AGENT, month_year: month, policy_no: pol
    }).toString();

  const tb = document.getElementById('st_tbody');
  tb.innerHTML = '';
  (r.json.items || []).forEach(s => {
    const tr = document.createElement('tr');
    tr.innerHTML =
      `<td>${s.statement_id || ''}</td>` +
      `<td>${s.policy_no || ''}</td>` +
      `<td>${s.holder || ''}</td>` +
      `<td>${s.policy_type || ''}</td>` +
      `<td>${s.pay_date || ''}</td>` +
      `<td>${s.premium || ''}</td>` +
      `<td>${s.com_rate || ''}</td>` +
      `<td>${s.com_amt || ''}</td>` +
      `<td>${s.month_year || s.MONTH_YEAR || ''}</td>`;
    tb.appendChild(tr);
  });
  setText('st_info', `Loaded via ${source} endpoint.`);
}

async function loadSchedule() {
  const month = document.getElementById('sc_month').value.trim();
  setText('sc_info','');

  const params = new URLSearchParams({ agent_code: AGENT, month_year: month, latest_only: '1', limit: '200' });
  let r = await fetchJSON('/api/agent/schedule?' + params.toString());
  let source = 'Agent';
  if (!r.ok) {
    r = await fetchJSON('/api/admin/schedule?' + params.toString());
    source = r.ok ? 'Admin' : '';
  }
  if (!r.ok) { setText('sc_info','Schedule endpoint not available.'); return; }

  document.getElementById('sc_csv').href =
    (source === 'Agent' ? '/api/agent/schedule.csv?' : '/api/admin/schedule.csv?') +
    new URLSearchParams({ agent_code: AGENT, month_year: month, latest_only: '1' }).toString();

  const tb = document.getElementById('sc_tbody');
  tb.innerHTML = '';
  (r.json.items || []).forEach(sc => {
    const tr = document.createElement('tr');
    tr.innerHTML =
      `<td>${sc.upload_id || ''}</td>` +
      `<td>${sc.commission_batch_code || ''}</td>` +
      `<td>${sc.total_premiums || ''}</td>` +
      `<td>${sc.income || ''}</td>` +
      `<td>${sc.total_deductions || ''}</td>` +
      `<td>${sc.net_commission || ''}</td>`;
    tb.appendChild(tr);
  });
  setText('sc_info', `Loaded via ${source} endpoint.`);
}

async function loadTerminated() {
  const month = document.getElementById('te_month').value.trim();
  const pol   = document.getElementById('te_pol').value.trim();
  setText('te_info','');

  const params = new URLSearchParams({ agent_code: AGENT, month_year: month, policy_no: pol, limit: '200' });
  let r = await fetchJSON('/api/agent/terminated?' + params.toString());
  let source = 'Agent';
  if (!r.ok) {
    r = await fetchJSON('/api/admin/terminated?' + params.toString());
    source = r.ok ? 'Admin' : '';
  }
  if (!r.ok) { setText('te_info','Terminated endpoint not available.'); return; }

  document.getElementById('te_csv').href =
    (source === 'Agent' ? '/api/agent/terminated.csv?' : '/api/admin/terminated.csv?') +
    new URLSearchParams({ agent_code: AGENT, month_year: month, policy_no: pol }).toString();

  const tb = document.getElementById('te_tbody');
  tb.innerHTML = '';
  (r.json.items || []).forEach(t => {
    const tr = document.createElement('tr');
    tr.innerHTML =
      `<td>${t.terminated_id || ''}</td>` +
      `<td>${t.policy_no || ''}</td>` +
      `<td>${t.holder || ''}</td>` +
      `<td>${t.policy_type || ''}</td>` +
      `<td>${t.premium || ''}</td>` +
      `<td>${t.status || ''}</td>` +
      `<td>${t.reason || ''}</td>` +
      `<td>${t.month_year || ''}</td>` +
      `<td>${t.termination_date || ''}</td>`;
    tb.appendChild(tr);
  });
  setText('te_info', `Loaded via ${source} endpoint.`);
}

/* Missing  /api/agent/missing */
async function loadMissing() {
  const month = document.getElementById('mi_month').value.trim();
  setText('mi_info','');

  const params = new URLSearchParams({ month_year: month });
  let r = await fetchJSON('/api/agent/missing?' + params.toString());
  if (!r.ok) { setText('mi_info','Missing policies endpoint not available.'); return; }

  // There is no dedicated CSV for this agent endpoint yet; disable link if desired
  document.getElementById('mi_csv').href = 'javascript:void(0);';

  const tb = document.getElementById('mi_tbody');
  tb.innerHTML = '';
  (r.json.items || []).forEach(x => {
    const tr = document.createElement('tr');
    tr.innerHTML =
      `<td>${x.policy_no || ''}</td>` +
      `<td>${x.last_seen_month || ''}</td>` +
      `<td>${x.last_premium || ''}</td>` +
      `<td>${x.last_com_rate || ''}</td>`;
    tb.appendChild(tr);
  });
  setText('mi_info', 'Loaded via Agent Missing endpoint.');
}

/* Disparities  /api/disparities/pay-date */
async function loadDisparities() {
  const month = document.getElementById('dp_month').value.trim();
  setText('dp_info','');
  const params = new URLSearchParams({ agent_code: AGENT, month_year: month });

  const r = await fetchJSON('/api/disparities/pay-date?' + params.toString());
  if (!r.ok) { setText('dp_info','Disparities endpoint not available.'); return; }

  document.getElementById('dp_csv').href = '/api/disparities/pay-date.csv?' + params.toString();

  const tb = document.getElementById('dp_tbody');
  tb.innerHTML = '';
  (r.json.disparities || []).forEach(d => {
    const tr = document.createElement('tr');
    tr.innerHTML =
      `<td>${d.policy_no || ''}</td>` +
      `<td>${d.holder_name || ''}</td>` +
      `<td>${d.premium || ''}</td>` +
      `<td>${d.expected_month || ''}</td>` +
      `<td>${d.pay_date || ''}</td>` +
      `<td>${d.days_difference ?? ''}</td>`;
    tb.appendChild(tr);
  });

  const s = r.json.summary || {};
  setText('dp_info', `Disparities: ${s.total_disparities || 0}  Future: ${s.future_dated_count || 0}  Past: ${s.past_dated_count || 0}  Premium affected: ${s.total_premium_affected || 0}`);
}

/* Reports */
function setRpMsg(text, kind = 'info') {
  const el = document.getElementById('rp_msg');
  el.className = 'alert alert-' + kind;
  el.textContent = text;
  el.classList.remove('d-none');
}

async function generateAgentMonth() {
  const month = document.getElementById('rp_month').value.trim();
  if (!AGENT || !month) { alert('Provide Agent Code (auto) and Month'); return; }

  const form = new URLSearchParams();
  form.append('agent_code', AGENT);
  form.append('month_year', month);

  const r = await fetchJSON('/api/agent/reports/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: form
  });
  setRpMsg(r.ok ? 'Generated successfully' : ('Error: ' + (r.json?.detail || 'unknown')), r.ok ? 'success' : 'danger');
}

async function downloadLatestPDF() {
  const month = document.getElementById('rp_month').value.trim();
  if (!AGENT || !month) { alert('Provide Agent Code (auto) and Month'); return; }
  const list = await fetchJSON('/api/agent/reports?' + new URLSearchParams({ agent_code: AGENT, month_year: month }).toString());
  if (!list.ok || !(list.json.items || []).length) {
    setRpMsg('No report rows found', 'warning');
    return;
  }
  const items = list.json.items;
  const rid = items[0].report_id || items[0].id || items[0].ReportID;
  window.open(`/api/agent/reports/download/${encodeURIComponent(rid)}`, '_blank');
}

function exportMonthCSV() {
  const month = document.getElementById('rp_month').value.trim();
  if (!AGENT || !month) { alert('Provide Agent Code (auto) and Month'); return; }
  const params = new URLSearchParams({ agent_code: AGENT, month_year: month, agent_name: AGENT });
  const url = '/api/agent/reports/export-csv?' + params.toString();
  window.open(url, '_blank');
}

</script>
</body>
</html>
"""
    return head + preload + tail
# ===== END FILE: ui\agent_dashboard.py =====

################################################################################
# ===== FILE: ui\superuser_dashboard.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\ui\superuser_dashboard.py
# SIZE: 37,150 bytes
# ENCODING: utf-8
# ===== START =====

# src/ui/superuser_dashboard.py
from __future__ import annotations
from fastapi import APIRouter
from fastapi.responses import HTMLResponse

router = APIRouter(prefix="/ui/superuser", tags=["Superuser Dashboard  Midnight Plum"])

@router.get("/", response_class=HTMLResponse)
def superuser_dashboard() -> HTMLResponse:
    return HTMLResponse(_super_html())

def _super_html() -> str:
    # Midnight-plum theme; parity with Admin (minus Docs/Manage tabs). Uses /api/superuser/*
    return r"""
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Superuser Dashboard  ICRS  Midnight Plum</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css" rel="stylesheet"/>
  <style>
    :root{
      --bg:#020617; --bg-panel:#020617; --bg-main:#020617;
      --text:#e5e7eb; --text-muted:#9ca3af;
      --accent:#a855f7; --accent2:#22c55e; --accent-soft:rgba(168,85,247,.16);
      --border:#1f2937; --border-strong:#0f172a;
    }
    *{box-sizing:border-box}
    body{
      margin:0; min-height:100vh; color:var(--text);
      font-family:system-ui,-apple-system,BlinkMacSystemFont,"SF Pro Text",sans-serif;
      background:
        radial-gradient(circle at top left,#a855f733 0,transparent 55%),
        radial-gradient(circle at bottom right,#22c55e22 0,transparent 55%),
        radial-gradient(circle at center,#0f172a 0,#020617 60%);
    }
    .shell{max-width:1440px;margin:0 auto;padding:18px}
    .shell-inner{display:flex;gap:18px}
    .left-nav{
      width:260px;background:rgba(15,23,42,.96);border-radius:18px;padding:16px 14px;
      border:1px solid rgba(109,40,217,.55);
      box-shadow:0 28px 80px rgba(0,0,0,.9),0 0 0 1px rgba(15,23,42,.8);
    }
    .brand-title{font-weight:600;letter-spacing:.12em;text-transform:uppercase;font-size:11px;display:flex;align-items:center;gap:8px}
    .brand-title i{color:var(--accent);font-size:18px}
    .brand-pill{font-size:10px;padding:2px 7px;border-radius:999px;border:1px solid rgba(148,163,184,.7);color:var(--text-muted);text-transform:uppercase;letter-spacing:.14em}
    .idcard{
      border-radius:12px;border:1px solid #1f2937;
      background:radial-gradient(circle at top left,#0f172a 0,transparent 65%),
                 radial-gradient(circle at bottom right,#0b1120 0,transparent 60%);
      font-size:12px;color:var(--text-muted);
    }
    .nav-pills .nav-link{
      border-radius:10px;font-size:13px;color:var(--text-muted);padding:7px 8px;display:flex;align-items:center;gap:8px;border:1px solid transparent;margin-bottom:2px;background:transparent;cursor:pointer
    }
    .nav-pills .nav-link i{font-size:16px;color:#4b5563}
    .nav-pills .nav-link:hover{background:rgba(15,23,42,.95);color:#e5e7eb}
    .nav-pills .nav-link.active{
      background:
        radial-gradient(circle at left,#a855f733 0,transparent 70%),
        radial-gradient(circle at right,#22c55e22 0,transparent 70%);
      color:#f9fafb;border-color:rgba(168,85,247,.7);
      box-shadow:0 0 0 1px rgba(34,197,94,.45),0 0 20px rgba(8,47,73,.7)
    }
    .nav-pills .nav-link.active i{color:var(--accent)}

    .main{
      flex:1;min-width:0;background:rgba(15,23,42,.94);border-radius:18px;padding:14px;border:1px solid var(--border);
      box-shadow:0 30px 80px rgba(0,0,0,.9)
    }
    .section{display:none}.section.active{display:block}

    .card{
      border-radius:16px;border:1px solid var(--border);
      background:radial-gradient(circle at top left,#0f172a 0,transparent 60%),
                 radial-gradient(circle at bottom right,#020617 0,transparent 60%),#020617;
      box-shadow:0 18px 60px rgba(0,0,0,.9)
    }
    .card h6{font-size:14px;letter-spacing:.12em;text-transform:uppercase;color:#e5e7eb}
    .small{font-size:.84rem;color:var(--text-muted)}
    .table{color:#e5e7eb}
    .table thead th{white-space:nowrap;font-size:11px;text-transform:uppercase;letter-spacing:.1em;color:#9ca3af;border-bottom-color:#1f2937}
    .table tbody td{font-size:12px;vertical-align:middle;border-top-color:#111827}

    label.form-label{font-size:11px;text-transform:uppercase;letter-spacing:.14em;color:#9ca3af;margin-bottom:2px}
    .form-control,.form-select{border-radius:999px;font-size:12px;border:1px solid #374151;padding:6px 10px;background:#020617;color:#f9fafb}
    .form-control::placeholder{color:#4b5563}.form-select option{background:#020617;color:#f9fafb}
    .btn{border-radius:999px;font-size:12px}
    .btn-primary{background:radial-gradient(circle at top left,#a855f7 0,#22c55e 70%);border:none}
    .btn-outline-secondary{border-color:#4b5563;color:#e5e7eb}.btn-outline-secondary:hover{background:#111827}
    .btn-warning{background:#f59e0b;border:none;color:#0f172a}
    .badge-soft{border-radius:999px;font-size:10px;padding:2px 8px;background:var(--accent-soft);color:#e0f2fe;text-transform:uppercase;letter-spacing:.14em}
    .mono{font-family:ui-monospace,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}
    #rp_msg,#pf_msg{border-radius:10px;border:1px solid #374151}
  </style>
</head>
<body>
<div class="shell">
  <div class="shell-inner">
    <!-- LEFT NAV -->
    <div class="left-nav">
      <div class="d-flex justify-content-between align-items-center mb-2">
        <div class="brand-title">
          <i class="bi bi-stars"></i>
          <span>ICRS SUPERUSER</span>
        </div>
        <span class="brand-pill">v1.0</span>
      </div>
      <div class="d-flex justify-content-end align-items-center mb-2">
        <a class="btn btn-outline-danger btn-sm" href="/api/auth/logout"><i class="bi bi-box-arrow-right me-1"></i>Logout</a>
      </div>

      <div id="idcard" class="idcard py-2 px-3 mb-3">Verifying access</div>

      <div class="nav flex-column nav-pills">
        <a class="nav-link active" onclick="show('uploadpdf')"><i class="bi bi-cloud-upload"></i><span>Upload PDF</span></a>
        <a class="nav-link" onclick="show('uploads')"><i class="bi bi-cloud-arrow-up"></i><span>Uploads</span></a>
        <a class="nav-link" onclick="show('statements')"><i class="bi bi-receipt"></i><span>Statements</span></a>
        <a class="nav-link" onclick="show('schedule')"><i class="bi bi-table"></i><span>Schedule</span></a>
        <a class="nav-link" onclick="show('terminated')"><i class="bi bi-slash-circle"></i><span>Terminated</span></a>
        <a class="nav-link" onclick="show('activepolicies')"><i class="bi bi-activity"></i><span>Active Policies</span></a>
        <a class="nav-link" onclick="show('missing')"><i class="bi bi-question-circle"></i><span>Missing Policies</span></a>
        <a class="nav-link" onclick="show('auditflags')"><i class="bi bi-flag"></i><span>Audit Flags</span></a>
        <a class="nav-link" onclick="show('reports')"><i class="bi bi-graph-up-arrow"></i><span>Monthly Report</span></a>
        <a class="nav-link" onclick="show('tracker')"><i class="bi bi-calendar-week"></i><span>Uploads Tracker</span></a>
      </div>
    </div>

    <!-- MAIN CONTENT -->
    <div class="main">

      <!-- Upload PDF -->
      <div id="uploadpdf" class="section active">
        <div class="card p-3 mb-3">
          <div class="d-flex justify-content-between align-items-center mb-2">
            <div>
              <h6 class="mb-0">Upload &amp; Ingest PDF</h6>
              <div class="small">Validate then ingest STATEMENT / SCHEDULE / TERMINATED for any agent.</div>
            </div>
          </div>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="pf_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="pf_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Document Type</label>
              <select id="pf_type" class="form-select">
                <option value="statement">STATEMENT</option>
                <option value="schedule">SCHEDULE</option>
                <option value="terminated">TERMINATED</option>
              </select>
            </div>
            <div class="col-md-3"><label class="form-label">Agent Name (optional)</label><input id="pf_name" class="form-control"></div>
          </div>
          <div class="row g-2 mt-1 align-items-end">
            <div class="col-md-6"><label class="form-label">PDF File</label><input id="pf_file" type="file" accept="application/pdf" class="form-control"></div>
            <div class="col-md-6 d-flex gap-2">
              <button class="btn btn-primary mt-4" onclick="validateAndUpload()"><i class="bi bi-shield-check me-1"></i>Validate &amp; Upload</button>
              <button class="btn btn-outline-secondary mt-4" onclick="resetUpload()"><i class="bi bi-arrow-counterclockwise me-1"></i>Reset</button>
            </div>
          </div>
          <div id="pf_msg" class="alert d-none mt-3"></div>
          <div id="pf_result" class="mt-2"></div>
        </div>
      </div>

      <!-- Uploads -->
      <div id="uploads" class="section">
        <div class="card p-3 mb-3">
          <div class="d-flex justify-content-between align-items-center mb-2">
            <div><h6 class="mb-0">Uploads</h6><div class="small">Filter and inspect raw upload records.</div></div>
            <span class="badge-soft">Readonly</span>
          </div>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Doc Type</label>
              <select id="up_doc_type" class="form-select">
                <option value="">(any)</option><option>STATEMENT</option><option>SCHEDULE</option><option>TERMINATED</option>
              </select>
            </div>
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="up_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="up_month" class="form-select"></select></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadUploads()"><i class="bi bi-play-circle me-1"></i>Load</button>
              <a id="up_csv" class="btn btn-outline-secondary w-100" target="_blank"><i class="bi bi-filetype-csv me-1"></i>CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm align-middle">
              <thead><tr>
                <th>UploadID</th><th>Agent</th><th>Agent Name</th><th>Type</th><th>File</th>
                <th>Uploaded</th><th>Month</th><th>Active</th>
              </tr></thead>
              <tbody id="up_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Statements -->
      <div id="statements" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Statements</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="st_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="st_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Policy No</label><input id="st_pol" class="form-control"></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadStatements()">Load</button>
              <a id="st_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>ID</th><th>Upload</th><th>Agent</th><th>Policy</th><th>Holder</th><th>Type</th>
                <th>Pay Date</th><th>Premium</th><th>Com Rate</th><th>Com Amt</th><th>Month</th>
              </tr></thead>
              <tbody id="st_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Schedule -->
      <div id="schedule" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Schedule</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="sc_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="sc_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Latest Only</label>
              <select id="sc_latest" class="form-select">
                <option value="">(auto)</option><option value="1">Yes</option><option value="0">No</option>
              </select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadSchedule()">Load</button>
              <a id="sc_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>ScheduleID</th><th>UploadID</th><th>Agent</th><th>Agent Name</th><th>Batch Code</th>
                <th>Total Premiums</th><th>Income</th><th>Total Deductions</th><th>Net Commission</th><th>Month</th>
              </tr></thead>
              <tbody id="sc_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Terminated -->
      <div id="terminated" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Terminated</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="te_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="te_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Policy No</label><input id="te_pol" class="form-control"></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadTerminated()">Load</button>
              <a id="te_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>TerminatedID</th><th>UploadID</th><th>Agent</th><th>Policy</th><th>Holder</th><th>Type</th>
                <th>Premium</th><th>Status</th><th>Reason</th><th>Month</th><th>Termination Date</th>
              </tr></thead>
              <tbody id="te_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Active Policies -->
      <div id="activepolicies" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Active Policies</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="ap_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Last Seen Month</label><select id="ap_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Status</label>
              <select id="ap_status" class="form-select"><option value="">(any)</option><option value="ACTIVE">ACTIVE</option><option value="MISSING">MISSING</option></select>
            </div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadActive()">Load</button>
              <a id="ap_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>ID</th><th>Agent</th><th>Policy</th><th>Type</th><th>Holder</th><th>Inception</th>
                <th>First Seen</th><th>Last Seen</th><th>Last Seen Month</th><th>Last Premium</th><th>Last Com Rate</th><th>Status</th><th>Missing Streak</th>
              </tr></thead>
              <tbody id="ap_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Missing Policies -->
      <div id="missing" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Missing Policies</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-4"><label class="form-label">Agent Code</label><input id="mi_agent" class="form-control"></div>
            <div class="col-md-4"><label class="form-label">Month</label><select id="mi_month" class="form-select"></select></div>
            <div class="col-md-4 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadMissing()">Load</button>
              <a id="mi_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>Policy No</th><th>Holder</th><th>Policy Type</th><th>Last Seen Month</th><th>Last Premium</th><th>Last Com Rate</th>
              </tr></thead>
              <tbody id="mi_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Audit Flags -->
      <div id="auditflags" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Audit Flags</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="af_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="af_month" class="form-select"></select></div>
            <div class="col-md-3"><label class="form-label">Flag Type</label><input id="af_type" class="form-control"></div>
            <div class="col-md-3 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadAudit()">Load</button>
              <a id="af_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>Agent</th><th>Policy</th><th>Month</th><th>Type</th><th>Severity</th><th>Detail</th>
                <th>Expected</th><th>Actual</th><th>Created</th>
              </tr></thead>
              <tbody id="af_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

      <!-- Monthly Report -->
      <div id="reports" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-3">Generate &amp; Download Monthly Report</h6>
          <div class="row g-2">
            <div class="col-md-3"><label class="form-label">Agent Code</label><input id="rp_agent" class="form-control"></div>
            <div class="col-md-3"><label class="form-label">Month</label><select id="rp_month" class="form-select"></select></div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-primary w-100" onclick="generateAgentMonth()">Generate</button>
            </div>
            <div class="col-md-3 d-flex align-items-end">
              <button class="btn btn-outline-secondary w-100" onclick="downloadLatestPDF()">Download PDF</button>
            </div>
          </div>
          <div id="rp_msg" class="alert mt-3 d-none"></div>
        </div>
      </div>

      <!-- Uploads Tracker -->
      <div id="tracker" class="section">
        <div class="card p-3 mb-3">
          <h6 class="mb-2">Uploads Tracker</h6>
          <div class="row g-2 align-items-end">
            <div class="col-md-4"><label class="form-label">Agent Code</label><input id="tr_agent" class="form-control"></div>
            <div class="col-md-4"><label class="form-label">Months Back</label><input id="tr_back" class="form-control" type="number" value="36"></div>
            <div class="col-md-4 d-flex gap-2">
              <button class="btn btn-primary w-100" onclick="loadTracker()">Load</button>
              <a id="tr_csv" class="btn btn-outline-secondary w-100" target="_blank">CSV</a>
            </div>
          </div>
          <div class="table-responsive mt-3">
            <table class="table table-sm">
              <thead><tr>
                <th>Month</th><th>Statement</th><th>Schedule</th><th>Terminated</th>
                <th>Stmt UID</th><th>Sch UID</th><th>Ter UID</th>
              </tr></thead>
              <tbody id="tr_tbody"></tbody>
            </table>
          </div>
        </div>
      </div>

    </div><!-- /main -->
  </div><!-- /shell-inner -->
</div><!-- /shell -->

<script>
/* ---------- Common UI helpers ---------- */
function show(id){
  document.querySelectorAll('.nav-link').forEach(a=>a.classList.remove('active'));
  document.querySelectorAll('.section').forEach(s=>s.classList.remove('active'));
  document.getElementById(id)?.classList.add('active');
  const links = document.querySelectorAll('.nav-link');
  links.forEach(el=>{
    if(el.getAttribute('onclick') === `show('${id}')`) el.classList.add('active');
  });
}
function monthLabels(n=36){
  const out=[], abbr=["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];
  const now=new Date(); let y=now.getFullYear(), m=now.getMonth();
  for(let i=0;i<n;i++){ const mm=(m-i); const year=y+Math.floor(mm/12); const mon=((mm%12)+12)%12; out.push(`${abbr[mon]} ${year}`); }
  return out;
}
function populateMonths(){
  const labels=monthLabels(36);
  ['pf_month','up_month','st_month','sc_month','te_month','rp_month','ap_month','mi_month','af_month'].forEach(id=>{
    const el=document.getElementById(id); if(!el) return; el.innerHTML='';
    const empty=document.createElement('option'); empty.value=''; empty.textContent='(any)'; el.appendChild(empty);
    labels.forEach(l=>{ const opt=document.createElement('option'); opt.value=l; opt.textContent=l; el.appendChild(opt); });
  });
}
populateMonths();

async function fetchJSON(url, opts={}){
  try{
    const r = await fetch(url, { credentials:'same-origin', ...opts });
    const ct = r.headers.get('content-type')||'';
    const j = ct.includes('application/json') ? await r.json() : {};
    return { ok:r.ok, status:r.status, json:j };
  }catch(e){ return { ok:false, status:0, json:{ detail:String(e) } }; }
}
function setText(id, txt){ const el=document.getElementById(id); if(el) el.textContent=txt; }

/* ---------- Auth guard (superuser only) ---------- */
async function guard(){
  const r = await fetchJSON('/api/auth/me', { method:'GET' });
  const card = document.getElementById('idcard');
  if(!r.ok || !r.json || r.json.status!=='OK' || !r.json.identity){
    window.location.href = '/ui/login/superuser'; // Option A alias
    return;
  }
  const role = (r.json.identity.role || '').toLowerCase();
  if(role!=='superuser'){ window.location.href = '/ui/login/superuser'; return; }
  const email=r.json.identity.user_email||r.json.identity.email||'', uid=r.json.identity.user_id||'';
  card.className='idcard py-2 px-3 mb-3 border border-success';
  card.innerHTML=`<strong>Role:</strong> ${role}  <strong>ID:</strong> ${uid}  <strong>Email:</strong> ${email}`;
}
guard();

/* ---------- Upload PDF (validate -> upload) ---------- */
function setPfMsg(text, kind='info'){ const m=document.getElementById('pf_msg'); m.className='alert alert-'+kind; m.textContent=text; m.classList.remove('d-none'); }
function resetUpload(){
  document.getElementById('pf_agent').value='';
  document.getElementById('pf_month').selectedIndex=0;
  document.getElementById('pf_type').value='statement';
  document.getElementById('pf_name').value='';
  document.getElementById('pf_file').value='';
  document.getElementById('pf_msg').className='alert d-none';
  document.getElementById('pf_result').innerHTML='';
}
async function validateAndUpload(){
  const agent=(document.getElementById('pf_agent').value||'').trim();
  const month=(document.getElementById('pf_month').value||'').trim();
  const dtype=(document.getElementById('pf_type').value||'statement').trim();
  const aname=(document.getElementById('pf_name').value||'').trim();
  const file=document.getElementById('pf_file').files[0];
  if(!agent || !month || !file){ setPfMsg('Agent, Month and PDF are required','warning'); return; }

  const fdv=new FormData(); fdv.append('agent_code',agent); fdv.append('month_year',month); fdv.append('file',file);
  const v = await fetch(`/api/uploads-secure/${dtype}`, { method:'POST', body:fdv, credentials:'same-origin' });
  const vj = await v.json();
  if(!v.ok){ setPfMsg(vj.detail || 'Validation failed','danger'); return; }
  setPfMsg(`Validated: ${vj.file_type} with ${vj.markers_matched} markers`, 'success');

  const fdi=new FormData(); fdi.append('agent_code',agent); fdi.append('month_year',month); fdi.append('agent_name',aname); fdi.append('file',file);
  const u = await fetch(`/api/pdf-enhanced/upload/${dtype}`, { method:'POST', body:fdi, credentials:'same-origin' });
  const uj = await u.json();
  if(!u.ok){ setPfMsg(uj.detail || 'Upload failed','danger'); return; }

  document.getElementById('pf_result').innerHTML = `
    <div class="alert alert-success">
      <div><strong>Uploaded & Ingested.</strong></div>
      <div class="mt-1"><small class="mono">upload_id=${uj.upload_id}  doc_type=${uj.doc_type}  records=${uj.records_count}  month=${uj.month_year}</small></div>
      <div class="mt-1"><small class="mono">saved_as=${uj.file_saved_as}</small></div>
    </div>`;
}

/* ---------- Uploads listing ---------- */
async function loadUploads(){
  const doc=document.getElementById('up_doc_type').value.trim();
  const agent=document.getElementById('up_agent').value.trim();
  const month=document.getElementById('up_month').value.trim();
  const url='/api/superuser/uploads?' + new URLSearchParams({doc_type:doc, agent_code:agent, month_year:month, limit:200});
  document.getElementById('up_csv').href='/api/superuser/uploads.csv?' + new URLSearchParams({doc_type:doc, agent_code:agent, month_year:month});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('up_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(u=>{
    const tr=document.createElement('tr');
    const active = (u.is_active? 'Yes':'No');
    tr.innerHTML = `<td>${u.UploadID||''}</td><td>${u.agent_code||''}</td><td>${u.AgentName||''}</td><td>${u.doc_type||''}</td>
                    <td>${u.FileName||''}</td><td>${u.UploadTimestamp||''}</td><td>${u.month_year||''}</td><td>${active}</td>`;
    tb.appendChild(tr);
  });
}

/* ---------- Statements / Schedule / Terminated ---------- */
async function loadStatements(){
  const agent=document.getElementById('st_agent').value.trim();
  const month=document.getElementById('st_month').value.trim();
  const pol=document.getElementById('st_pol').value.trim();
  const url='/api/superuser/statements?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol, limit:200});
  document.getElementById('st_csv').href='/api/superuser/statements.csv?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('st_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(s=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${s.statement_id||''}</td><td>${s.upload_id||''}</td><td>${s.agent_code||''}</td><td>${s.policy_no||''}</td>
                  <td>${s.holder||''}</td><td>${s.policy_type||''}</td><td>${s.pay_date||''}</td><td>${s.premium||''}</td>
                  <td>${s.com_rate||''}</td><td>${s.com_amt||''}</td><td>${s.month_year||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadSchedule(){
  const agent=document.getElementById('sc_agent').value.trim();
  const month=document.getElementById('sc_month').value.trim();
  const latest=document.getElementById('sc_latest').value.trim();
  const url='/api/superuser/schedule?' + new URLSearchParams({agent_code:agent, month_year:month, latest_only:latest, limit:200});
  document.getElementById('sc_csv').href='/api/superuser/schedule.csv?' + new URLSearchParams({agent_code:agent, month_year:month, latest_only:latest});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('sc_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(sc=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${sc.schedule_id||''}</td><td>${sc.upload_id||''}</td><td>${sc.agent_code||''}</td><td>${sc.agent_name||''}</td>
                  <td>${sc.commission_batch_code||''}</td><td>${sc.total_premiums||''}</td><td>${sc.income||''}</td>
                  <td>${sc.total_deductions||''}</td><td>${sc.net_commission||''}</td><td>${sc.month_year||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadTerminated(){
  const agent=document.getElementById('te_agent').value.trim();
  const month=document.getElementById('te_month').value.trim();
  const pol=document.getElementById('te_pol').value.trim();
  const url='/api/superuser/terminated?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol, limit:200});
  document.getElementById('te_csv').href='/api/superuser/terminated.csv?' + new URLSearchParams({agent_code:agent, month_year:month, policy_no:pol});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('te_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(t=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${t.terminated_id||''}</td><td>${t.upload_id||''}</td><td>${t.agent_code||''}</td><td>${t.policy_no||''}</td>
                  <td>${t.holder||''}</td><td>${t.policy_type||''}</td><td>${t.premium||''}</td><td>${t.status||''}</td>
                  <td>${t.reason||''}</td><td>${t.month_year||''}</td><td>${t.termination_date||''}</td>`;
    tb.appendChild(tr);
  });
}

/* ---------- Active / Missing / Audit ---------- */
async function loadActive(){
  const agent=document.getElementById('ap_agent').value.trim();
  const month=document.getElementById('ap_month').value.trim();
  const status=document.getElementById('ap_status').value.trim();
  const url='/api/superuser/active-policies?' + new URLSearchParams({agent_code:agent, month_year:month, status, limit:200});
  document.getElementById('ap_csv').href='/api/superuser/active-policies.csv?' + new URLSearchParams({agent_code:agent, month_year:month, status});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('ap_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(x=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.id||''}</td><td>${x.agent_code||''}</td><td>${x.policy_no||''}</td><td>${x.policy_type||''}</td>
                  <td>${x.holder_name||''}</td><td>${x.inception_date||''}</td><td>${x.first_seen_date||''}</td>
                  <td>${x.last_seen_date||''}</td><td>${x.last_seen_month_year||''}</td><td>${x.last_premium||''}</td>
                  <td>${x.last_com_rate||''}</td><td>${x.status||''}</td><td>${x.consecutive_missing_months||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadMissing(){
  // Use admin endpoint allowed to superusers for richer columns
  const agent=document.getElementById('mi_agent').value.trim();
  const month=document.getElementById('mi_month').value.trim();
  const url='/api/admin/missing?' + new URLSearchParams({agent_code:agent, month_year:month});
  document.getElementById('mi_csv').href='/api/admin/missing.csv?' + new URLSearchParams({agent_code:agent, month_year:month});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('mi_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(x=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.policy_no||''}</td><td>${x.holder_name||''}</td><td>${x.policy_type||''}</td>
                  <td>${x.last_seen_month||''}</td><td>${x.last_premium||''}</td><td>${x.last_com_rate||''}</td>`;
    tb.appendChild(tr);
  });
}
async function loadAudit(){
  const agent=document.getElementById('af_agent').value.trim();
  const month=document.getElementById('af_month').value.trim();
  const flag=document.getElementById('af_type').value.trim();
  const url='/api/superuser/audit-flags?' + new URLSearchParams({agent_code:agent, month_year:month, flag_type:flag, limit:200});
  document.getElementById('af_csv').href='/api/superuser/audit-flags.csv?' + new URLSearchParams({agent_code:agent, month_year:month, flag_type:flag});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('af_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(a=>{
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${a.agent_code||''}</td><td>${a.policy_no||''}</td><td>${a.month_year||''}</td>
                  <td>${a.flag_type||''}</td><td>${a.severity||''}</td><td>${a.flag_detail||''}</td>
                  <td>${a.expected_value||''}</td><td>${a.actual_value||''}</td><td>${a.created_at||''}</td>`;
    tb.appendChild(tr);
  });
}

/* ---------- Reports ---------- */
function setRpMsg(text, kind='info'){ const el=document.getElementById('rp_msg'); el.className='alert alert-'+kind; el.textContent=text; el.classList.remove('d-none'); }
async function generateAgentMonth(){
  const agent=document.getElementById('rp_agent').value.trim();
  const month=document.getElementById('rp_month').value.trim();
  if(!agent || !month){ setRpMsg('Provide Agent Code and Month','warning'); return; }
  // Admin endpoint allows superusers (require_admin_or_superuser)
  const form=new URLSearchParams(); form.append('agent_code',agent); form.append('month_year',month);
  const r=await fetch('/api/admin/reports/generate-agent-month',{
    method:'POST', headers:{'Content-Type':'application/x-www-form-urlencoded'}, body:form, credentials:'same-origin'
  });
  const j=await r.json(); setRpMsg(r.ok ? 'Generated successfully' : ('Error: '+(j.detail||'unknown')), r.ok ? 'success' : 'danger');
}
async function downloadLatestPDF(){
  const agent=document.getElementById('rp_agent').value.trim();
  const month=document.getElementById('rp_month').value.trim();
  if(!agent || !month){ setRpMsg('Provide Agent Code and Month','warning'); return; }
  const list = await (await fetch(`/api/agent/reports?agent_code=${encodeURIComponent(agent)}&month_year=${encodeURIComponent(month)}`, {credentials:'same-origin'})).json();
  const items = list.items || []; if(!items.length){ setRpMsg('No report rows found','warning'); return; }
  const rid = items[0].report_id || items[0].id || items[0].ReportID;
  window.open(`/api/agent/reports/download/${encodeURIComponent(rid)}`, '_blank');
}

/* ---------- Uploads Tracker ---------- */
async function loadTracker(){
  const agent=document.getElementById('tr_agent').value.trim();
  const back=document.getElementById('tr_back').value.trim() || '36';
  if(!agent) return;
  const url='/api/superuser/uploads/tracker?' + new URLSearchParams({agent_code:agent, months_back:back});
  document.getElementById('tr_csv').href='/api/superuser/uploads/tracker.csv?' + new URLSearchParams({agent_code:agent, months_back:back});
  const r=await fetch(url, {credentials:'same-origin'}); const j=await r.json(); const tb=document.getElementById('tr_tbody'); tb.innerHTML='';
  (j.items||[]).forEach(x=>{
    const s = x.statement_present ? '' : '';
    const sc= x.schedule_present  ? '' : '';
    const te= x.terminated_present? '' : '';
    const tr=document.createElement('tr');
    tr.innerHTML=`<td>${x.month_year||''}</td><td>${s}</td><td>${sc}</td><td>${te}</td>
                  <td>${x.statement_upload_id||''}</td><td>${x.schedule_upload_id||''}</td><td>${x.terminated_upload_id||''}</td>`;
    tb.appendChild(tr);
  });
}
</script>
</body>
</html>
"""
# ===== END FILE: ui\superuser_dashboard.py =====

################################################################################
# ===== FILE: utils\request_id.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\utils\request_id.py
# SIZE: 1,530 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

import time
import uuid
from typing import Callable, Awaitable

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response
from starlette.types import ASGIApp


class RequestIDMiddleware(BaseHTTPMiddleware):
    """
    Attach a unique X-Request-ID header to every response and emit a simple
    structured log line for each request.

    You can later swap the print() for a proper logger without changing the
    middleware contract.
    """

    async def dispatch(
        self,
        request: Request,
        call_next: Callable[[Request], Awaitable[Response]],
    ) -> Response:
        request_id = str(uuid.uuid4())
        start = time.perf_counter()

        # Optionally expose it to downstream handlers via state if needed
        request.state.request_id = request_id

        response: Response = await call_next(request)
        elapsed_ms = int((time.perf_counter() - start) * 1000)

        # Propagate the ID to the client
        response.headers["X-Request-ID"] = request_id

        # Minimal structured log; replace with your own logger if desired
        print(
            {
                "request_id": request_id,
                "method": request.method,
                "path": request.url.path,
                "status": response.status_code,
                "elapsed_ms": elapsed_ms,
            }
        )

        return response
# ===== END FILE: utils\request_id.py =====

################################################################################
# ===== FILE: utils\security_headers.py =====
# ABS: D:\PROJECT\INSURANCELOCAL\src\utils\security_headers.py
# SIZE: 1,800 bytes
# ENCODING: utf-8
# ===== START =====
from __future__ import annotations

from typing import Optional

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response
from starlette.types import ASGIApp


class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    """
    Add a baseline set of security headers to every response.

    - HSTS (Strict-Transport-Security)
    - X-Frame-Options
    - X-Content-Type-Options
    - Referrer-Policy
    - Permissions-Policy
    - Content-Security-Policy (configurable)
    """

    def __init__(self, app: ASGIApp, *, csp: Optional[str] = None) -> None:
        super().__init__(app)
        # Very conservative default CSP; you can relax as needed.
        self._csp = (
            csp
            or "default-src 'self'; "
            "img-src 'self' data:; "
            "style-src 'self' 'unsafe-inline'; "
            "script-src 'self' 'unsafe-inline';"
        )

    async def dispatch(self, request: Request, call_next) -> Response:
        response: Response = await call_next(request)

        # Only set headers if not already present, so per-route overrides still work.
        response.headers.setdefault(
            "Strict-Transport-Security",
            "max-age=31536000; includeSubDomains; preload",
        )
        response.headers.setdefault("X-Frame-Options", "DENY")
        response.headers.setdefault("X-Content-Type-Options", "nosniff")
        response.headers.setdefault("Referrer-Policy", "no-referrer")
        response.headers.setdefault(
            "Permissions-Policy",
            "geolocation=(), microphone=(), camera=()",
        )
        response.headers.setdefault("Content-Security-Policy", self._csp)

        return response
# ===== END FILE: utils\security_headers.py =====

################################################################################
# SUMMARY
# Files written: 51/51
# Duration: 0.12 sec
################################################################################

